title,articleUrls,keywords,text
Everything Immersive This Week (8/1/20),https://noproscenium.com/everything-immersive-this-week-08-01-2020-65c50682aaeb?source=tag_archive---------0-----------------------,"Eitw,Immersive Theatre,VR","Look: life happens.So you’re getting double the W in this week’s EITW. That’s a lot of show listings, reviews, features, and news. Some of the latter of which is disconcerting as some long whispered issues with a seminal immersive project are starting to come to the surface.Yet the overall thrust of Pandemic Era immersive and experiential remains surprisingly strong.Let’s get into it.Office facilities for No Proscenium are provided by…No Proscenium is made possible by our generous Patreon supporters.[We’re on the march to 1000 backers. Every $1 and $5/month pledge makes all the difference in the world.]ON THE PODCAST THIS WEEKSean Stewart has been a lot of things in his storied career in telling stories. Novelist, LARPwright, actor, theatre tech, and most famously of all: one of the creators of the modern Alternate Reality Game.Now add “internationally produced playwright” to the list.Sean and Noah talk about his upcoming interactive play Roundabout, which will be performed by students of Australia’s National Institute of Dramatic Art via Twitch, and the evolving nature of theatre (yes with the “re”) in the Pandemic Age.Show NotesAustralia’s National Institute of Dramatic Art production of RoundaboutSwings And Roundabouts: Theater Strikes Back — Sean StewartNoPro Episode 156 — Sean Stewart & The Birth of the ARGFROM THE WIRE: SHOWS, EVENTS, & EXPERIENCESWe’re still running the Newswire here at NoPro while the public beta of Everything Immersive shakes out. To get your work on the Newswire, submit at EverythingImmersive.comThe House That SlippedAn online immersive show from Teatro Vivoeach and every“to the makers of music”Greenfield, MA: Under the StarsA Covid-friendly drive-in theatre experienceEngland ExpectsCommand a Royal Navy Warship in the Mediterranean during WW2… over Zoom.Instructions for a Habitat InventoryAn on-demand examination of the place where you areThe Wizards of Oakwood DriveA La Jolla Playhouse Digital Without Walls (WOW) ProductionThe Officially Licensed Evil Dead 2™ Live Remote Escape RoomYou have 70 minutes to save the world in this Groovy game via ZoomFour LoversA game that is (not?) about love.Agent Venture Mission 1: The HeistBond has Q-Branch, Jack Bauer has CTU, Inspector Gadget has Penny & Brain, Agent Venture has… youDr. Crumb’s School for Disobedient Petsbe clever. be quick. be disobedient.LA/Remote: C(ovell) in the C(loud)The Game Goes VirtualElectric Dreams Online FestivalCelebrating the best of cyberspace storytellingSign up for our newsletters to get new immersive experiences sent straight to your inbox.Source: Pixel PlayhouseREVIEWSPandemic Age immersive is taking making forms, and the past two week’s worth of reviews shows off some of that breadth.We kick things off with Definitely Not Clue, which completed its run on Twitch last month. A musical from the gang at Pixel Playhouse, who, in their IRL incarnation as After Hours Theatre Company, have had no small measure of success with immersive experimentation.Definitely Not Clue plays with the chat feature of Twitch to create a dynamic audience experience that influences the way the show is received. This notion of the audiences’ experience as being a distinct element that can be designed and developed is the lodestone by which NoPro as a whole navigates, and its what sets Definitely Not Clue and the upcoming Roundabout (see the Podcast) apart from your basic livestreamed play.Suffice it to say, we’re thinking a lot about this topic these days.Spoilers on the review: Blake loved it.‘Definitely Not Clue’ Lets Loose in a Lively Livestream (Review)Pixel Playhouse brings high school drama archetypes galore to Twitchnoproscenium.comKlaxAlterian Sequester is a podplay that lives up to the experiential potential of the form, and delivers a fantastically polished production right onto the smartphone of your choice for the low low price of nada.Our reviewer, NoPro publisher and third person writing enthusiast Noah Nelson, found the meta-frame of the largely meditative experience a tad depressing as the whole thing is meant to be a transmission from an even darker future, but there’s so many textual layers baked into the production that you might find yourself drawing some hope from what’s sandwiched in between the darker vibes.One way or another: this one is worth the time for the production values alone.The ‘KlaxAlterian Sequester’ Broadcasts From An Even Darker Timeline (Review)It is the Twenties and is there time for KlaxAlteria?noproscenium.comAllie gets to be part of an anarchic audience experience as performer Brian Feldman gives himself over to their control in the improvised #txtshow, which sounds like a blast and the platonic ideal of all those improv shows you went to back in college.Maybe stack the deck with your friends, yeah?Socially Distanced Anarchy Runs Amok in ‘#txtshow (on the internet)’ (Review)Brian Feldman does… whatever we want him to in the audience-led experimental piecenoproscenium.comLaura writes up the team’s experience with B.O.W.L.I.N.G. Night, which they were granted a preview of by creator Brett Jackson.I think this sums it up:I laugh so hard my notes are simply: “lick sauce hole.”Honestly, if I can’t get you to read this based on that there’s no hope for any of us.No Gutterballs Get Rolled in ‘B.O.W.L.I.N.G. Night’ (A NoPro First Look)Live Action Attractions’ Brett Jackson stands out as the game’s kingpinnoproscenium.comFinally this week, Asya takes at look at The Delegation from London’s Coney, which dives into pandemic capitalism via a game-like simulation of a diplomatic summit. Multiple platforms — Zoom, Whereby, and the web — get used to create an evening-long version of a multi-day conference.There’s a lot of ideas packed into this show.‘The Delegation’ Reminds Us of the Power of the People (Review)Coney puts Russians and Brits into a virtual hotel for a diplomatic treatynoproscenium.comFood For ThoughtThis week our executive editor Kathryn Yu published a feature looking at how creators are devising new ways to set the tone for experiences in the Pandemic Age.With so many of the tools of immersive and experiential taken away from us at present, this is a fascinating look at how people are doing more than just “making do” in this digital focused era.Setting the Tone, Virtually: Creating the Magic Circle Online (Feature)How immersive creators can help participants suspend their disbelief at homenoproscenium.comLook, I’m a broken record at this point, but Sean Stewart’s essay Swings And Roundabouts: Theater Strikes Back, is a must read about the role of the audience in the theatre of now. Not just immersive theatre, but theatre in general. Expect more on this anon.Swings and Roundabouts: Theater Strikes Back - Sean StewartWith the advent of live streaming platforms such as Twitch and Facebook Live, theater can draw even with film for the…www.seanstewart.orgNews From around the Immersiverse — Part One: NonchalanceEarlier this week, the NoPro Twitter account was tagged in a tweet by the account of Nonchalance, the production company behind the seminal alternate reality game The Jejune Institute which was the subject of the film The Institute and inspiration of the AMC series Dispatches From Elsewhere.When Nonchalance’s follow up experience The Latitude ended, there was a fracture in the community that had built up around the show. In short: there was a lot of bad blood in the wake of that one, and people weren’t always up for talking on the record. While in private conversations it was obvious that wounds had never fully healed, in public bygones were largely being allowed to be bygones.In the past year, the arrival of Dispatches From Elsewhere and a second film about Nonchalance — developed with their cooperation and focused on The Latitude — called In Bright Axiom stirred up the past. At least one screening of In Bright Axiom appears to have been pulled because of objections from somewhere in the community. That right there is important as the “who” and “why” drives some of what follows.The Nonchalance tweet was followed by a response from Michelle Krasowski, who both challenged Nonchalance’s premise and then proceeded to recount parts of her own experience of Latitude, its creators and the aftermath.Krasowski also made reference to her partner Uriah Findley’s experience as one of the producers of The Latitude. Findley has long since parted ways with Nonchalance, and indeed already had at the time that we interviewed him on our podcast back in 2016.The Nonchalance account and Krasowski had a back and forth, and in the wake of it Nonchalance posted a call to get the stories out in the open.(According to Krasowski, the Nonchalance account would end up blocking her at some point in this window of time.)This call prompted a response from Findley, who released a lengthy thread about his interactions with the director of In Bright Axiom, Spencer McCall, and the head of Nonchalance, Jeff Hull, on Friday night.Findley goes into exhaustive detail on one particular exchange around the time of the festival circuit screenings of In Bright Axiom. As of this writing the Nonchalance account has yet to respond publicly to the thread.So why are we posting this here since Twitter drama isn’t something we normally cover?Well, for one, “Twitter drama” isn’t what this is about. This is a look — messy as it is — at how one of the more controversial projects of the past five years was made and the fallout of the way in which it ended. The Latitude was heavily buzzed about at the time, and the initial fallout was the subject of a feature article at Vice.We’ve been tagged in this, so we were asked to bear witness. The timing of the initial tweet may or may not have to do with the release of In Bright Axiom on VOD, and if there had been no follow ups we likely wouldn’t have had responded, since tagging us isn’t a great way to get our attention for PR purposes. Since there is a dialogue — of sorts — and things that have been talked about on background in the past have started to be surfaced, we have an obligation to draw what meager spotlight we have on to the exchange.Getting to the bottom of all this would take a level of resources that we just don’t have. However, addressing the pains of the past — and, from the outside looking in, there seems to be a lot of pain to go around — is a much needed process. From our previous looks at The Latitude, we know that there are those who have been reluctant to go on the record, so where their stance is at present remains to be seen.We will continue to follow this story as it develops.Her name is Rashin, Tara Rashin. She’s a pirate. Source: ILMxLABNews From around the Immersiverse — Part Two: Everything ElseHey! Who wants some fun?I do! I do!Great!Star Wars: Galaxy’s Edge is is coming home in the form of Star Wars: Tales from the Galaxy’s Edge by way of the Oculus Quest. The experience is still under development, but who knows: we might just be able to go to the digital version of Black Spire Outpost before we can go to the real one.No I will NOT put quotes on “real one.” And I’m sorry but Batuu East is a myth. ;-)5 New Things We Announced This Week About Star Wars: Tales From The Galaxy's Edge - ILMxLABIn a new video, our Star Wars: Tales from the Galaxy's Edge creative team announced story details and casting news for…www.ilmxlab.com44 immersive projects have been selected for the Venice Biennale, greatly expanding the festival’s VR footprint. And the whole thing will be ONLINE. The Venice VR Expanded projects hail from 24 different countries and the jury includes of Celine Tricart (USA), Asif Kapadia (BG), Hideo Kojima (Japan).The online platform is supported by HTC VIVEPORT, Facebook’s Oculus, VRChat and VRrOOm.Oh, how we hope our Quests work for this! It all starts September 2nd.Biennale Cinema 2020 | Selection complete for the works of Venice VR ExpandedVenice VR Expanded The selection is now complete for the Virtual Reality works to be presented at the 77th Venice…www.labiennale.orgIn case you’re not tired of hearing about Roundabout yet, the UK’s Guardian wrote up how Australia’s NIDA is managing the pandemic. No word yet on the secret classes where they teach Australians how to have better accents than any American or British person. Only Canadian actors can stop their plot for global cinematic domination!'It's been deeply odd': how NIDA, Australia's most prestigious acting school, is managing the…Final-year acting student Alex Stamell was deep into rehearsals for Will Eno's Middletown when the Covid-19 shutdown…www.theguardian.comImmerse has this deep dive with the one and only Nonny De La Peña, whose work set the table for the VR renaissance we are currently living in.The World Is 3D and Media Should Be TooNonny de la Peña reflects on her experience as a VR pioneer.immerse.newsFilm Independant interviewed the creative forces behind The Under Presents: Tempest, including one of our favorite immersive actors in any reality: Dasha Kittredge.Tender Claws Uses VR to Re-Imagine Immersive Theater During Lockdown - Film IndependentIn world where real reality increasingly seems like the far inferior of any two given options, it's no wonder that…www.filmindependent.orgAnnnnd just because we can’t have only good news: London’s VAULT festival postpones until 2022.It sucks. But is obviously for the best.VAULT Festival London postpones until 2022In consideration of the significant financial and safety risks brought about by COVID-19 and that each festival takes…britishtheatre.comOpportunities: Professional & EducationalOculus Lauch Pad Scholarships — 2020 Applications OpenOculus, the Facebook owned VR company that makes the popular Quest headset, has announced the winners of its 2019 Launch Pad Scholarship program and that applications for 2020 are now open:Our fourth annual Oculus Launch Pad program has come to a close! Last year, we welcomed 100 new developers from diverse backgrounds to join us for two days of hands-on learning and invited them to continue that momentum through Oculus Connect. At boot camp, we spent two days sharing best practices, unique perspectives, and inspiring ideas. Launch Pad attendees then had four months to build a prototype that could be submitted for consideration as part of our Launch Pad Scholarship program. Today, we’re excited to introduce the 2019 Launch Pad Scholarship recipients and their VR projects that are helping to push the industry in exciting new directions.Oculus Launch Pad 2020 applications are open through August 20. Click here to apply.NoPro is a labor of love made possible by our generous Patreon backers. Join them today!In addition to the No Proscenium web site, our podcast, and our newsletters, you can find NoPro on Twitter, Facebook, YouTube, Instagram, in the Facebook community Everything Immersive, and on our Slack forum.Office facilities provided by Thymele Arts, in Los Angeles, CA.No Proscenium: The Guide To Everything ImmersiveImmersive theatre, virtual reality, escape rooms…Follow2 EitwImmersive TheatreVR2 claps2 clapsWritten byNo ProsceniumFollowThe Guide to Everything Immersive: immersive theatre, virtual reality, escape rooms, LARPs, site-specific dance/art.FollowNo Proscenium: The Guide To Everything ImmersiveFollowImmersive theatre, virtual reality, escape rooms, site-specific dance/art, and moreFollowWritten byNo ProsceniumFollowThe Guide to Everything Immersive: immersive theatre, virtual reality, escape rooms, LARPs, site-specific dance/art.No Proscenium: The Guide To Everything ImmersiveFollowImmersive theatre, virtual reality, escape rooms, site-specific dance/art, and moreMore From MediumBuilding a New World Together with ‘Project Ascension’ (A NoPro Adventure)Leah Ableson in No Proscenium: The Guide To Everything ImmersiveTake a Journey Through 7 O’Clock with ‘The Mile Long Opera’ (Review)Asya Gorovits in No Proscenium: The Guide To Everything ImmersivePast and Present Collide at ‘The Soiled Dove’ (Review)Brian Resler in No Proscenium: The Guide To Everything ImmersiveA Wonderland Indeed with Upended Productions’ ‘Alice’ (Review)Patrick B. McLean in No Proscenium: The Guide To Everything ImmersiveBirds and Bees and Multiple Realities — ‘Loveseat’ at Venice VRPola Weiß in No Proscenium: The Guide To Everything ImmersiveExperience the End of Humanity in ‘Jeff Wayne’s The War of the Worlds’ (Review)Edward Mylechreest in No Proscenium: The Guide To Everything ImmersiveFollow This ‘SCARECROW’ Into the Dark (Review)Kathryn Yu in No Proscenium: The Guide To Everything ImmersiveIt’s A Bloody Good Time at ‘Murder at the Drive-In’ (Review)Danielle Look in No Proscenium: The Guide To Everything ImmersiveLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Building Reality…,https://medium.com/xrpractices/building-reality-793573ce6520?source=tag_archive---------1-----------------------,"Unity3d,Game Development,VR,Virtual Reality,Tutorial","As pain requires to be felt… reality requires to be perceived.Disclaimer: This article doesn’t deal with the philosophy around perception and reality, if you are here for such things, turn back… or find me... :POk, now that the romantics are gone… This article outlines a detailed technical approach to creating a virtual reality (VR) experience and designing interactions around it.We would be using Unity3D and building to Google Cardboard for the same.Let’s get this party started…1. Project SetupStart by setting up a basic Unity project, if in doubt refer to below article.Let’s get Started with Unity…Well let me tell you this won’t be the end all be all… This is just the beginning of a series of Journal log styled…medium.comYou can find the complete code at the following Repository (I’m using Unity3D 2019.4.4 but any 2019.4 should work). To get synced up you can use the following…git clone git@github.com:Neelarghya/reality-vr.gitgit checkout 1429b492. Setting up of SDKs for VR.Once the project is ready we will set up the SDKs required for VR.[Alternative] If you want to use GoogleVR (Since it simple to start with has good examples and docs, literally a dev’s … dream! XD) for the legacy GoogleVR (Legacy but Matured) feel free to follow the below article…Setting up Google VR in UnityA Quick-start for setting up Google VR (GVR)medium.comFor our case we would be targeting Google Cardboard using Cardboard SDK, refer setup below…Quickstart for Google Cardboard for Unity | Google DevelopersThis guide shows you how to use the Google Cardboard XR Plugin for Unity for Unity to create your own Virtual Reality…developers.google.com[Commit: 43a9fca]3. Setting up a basic SceneStart by organize the Scene into Player (0, 0, 0) > Head (0, 1.8, 0) > MainCamera (0, 0, 0) structure. Note the Head is at an height from the body we will come back to this later.Player and MainCamera set upAdd an environment to your Scene, I personally am a sucker for a Plane with a Grid texture and Pro-builder’s bathroom tile like wall material, so… :PLet’s also add something that looks intractable for good measure.Game view for the basic scene setup[Commit: 36f900d]4. “How is this VR..?”Start by adding a TrackedPoseDriver component to the MainCamera, this will sync up the camera’s orientation to the user’s head movement.MainCamera componentsNext we need to set up the whole VR context by configuring the XR-Cardboard Plugin. We will add a basic setup script to check for updates in the device parameters and to manage closing of the app, and add it to a GameObject....using Google.XR.Cardboard;public class CardboardSetup : MonoBehaviour{    public void Start()    {        Screen.sleepTimeout = SleepTimeout.NeverSleep;                if (!Api.HasDeviceParams())            Api.ScanDeviceParams();    }    public void Update()    {        if (Api.IsGearButtonPressed)            Api.ScanDeviceParams();        if (Api.IsCloseButtonPressed)            Application.Quit();        if (Api.HasNewDeviceParams())            Api.ReloadDeviceParams();    }}Adding CardboardSetup scriptNext thing we need is the basic intractability.public class GazeInteractionSource : MonoBehaviour{    [SerializeField] private float intractableDistance = 10;    ...We will start a basic script (GazeInteractionSource) with an exposed field (intractableDistance) which would define how close you need to be to the object to interact with.    private GameObject _gazedObject;    private PointerEventData _eventData;    private void Start()    {        _eventData = new PointerEventData(EventSystem.current);    }    ...We will also define two variables one to to keep track of the object we are focusing/gazing at (_gazedObject) and another would be the pointer event data we use to Invoke pointer event (_eventData).public void Update(){    UpdateInteraction();}private void UpdateInteraction(){    if (Physics.Raycast(transform.position, transform.forward,                     out var hit, intractableDistance))    {        if (_gazedObject != hit.transform.gameObject)        {            if (_gazedObject)                 _gazedObject.GetComponent<IPointerExitHandler>()?                            .OnPointerExit(_eventData);                        _gazedObject = hit.transform.gameObject;            _gazedObject.GetComponent<IPointerEnterHandler>()?                            .OnPointerEnter(_eventData);        }    }    ...So with every update we will check if a ray cast from the current object hits any other GameObject, if so that would be out newly gazed GameObject. We could call the OnPointerExit for the object that loses focus and OnPointerEnter for the object that gains focus.    ...    else if (_gazedObject)    {        _gazedObject.GetComponent<IPointerExitHandler>()?                             .OnPointerExit(_eventData);        _gazedObject = null;    }    ...And if the raycast misses we let the previously focus object lose focus and get rid of its reference.    if (_gazedObject != null &&            Google.XR.Cardboard.Api.IsTriggerPressed)    {        _gazedObject.GetComponent<IPointerClickHandler>()?                            .OnPointerClick(_eventData);    }}Finally when ever the cardboard api’s trigger is pressed we want to perform the click actions on the focused object.Finally Let’s add the script to our MainCamera, and an EventTrigger to out Intractable Object, also make sure it has a collider.Setting up interactions (GazeInteractionSource and EventTrigger)[Commit: e9c95e3]VR view, (screen recording)So what we get is the ability to look around and interact with different objects. This is where you can make a build and experience it in your VR Box/Cardboard.5. “How am I not gazing at it..?”That’s seems like an odd question, but that’s a very valid query when it comes to immersive designing, simply because gaze is subjective (unless you are using eye tracking). What I mean is the intractable point on the screen is only at the centre but as a user I am free to gazing at let’s say the top right corner of my FOV (field of view). So even if I’m gazing at any intractable object I might not be gazing at it (i.e. the raycast might not hit it). Thus visually representing the point of interaction is paramount! This point is represented by a Reticle/Gaze Pointer in most XR mediums. That’s exactly what we are missing…Start by adding a World Space Canvas as a child to the MainCamera.Setting up Canvas to display ReticleNotice the Event Camera and the RectTransform properties. Also there is a more advance way of displaying the reticle at the point of the raycast hit along with scaling based on distance to get around the parallax effect the current method has. But that would just bloat things.Let’s design a Reticle then!All you need though is some UI and animation to start with… For our purposes we will set up a basic Reticle with 2 animations one to hover and one to click. All in all things should look kind of like…Reticle’s Animator ControllerReticle Roll (in and out) and Click AnimationsOne call out don’t spend too much time on designing the reticle (…I spent way more time than I’m willing to accept on these god awful designs :| …)And more importantly you will need to add a material with a Custom Shader to the reticle that that will turn off the ZTest, i.e. render the reticle above the rest of the objects regardless of the Z depth that it has in the scene.What’s more important than spending 4hrs designing and animating a damn reticle is making it actually work with the gaze interactions… :PLet’s start by adding the events to our GazeInteractionSource class.public class GazeInteractionSource : MonoBehaviour{    [SerializeField] private UnityEvent onFocusIntractable;    [SerializeField] private UnityEvent onLoseFocus;    [SerializeField] private UnityEvent onClick;    ...We will update the Update function (:P) to accommodate for these events...    if (_gazedObject != hit.transform.gameObject)    {        if (_gazedObject)        {            _gazedObject.GetComponent<IPointerExitHandler>()?.                            OnPointerExit(_eventData);                        if (IsGazedObjectIntractable())                 onLoseFocus?.Invoke();        }        _gazedObject = hit.transform.gameObject;        _gazedObject.GetComponent<IPointerEnterHandler>()?                           .OnPointerEnter(_eventData);                if (IsGazedObjectIntractable())             onFocusIntractable?.Invoke();    }}else if (_gazedObject){    _gazedObject.GetComponent<IPointerExitHandler>()?                        .OnPointerExit(_eventData);    _gazedObject = null;    onLoseFocus?.Invoke();}if (_gazedObject != null && Api.IsTriggerPressed){    _gazedObject.GetComponent<IPointerClickHandler>()?                        .OnPointerClick(_eventData);        if (IsGazedObjectIntractable())         onClick?.Invoke();}...Also we will add a function to check if the currently hovered object if Intractable. (I will skip optimizations not to bloat this article)private bool IsGazedObjectIntractable(){    return _gazedObject.GetComponent<IEventSystemHandler>() != null;}Link the reticle’s animator to these events and you should be good.[Commit: 534acc3]6. “But I want to explore!”The worst feeling is to be in a new world but not be able to explore it! In the current state the user can only look around and interact with objects it feels restrictive so let’s add some movement to it…Let’s start by setting up a NavMesh for out Environment, and a NavMeshAgent to the Player (keep angularSpeed as 0). (Ref: https://docs.unity3d.com/Manual/nav-BuildingNavMesh.html)Baking NavMesh and adding NavMeshAgent to PlayerNext we need the Player to do is move or should I say navigate… So Let’s add a NavigationControllerpublic class NavigationController : MonoBehaviour,                             IPointerClickHandler{    [SerializeField] private NavMeshAgent playerNavMeshAgent;        public void OnPointerClick(PointerEventData eventData)    {        playerNavMeshAgent.SetDestination(                    eventData.pointerPressRaycast.worldPosition);    }}But we also need to set this worldPosition before we can use it properly. So in GazeInteractionSource.Update()… We update the _eventDate.pointerPressRaycast...if (_gazedObject != null && Api.IsTriggerPressed){    var clickHandler = _gazedObject                  .GetComponentInParent<IPointerClickHandler>();    if (clickHandler != null)    {        _eventData.pointerPressRaycast = new RaycastResult        {            worldPosition = hit.point        };        clickHandler.OnPointerClick(_eventData);    }    if (IsGazedObjectIntractable())        onClick?.Invoke();}...Also we can change all the GetComponents to GetComponentInParent keeping in mind child object can contribute to the colliders.[Commit: 3b9162a]With all that we should be ready to experience the Reality that we have built!A few lines of code here while a new skybox there and we have…Post polishing, view for userLook and feel, source: https://www.youtube.com/channel/UC64M3FR1UBOdn6cL9PnXbgA (self)[Commit: 36f08a9]…Wow still here, quite the journey! Hoping this gave you a head start in VR and looking forward to see the exciting things you folks would come up with! :DXRPracticesThis publication covers the AR VR MR practices in the…Follow34 Unity3dGame DevelopmentVRVirtual RealityTutorial34 claps34 clapsWritten byNeelarghyaFollowStuck between being the Fly on the Wall and the Eye of the Storm!FollowXRPracticesFollowThis publication covers the practical knowledge and experience of software development practices such as TDD, CICD, Automated Testing, Agile for ARVRMR development, and UX design. It is an open community initiative for and by the XR enthusiasts and is maintained by ThougthWokrs.FollowWritten byNeelarghyaFollowStuck between being the Fly on the Wall and the Eye of the Storm!XRPracticesFollowThis publication covers the practical knowledge and experience of software development practices such as TDD, CICD, Automated Testing, Agile for ARVRMR development, and UX design. It is an open community initiative for and by the XR enthusiasts and is maintained by ThougthWokrs.More From MediumOur Firebase Tech StackGeoffrey Bourne in The StartupLearn How to Learn How to ProgramLucas PenzeyMoog in The StartupDetermining the effectiveness of Selective Memoization to defeat ReDoSDionnetakudzwachasiAll Your Travel Plans in One Place With One WebsiteIrene Scott in The StartupHow to Stay Up to Date With Programming TrendsThomas Guibert in Better Programming[GSoC][LibreHealth] Work around for app freezing on READYash SarafHow to choose which programming language you should learn in 2019Ariel Camus in freeCodeCamp.orgHow To Iterate Over Two (or More) Lists at the Same TimeJonathan Hsu in Better ProgrammingLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
N/A,https://medium.com/@DanSteen/the-secret-to-escaping-lockdown-is-skyrim-vr-5b566b11fafd?source=tag_archive---------2-----------------------,"Covid Diaries,Gaming,Virtual Reality,VR,Happiness","Sketches by meThe secret to escaping lockdown is Skyrim VRI’ve recently joined a guild of thieves. After completing several sneaky acts of thievery, I’ve been asked by my superiors to cross the land and investigate some dodgy dealings of the swindling anthropomorphised lizard barfly in Solitude. Having never visited Solitude, I decide to walk northwesterly from my guild’s home in Riften. Like all good hikes, there are many wonders to be discovered on my journey. Not far from my departure point, I discover a cave filled with bandits. Do I investigate and loot this cavern or stick to the primary quest? I decide to investigate, loot and murder. Doesn’t that life sound much more interesting than ‘wake, eat, work, binge-watch TV, back to bed’, and repeat?I’m based in Melbourne, Australia, and we’re now amid our second strict lockdown. I’ve been reflecting and trying to remember, ‘how did I survive the first lockdown just a few months ago?’. The answer is through lots of bad things like drinking too much, eating lots and probably not doing enough exercise. ‘Be kind to me,’ I said, but perhaps I was a little too kind. For me, managing the social impact was easy – my partner is my best mate and I’m a huge introvert – but the lack of space in our small apartment and the inability to explore, visit new places and shake up my routine made the days blur together. Environmental variability is a huge element that is inhibited during the lockdown.It was during that first lockdown that I untangled my PSVR cords and launched Skyrim VR. Skyrim VR was my third purchased copy of the game; the first was a blurry port of the game on Playstation 3, and my second was a copy on PC, and then I finally got a copy for the PSVR when it launched a while back. I’m sure I’m part of the problem when it comes to gaming culture’s frustration of Todd Howard and Bethesda republishing Skyrim on every platform (*starts trawling online for a Nokia N-Gage port). Having never finished the game, each purchase was an ambitious statement: ‘Maybe this time’.The series itself is an amalgamation of traditional fantasy elements with its own unique lore. This series has a special nostalgic place in my heart. As a fourteen-year-old, I was obsessed with one of the predecessors of Skyrim, Elder Scrolls III: Morrowind. I don’t think I ever finished that either, despite spending countless hours exploring the nooks and crannies of that world. If that wasn’t enough, I would expand the world by installing countless mods and replacing game music with my own favourite angsty metal tracks. Sadly, ‘cliff racers’, a notoriously frustrating, common and annoying enemy, would trigger a change in music tracks. Cliff racers ruined Deftones for me. I swear I still look out for flying cliff racers when I hear My Own Summer.I had played a little Skyrim VR when I first purchased the game. I was touting the novelty of swinging a sword and looking up at the landscape to others, but I still stopped playing it due to the sheer effort of setting up the VR experience. But then during the first lockdown, the craving for something reminding me of simpler times and the ability to visit new environments and immersive escapism made Skyrim VR the ideal answer.This time, I surprisingly played the game entirely differently. Rather than being a sword-wielding warrior, I opted to be an archer and mage. The physical act of drawing the bow back or rising my hands to blast enemies with fireballs was tantalising. The additional free time, thanks to no commute or social life, made me appreciate the smaller moments in the game. I would take the longer route, look up more, collect objects that I liked the look of and put more time and effort into laying out objects in my new digital home.Despite playing the game slower, I did let myself take a more completionist mindset and jumped into the primary mission structure and joined two guilds. For the first time, I let the narrative do what the game designers intended it to, showing off the varied beautiful landscapes and the unique enemies, objects and dialogue. The ‘maybe this time’ was ‘this time’. I did finish the game. The main storyline was fun, but perhaps a little underwhelming (the game is pretty damn old now!). What did stand out was the seemingly boring missions. Little things like helping out townies, breaking into random houses, pillaging ruins and exploring caves were surprisingly fun.Playing Skyrim has made me think a lot more about the scale of spaces. Throughout the pandemic, I’ve been listening to audiobooks in the kitchen while doing dishes or cooking, but oddly I find myself sitting on the kitchen bench finishing my current chapter once the dishes are already done. I burnt through The Lord of The Rings trilogy during the first lockdown in a similar need for escapism. I don’t normally hang in the kitchen, but the deep desire for greater environmental variability is making me act out. The kitchen as a hang spot only has so much appeal. Having a look at some dodgy maps, Skyrim’s landscape is about 15.5 km^2 according to self-confessed lifelong player and enthusiast of games, Matthew Sutton. This is much bigger than the 1.5-bedroom apartment I live in! As appealing as hanging in the kitchen is, hanging out at the top of the tallest mountain in Skyrim while chatting to a dragon seemed to do it for me.Having a safe place to escape to that was familiar, but uniquely different, was the ideal distraction from the non-virtual pandemic and Zoom-meeting-laden world. The immersion that is achievable by gestures, motion and head-movement, paired with 3D sound, made the realities of being confined disappear. This experience makes me fantasise about the possibilities of immersive and escapist experiences during sensory-limited, challenging and isolated experiences. Long-haul flights (whenever they start again!), visiting the dentist or waiting in painfully long queues could be transformative experiences.So as we enter the third week of the second lockdown here in Melbourne, I’m reaching for the PSVR HDMI cords, untangling them once again and starting to think about what world I might visit next.Written byDan Steencreative, tinkerer, animator, designer, ux, games and education geek. Vegan.Follow4 4 4 Covid DiariesGamingVirtual RealityVRHappinessMore from Dan SteenFollowcreative, tinkerer, animator, designer, ux, games and education geek. Vegan.More From MediumBygone Gaming RitualsShawn Laib in SUPERJUMPSuper Mario Bros 3 is not LiteratureJack Wellschlager in FanFareReturning to PraetoriansAntony Terence in SUPERJUMPGullivarrr’s Unwelcome TravelsLizzie Bestow in SUPERJUMPWhat Does It Take To Get A Character In Smash?Caleb ComptonSolaire is the Sandworm and Other AporcryphaM StenbækPersona 4 Golden PC: Pokemon with a Side of Making FriendsEdmond WuFall Guys: Ultimate Knockout Is The Chaos We Need In 2020Bre Venanzio in SUPERJUMPAboutHelpLegalGet the Medium app"
"<strong class=""bt"">Let’s Rethink Virtual Reality</strong>",https://medium.com/@synaesthetic/lets-rethink-virtual-reality-daad06313330?source=tag_archive---------3-----------------------,"VR,AR,Music,UX,Technology","a humble opinionNow that we’ve established what Synaesthetic is all about, let’s have some fun.Even as a new-comer to the Augmented Reality / Mixed Reality / Virtual Reality space — it’s not surprising that the VR industry is failing (for convenience, I’ll refer to these all as VR in this post). Regardless of how established such companies are, how advanced their tech is, or the amount of resources they have, it seems that for many, common sense is lacking. Common sense is in such a drought, that we prefer to call Synaesthetic a next-generation User Experience company because the VR label is just not practical these days.Sound arrogant? Please read on.Many of these “Lack-of-Reality” companies and products focus on niche markets and the whims of only a privileged few. This includes premium remote gaming experiences which first and foremost require expensive hardware products (VR headsets) that are simply not worth it to most people. Second, these amazing devices are too complicated to work well. Even before the COVID-19 led recession, analysts declared a “VR winter” based on the 2019 sales of the biggest products out at the time… and others like Magic Leap proving to be a massive flop where vaporware grew from over-ambitious developers.And yes, COVID may open new opportunities for VR, but the concern is that no lesson will be learned and the same over-ambitious mindsets will prevail to repeat past mistakes. We’re only echoing criticisms of questionable trends of the startup world — but in this specific vertical of next-generation user experiences and VR, we will give some of our own opinions.Aside from a few interesting outliers like audio-haptic VR, the vast majority of VR development has been in the visual realm — up to now, advancing graphical displays into tiny wearables where you can generate immersive displays, or layering extra information on top of one’s surroundings, has been the mission. As cool as this idea may be, the general response has been lukewarm — the technology is simply not ready yet, resulting in high prices, limited use-cases, and awkward products.VR is still in its infancy, and it’s rushing towards grand goals without properly building up the social and technical foundations it needs to reach them. In that rush, it fails to recognize the even more critical role it plays in society, as a tool for filling in the cracks for the masses - much like music! I wasn’t alive in the post-war era of the 40s and 50s, but I can still hear and imagine the comfort and support radio and recordings offered to people who thought the world just came back from the brink of destruction.So instead of promising people iPhones upfront, why don’t we figure out basic infrastructure and enabling technologies to make them possible in the first place?And what should the purpose or potential of virtual reality be? Something tells me it’s much bigger than making your skin look smoother on Social. But at its core, something can be learned from such an application — virtual reality is meant to supplement reality, to fill the voids of everyday life, and conveniently offer something beyond what we have available to us in reality. The goal of such a virtual-reality industry is to be mainstream, to reach a critical mass big enough to leverage network effects (which should be a central appeal to VR, because who wants to be in a VR alone or with only a few people?). VR should fill the voids of everyday life; that means making something widely useful, comfortable, and accessible. And in these Post-COVID times, it means bringing back the richness of the in-person experiences we are missing.So in a world of growing isolation and loneliness, polarization and argumentativeness, of effectively grumpiness… What does society need? To feel connected, for better communication.Communication through just text lacks emotion and the larger context of the sea of words you’re drowning in. If your eyes glaze over at the walls of text… then perhaps you’ve reached a data-bloat and attention-deficit, and maybe you need to communicate in a different medium. Maybe what you really want is an emotional release, to recharge your feelings, to exchange empathy, and just feel good. As useful as video chats can be, it is still hard to focus on and feels a bit too removed to try to communicate through a small screen for extended periods of time.For a more sustainable solution, it makes sense to turn to the most long-standing and intuitive communication medium humanity has ever had. Why not turn to the creator of empathy and social connection; the tool that has gotten people through wars, famine, slavery, and spiritual purgatory over the millennia, i.e. Music?Music started off as a communal, interactive, multi-sensory ritual, and these aspects make it such a powerful experience that it tuned our genes to the point that babies can be born with musical intuition. Music was how we first connected, it is a communal pillar, a cultural bridge, the first form of emotional communication. It inspired our memories, transported us from the reality we were in into something higher, something fantastical and abstract… Music was the original Virtual Reality. Think about it, way before electricity or even writing, the sounds we made with just our bodies even as cavemen inspired our minds to add layers of meaning to our environment and lives. If that doesn’t sound like virtual reality, I don’t know what does.Even once the modern music industry was born, from vinyl records to radio broadcasts, recording and replaying audio was the first way we simulated experience with technology on a large scale. In doing so, we birthed the entertainment industry of motion pictures and music, which allowed a cultural revolution of more rich and accessible art for everyone. Sure amazing art existed before the advances in technologies like audio hardware, information storage, and telecommunication made it widely available — but by bringing art to the masses in a practical way, we democratized it away from just a luxury experience for the elite, and leveraged its true value to our society as a tool for the masses.But I’ll be the first to admit it — as much as I love music and listen to it constantly as a sort of fuel for life, I have trouble just listening to a full song with my full attention. I can’t easily focus on my hearing over my other sensory inputs, especially of vision. In fact, I am mostly thinking in my visual senses when I listen to music, as I’m probably typing an email, socializing or being present in my environment in some other capacity. I’ll admit I’m betraying the music in some way when I do that. I am letting this fire-hydrant sized stream of art to just blow past me, while I just take a sip now and again. But we can’t easily close our eyes and listen to a full song without getting distracted. That is just how we are naturally wired… we’ve evolved to look for things we hear, whether it’s a snake in the bush or a crying baby, these are instinctual habits. It’s involuntary; we are programmed to crave visual stimuli all the time… and the digital age of Social media certainly hasn’t reduced that craving. Even as my favorite songs play, my eyes wander and eventually catch on something and draw my attention there. And my eyes can’t stay closed instead, they are wired to be open and take in information and guide my consciousness. Thus, I find myself demoting music to a secondary activity, a background stimulus, a passive act… all of which compromises music’s central purpose, social connection.SO, doesn’t it make sense that in our mission to pioneer VR, to weave a new fabric for reality, and forming new social tools to elevate our culture, especially in these unprecedented and isolated times… we should start at the beginning? We should use music and audio to propel us into the next generation of media and VR to combat the side-effects of “social distancing” — simultaneously tapping into music’s strong social influence, but also rectifying some of digital music’s short-comings in holding our attention.“OK, OK, I get it”, you might say, “but how exactly could we do VR better with music?” Well, it isn’t by providing virtual music videos you can walk through or hyped-up gaming worlds, albeit those are great destinations with a clear demand.First though, what we need to do instead of moonshot products like VR headsets, is simply start with the basics — how do our senses tie together to construct our reality? What is the sensory hierarchy of our consciousness, and how can tech aid in optimizing our perception of experiences? What user experiences have naturally unoptimized sensory stimuli in their environment? For music, is there a link between visual characteristics like color, and audible ones like harmony? Is there data visualization value to physically linking a soundscape to one’s immediate landscape? Does effectively simulating ghosts that embody music move you on a deeper level and provide a new level of immortality to the art and artist?!What is the relationship between what we see and what we hear?At Synaesthetic, we believe VR should start a bit closer to reality in its offerings, even if that isn’t the sexiest or easiest thing to do. But maybe a first-principles approach, where creativity, accessibility, social responsibility, technical pragmatism, and business viability are kept as priorities, can help us pioneer VR and next-gen UX technology into the mainstream.Let me be clear and say this isn’t a dismissal of the industry, this isn’t even a scientific debate of the technology, I’m only challenging industry leaders to sharpen their pencils in how they view their role in society and as a result how they interact with it. There is no debate here that people would buy into an amazing virtual reality world, and there is no doubt that VR can offer value, but my point is we are nowhere near our Sci-fi fantasies yet.If someone really wants to create The Matrix (or save us from it), one should maybe first study Baudrillard and understand that the age of simulation and simulacra is the funeral of originality and “innovation” (a hollowed-out term, but just leave it for now).Instead of trying to hack everything into submission and sell it as “innovation!” before anyone sees the screws fall out — can we be a bit humbler and more respectful of the scientific method that got us this far?I have three suggestions:1. A first-principles approach should be applied to the overall user experience rather than assuming the starting point is a headset (which turns out today to be bulky, expensive, and limited). There are a lot simpler, prerequisite technologies and basic gaps in our understanding of perception that should be worked on first. And they should be worked on in a feasible, systematic fashion. Rome wasn’t built in a day, and the building blocks for VR aren’t even fully built yet, not from a scientific approach that properly masters and develops neurocognitive features at least. We all want to stand on the shoulders of giants, but how many of us realize that giants are not hollow, that if we hope to be giants ourselves then we must also take a thorough and meticulous route. We must learn to do more with less, and zoom in on more fundamental tech rather than dazzlingly large systems like headsets. We need more scientific maturity in tech, especially in VR.2. Even putting the science aside, headset wars do nothing to prime society and the culture to want such technologies as a whole. We need to think about what value can VR offer to the masses, what is our reality lacking that we want to supplement it with virtually? There is good reason to be skeptical and snake oil salesmen are emerging more and more in the tech startup realm. We should focus on leveraging proven hardware that people are familiar with, instead of pushing esoteric new products like headsets down people’s throats. We need to thoroughly prove the value of VR before it will become mainstream.3. Specifically: Steve Jobs took a very technical industry and re-imagined its products into something digestible for average people. Tesla advanced electric cars so much while keeping in mind that accessibility for the mainstream is critical, with their $35k USD Model 3. Last but not least, Snapchat is probably the most relevant example of a successful VR technology with widely-accepted value; nothing too crazy, a practical, engaging and accessible social platform tool that leverages proven and ubiquitous hardware — smartphones. We need to recognize the diversity in our societies and actually act in ways that accommodate it, rather than just support it with words or superficiality. We need to make products that are widely accessible both conceptually and economically.These suggestions may seem a bit demanding, and maybe are too much to ask of people looking to ride hype waves for short-term gains… but to the rest of us that are looking to build lasting value, I propose, in a world that’s stumbling over itself at light-speed — to walk before we run. Let’s come back full circle to some classic truths like listening more than we talk, valuing expertise, and being patient. And I repeat, let’s recognize diversity in our society not just through words but through actions… Can you think of a few?Stay tuned as Synaesthetic leads a movement of more practical & scientific Virtual Reality.Written bySamim SafaeiCEO & Co-Founder @ synaesthetic.aiFollow54 54 54 VRARMusicUXTechnologyMore from Samim SafaeiFollowCEO & Co-Founder @ synaesthetic.aiMore From MediumThe iPhone 12 Lineup Is Oddly Structured And “Un-Apple” LikeAnupam Chugh in Mac O’ClockThe Power to Humanize TechnologyJenn Taylor in The StartupAmazon Launches AI-Powered Halo Band for Health and WellnessPCMag in PC MagazineIn-Depth Guide on How to Greatly Boost Video Chat QualityVan Nguyen in The StartupAmazon Finds It’s Hard to Run a Real Sweepstakes in the Robocall EraBloomberg in BloombergHow a Feel-Good AI Story Went Wrong in FlintAlexis C. Madrigal in The AtlanticThe Podcast Player Showdown Part One; Pocket Casts vs AirrAmanda D. in The InnovationWas Humanity Simply Not Ready for the Internet?Douglas Rushkoff in Team HumanAboutHelpLegalGet the Medium app"
Teddy Bear Museum — VR Experience Design,https://medium.com/@hk659/teddy-bear-museum-vr-experience-design-72f2dd000a1?source=tag_archive---------4-----------------------,"VR,Virtual Reality,Unreal Engine","Unreal Engine Development (C++)OverviewFor a computer graphics course at Cornell, my team of 4 created a Virtual Reality (VR) experience using Unreal Engine (UE).For this project, I built the virtual environment in Unreal with 3D models made by our modelers, and coded animations and interactions such as object collisions and actor-tracking.Tool: Unreal Engine 4.23RoleUE DeveloperScope3.5 weeksTeam“DONuts”Hye Won Kim, UE DeveloperYisu Zheng, UE DeveloperJeffrey Zhu, Modeler/UE DeveloperJustin Joel Tan, ModelerThemeAn underground teddy bear museum filled with the iconic Cornell teddy bear that gazes at the actor as they navigate through the world, eventually finding a way out to the wintry mountains.Object Collison & Actor TrackingFinal DemoFor our final demo, our TA immersed himself in our Teddy Bear Museum using the Oculus Rift VR headset.Written byHye Won KimInformation Science and Communication | Content Designer @tiptoe&Follow5 5 5 VRVirtual RealityUnreal EngineMore from Hye Won KimFollowInformation Science and Communication | Content Designer @tiptoe&More From MediumValidating Azure ARM Template Never Been EasierSibeesh Venu#100DaysOfCode Day 5: More CRUD with Vim and Marlon BrandoRichard Russell in Cold Brew CodeDeploy your PyTorch model to ProductionNicolás Metallo in Data Driven InvestorThe Definitive Guide To Choosing The Right Programming Language To LearnZachary Minott in Dev GeniusDeploy Your Private Docker Registry as a Pod in KubernetesVarun Kumar G in The StartupParallel Asynchronous API Call in PythonSankhadip Samanta in The StartupBuilding Your Next CLIAlex Lakatos in The Startup5 tips for writing great client SDK librariesNatan Silnitsky in Wix EngineeringAboutHelpLegalGet the Medium app"
The Real VR Experience,https://medium.com/@mcleaannithin/the-real-vr-experience-e1420f361358?source=tag_archive---------5-----------------------,"VR,Valve Index,Oculus Rift,Oculus Quest,Gearvr","Virtual reality (VR) is a simulated experience that can be similar to or completely different from the real world.Phone VRAs the name implies These uses mobile phones as the Display. You would slide the phone in the slot.Most Users would have experienced this type of VR. It’s Cheap. When I brought my Samsung galaxy S7 phone, there was an offer of buying the gear VR at discounted price. It was very cheap so I brought it. When I first experienced it, I thought it was cool. But my expectations for VR grew lower after seeing that.Mobile VRs have only 3DoF (Degrees of Freedom) meaning we can look up, down, left, right. And that’s it, it sucks. Some have hand controllers.So, the problem is that most users would have experience only mobile VR in their lives and thought VR like novelty Toy. So, they would never buy a proper Real VR headset assuming that they would experience same.Phone VR gives a bad impression on VRSome Say these are improper VR.Examples: Samsung Gear VR, Google Cardboard.Gear VRGoogle CardboardProper/Real VRNow this is the real and main deal. These are costly. But Facebook(owns Oculus) and others are trying to reduce the cost as much as possible. They are enjoyable and addictive. Sadly, I don’t own one (planning to buy one soon). But what I gathered from watching a lot of twitch VR streamers Opinions, it’s likeIf a person experiences true VR once, he/she would surely buy it.But who is giving that first experience is a big question (probably its Phone VR, that’s why most say VR sucks) .These have 6DoF (Degrees of Freedom) meaning we can do everything that’s in 3DoF plus we can move forward, backward, left, right and the movements are translated into the VR world. The main advantage are the hand controllers which make our hands seem like in VR world to increase the immersion.These also have some disadvantages with the current technology. But they are improving rapidly.Examples: Valve Index, Oculus Rift S, Oculus Quest.Valve IndexOculus QuestWritten byMcleaan NithinComputer and Electronics EnthusiastFollowVRValve IndexOculus RiftOculus QuestGearvrMore from Mcleaan NithinFollowComputer and Electronics EnthusiastMore From MediumThe new Star Wars video game is under attackCNNTechmate: How AI rewrote the rules of chessThe Financial Times in Financial TimesNominal Wattage: Are regulators holding e-scooters back?TAUR in PredictTrump Takes On Amazon Again, Urging ‘Much More’ in Postage FeesBloomberg in BloombergOpen-Source `Great Satan’ No More, Microsoft Wins Over SkepticsBloomberg in BloombergDegrowth won’t take us anywhere but back to the pastEnrique Dans in Enrique DansChina’s Twitter Disinformation Ops Have Been Going on for YearsBloomberg in Bloombergfive links, apr 29 2020Michael SippeyAboutHelpLegalGet the Medium app"
"<strong class=""bt"">How Virtual Reality is Transforming the Healthcare Industry</strong>",https://medium.com/@vrarmr/how-virtual-reality-is-transforming-the-healthcare-industry-3a2331bfaff?source=tag_archive---------0-----------------------,"Virtual Reality,VR,Healthcare,Health,Technology","Virtual Reality is set to revolutionize the Healthcare industry. The healthcare industry operates virtual reality throughout its various divisions to offer a greater quality of attention and performance to patients and medical professionals similarly.From generating new life-saving routines to tutoring the doctors of the future, VR has a multitude of applications for the health and healthcare industry, from the clinical to the user.Following are the applications of Virtual Reality in the healthcare sector:1. Medical trainingVirtual Reality has the expertise to transport you inside the human body — to access & sense areas that contrarily would be difficult to reach. With VR, you can observe minute detail of any element of the body in stunning 360° CGI reconstruction & create training synopses that replicate common medical procedures.VR/AR/MR is one of the companies exploring the use of Virtual Reality to deliver high-quality medical foundation. By recording real-life surgery in 360° video from compound angles which is then merged with CGI models of the body being treated on to render an immersive & interactive training experience.2. Patient EducationThe facility to observe the inside of the human anatomy in Virtual Reality is not only useful for doctors but also patients. VR enables patients to be taken through their medical treatment by practically walking into a patient-specific 360° VR model of their body & diagnostics. This results in enhanced knowledge of the surgery, and consequently higher patient satisfaction.3. Pain Relief TherapyVR’s healing capacities aren’t just defined by mental issues but have been determined to serve for pain management & physical treatment too. VR for natural treatment has also been shown to be powerful in speeding up recovery time. Enabling the patient to do their designated daily tasks in a virtual setting makes the work more fun, keeps the patient-focused, and encourages them to keep their moods up during what can be a long healing period.4. Medical marketingMarketing is the most popular primary application of VR across all industries, and it extends to be an extremely powerful & effective retailing tool. Through, creativity, growth, and endless potential, the VR healthcare market is booming, with analysts predicting a $3 billion valuation by 2023.5. Virtual Reality DiagnosticsVR is being used as a compelling diagnostic device, which aids doctors and physicians to carry out a proper diagnosis. This is done through methods, such as MRI/CT scans, and eradicates the need for any kind of invasive methods, making it a pain-free experience for the patient. In the coming years, VR will be used more and more to improve the accuracy & effectiveness of current procedures and enhance the capabilities of the human being, both as the caregiver and the patient.Healthcare companies are frequently making use of VR in the examination, treatment, and other training purposes. This drift is only anticipated to get more benefits with newer technologies and faster Internet speeds.Very frankly, the potential for VR in the healthcare sector is immense, bound only by the creativity & imagination of those creating and stamping the technology.For more similar solutions specific to your industry visit www.mrarvr.inor contact us at ashutosh@mrarvr.inLiked the content, Don’t forget to give us your👏More similar content:VR AR MR𝗧𝗵𝗲 𝗣𝗿𝗼𝗺𝗶𝘀𝗶𝗻𝗴 𝗔𝗽𝗽𝗹𝗶𝗰𝗮𝘁𝗶𝗼𝗻𝘀 𝗼𝗳 𝗩𝗥 𝗜𝗻 𝗛𝗲𝗮𝗹𝘁𝗵𝗰𝗮𝗿𝗲www.linkedin.comVR AR MRAugmented Reality in Healthcarewww.facebook.comWritten byVR | AR | MRVR | AR | MR is the world’s fastest-growing Virtual Reality and Augmented Reality Company.Follow71 71 71 Virtual RealityVRHealthcareHealthTechnologyMore from VR | AR | MRFollowVR | AR | MR is the world’s fastest-growing Virtual Reality and Augmented Reality Company.AboutHelpLegalGet the Medium app"
The Art of Redirected Walking in Virtual Reality,https://medium.com/the-innovation/the-art-of-redirected-walking-in-virtual-reality-9ca6fee1ffe1?source=tag_archive---------1-----------------------,"VR,Virtual Reality,Gaming,Startup","Source: Langbehn et al.“With appropriate programming such a display could literally be the Wonderland into which Alice walked.“ — Sutherland, 1962In this quote from the 1962’s essay “The Ultimate Display”, Ivan Sutherland predicts the current VR developments. He even goes a little further and tells us that he envisions a programmed room where you can sit on virtual chairs and virtual bullets “are fatal” — but let’s focus on the walking-part for a moment.Sutherland was a pioneer of computer graphics. In his PhD thesis, which he wrote in 1963 at the MIT, he developed Sketchpad — widely seen as one of the first interactive graphic user interface. Not only this, he also envisioned and developed the first virtual reality system which looks straight out of a 90’s grunge music video. Nevertheless, he made an interesting comparison: he used 1865’s “Alice in Wonderland” by Lewis Carroll. The story about a girl who walked into the rabbit hole. A metaphor widely used, also by The Matrix, where Trinity tells Neo to follow the white rabbit. Wonderland as a metaphor for a fantastic world, where anything can happen.Locomotion is one of the big achievements of this fantastic world called VR. It makes it stand out from other experiences like 360° (images, movies et.). It is also one of the most problematic issues with VR — at least with current methods of locomotion. If you have ever put on a headset and experienced VR, chances are that you moved through a) teleportation or b) by using a joystick on a gamepad.Both methods have their problems. The movement via gamepad is a direct trigger for motion sickness because your eyes tell you that you are moving, but your body tells you: “No movement detected”. This is what causes sickness, dizziness etc. A great deal of the population has these problems. And it immediately ruins the experience (at least for some).Moving through teleportation does not cause motion sickness, but it too, has issues. If the creator of VR experience intends the user to go through a dark spooky hallway, she wants him to be scared. If she can just teleport to the end of the hallway, the effect is gone. It also often comes with effects like a loss of presence and orientation. You need a moment to reorient yourself. Time that’s spent not on the game while IN the game is bad.The best (and most natural) way of moving is by using our own legs. And luckily, this is possible — either through external sensors with infrared or inside-out-tracking via camera. But the biggest limitation until now is the actual physical tracking space. If you are experiencing a VR game in your 4x4 m living room, the available space for moving through the virtual environment is simply 4 m x 4 m = 16 sqm. That’s without any furniture etc.So how do we solve the problem of the room limiting the virtual experience?Redirected Walking (RDW) is a collective term for several techniques and algorithms that are being developed — mostly in a scientific environment — to solve this problem. To enable natural walking as the primary way of locomotion, without the limitations of the available physical tracking space. This is achieved by slightly manipulating the virtual environment around the player — without the player noticing it. Like increasing a rotation by 1.5: So when the player does a physical 5° rotation in the real life, the virtual environment does a 7,5° rotation. This can be used to “guide” the player in a certain direction while walking into a different direction in real life.The possibilities of Redirected Walking: turn 15 sqm tracking space into a 80 sqm virtual environment.In its most extreme way, the virtual environment would guide the player in a circle, but in the virtual environment the user would have the impression that he could walk in a straight line. To reach this with the current state of the art technology, a tracking area of ~40 sqm would be necessary. But we at Curvature Games do reach an 80 sqm virtual environment with just 15 sqm of tracking space — see image above. That’s a factor of more than 5!This, in turn, helps us solve a lot of different problems:Increased accessibility: the user does not have to learn how to use a gamepad or any other mechanics for locomotion. This decreases the “preparation time” drastically.Significantly less motion sickness, by avoiding unnatural movements or “conflicts” between visual and sense of balance by only using natural walking.The possibility of larger & more complex virtual room experience with …less physical space needed (which means more customers per space-unit for e.g. VR arcades) etc.Now add hand-tracking to this — what we are doing in our games — and you don’t need to learn any controls at all. All actions (moving, taking, pushing, moving, pulling etc.) can be done intuitively — especially for non gamers, just with your hands and feet. By using RDW, we can create better, more immersive virtual experiences which really extend the reality.Visit www.curvaturegames.com for more information about us, our team and our projects.The InnovationA place for variety of stories from different backgroundsFollowSign up for The Innovation DigestBy The InnovationOfficial newsletter of The Innovation Take a lookGet this newsletterBy signing up, you will create a Medium account if you don’t already have one. Review our Privacy Policy for more information about our privacy practices.Check your inboxMedium sent you an email at  to complete your subscription.VRVirtual RealityGamingStartupWritten byDennis BriddigkeitFollowCurios digital native by day, something else by night. I’m the Managing Director of the VR Startup Curvature Games from the heart of Hamburg.FollowThe InnovationFollowA place for a variety of stories from different backgroundsFollowWritten byDennis BriddigkeitFollowCurios digital native by day, something else by night. I’m the Managing Director of the VR Startup Curvature Games from the heart of Hamburg.The InnovationFollowA place for a variety of stories from different backgroundsMore From MediumThe Ultimate Farming Tool Is DataFelix Ingla in DataSeriesFrom Opera to Dance: Virtual Cultural Events to Keep You Occupied at HomePCMag in PC MagazineApple needs to stop kids from getting hooked on phonesCNNBipedal Robot Navigates the FuturePenn Engineering in Penn EngineeringThese 3 Computing Technologies Will Beat Moore’s LawForbes in ForbesAlcatel Go Flip 3: The Flip Phone You Never Knew You WantedPCMag in PC MagazineThis Chinese ‘Alexa’ Is a Singing, Holographic Anime GirlPCMag in PC MagazineTop AI Researchers Race to Detect ‘Deepfake’ Videos: ‘We Are Outgunned’Washington Post in The Washington PostLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
How do you listen to the Audio ?,https://medium.com/@srighatam/how-do-you-listen-to-the-audio-8fb86a53f870?source=tag_archive---------2-----------------------,"Audio,Audio Formats,Ambisonics,VR,Music","Free images from Pixabay.comWhen you ask me how I listen to the audio now, especially after completing my Masters in Music Technology, I would say I don't listen to them, rather I “Feel” them.There is a lot of intricate information in a single audio file. It is a vast subject to talk and discuss about. But, i am going to focus only on the time-based domain of the audio files here.The Audio can be recorded in multiple ways and played back in multiple ways. we are consuming audio via different devices such as headphones, mobile phone speakers, desktop speakers, car speakers, home theaters and many. Both the input and output source decides the type of audio that you will listen as an end product.The different formats of Audio Recording can be classified into:1. MonoThe Mono audio is the most basic format, used widely for recording via single channel. (Mono = One) So when you listen, whatever you hear in the right ear, you will hear the same in the left ear without any difference. A same single audio file is played back in both the speakers or earbuds.2. StereoA Stereo audio is basically 2 mono audios played back in both the ears with a change in the audio’s properties. The left and right audio can have temporal, timbre, and frequency differences, thereby making it 2 different audio sources. You can localize the audio to the left or right (X-axis). For example, a Stereo mix can have the guitars on the left ear and drums on the right ear completely.3. Surround sound ( 2.1 ,5.1, 7.1, and so on…)This is very interesting to observe and feel because it is more of a playback or listening experience than recording. The mix engineer basically uses mono or stereo audio files and creates a surround mix for 2.1, 5.1, and so on. The home theaters or movie theaters with several receiver speakers placed around gets the audio data digitally distributed for playback. ( DTS, Dolby digital are the inventors of this technology and algorithm)4. BinauralThis, for me is even more interesting and i like how it works! The audio is captured to the way how we hear naturally. To break it into simpler terms, You use binaural microphones( 2 microphones placed at the ear position) to capture the sound source at the exact location in relation to the person who is capturing it. So while listening to the binaural audio, it will feel like you are in the position of the recordist hearing the sounds at that moment.5. 3D ( 360 Audio)This is the most latest format that people have been researching and working on with constant improvements. All the Virtual reality softwares use 3D audio technology where the sound moves along with the video when they explore. The 3D audio can be produced in many ways where you can use computer softwares to place the sound virtually in the environment( primarily for Games and VR animations) so when the user moves to the environment virtually, they can experience the sound as well. For live experiences, ambisonic microphones are used which records audio in all the possible axis and later stitched to the VR videos, which gives the user a natural experience of being in that space where the sound moves along with the virutal environment.Thank you very much for reading! This is my first ever blog in life! I never imagined I would write one. But I am glad I started with something that I love exploring!Keep listening!Written bySrikrishnan SridharanMusic and Audio Technologist | Percussionist | EngineerFollow13 13 13 AudioAudio FormatsAmbisonicsVRMusicMore from Srikrishnan SridharanFollowMusic and Audio Technologist | Percussionist | EngineerMore From MediumIf the Feds Don’t Act, Expect More Autonomous-Car AccidentsPCMag in PC MagazineNew lift technology is reshaping citiesThe EconomistHow Silicon Valley’s Whiz-Kids Finally Ran out of FriendsThe Guardian in The GuardianThe Tesla Tabless Electrode Battery BreakthroughVince Tabora in 0xMachinaSmart Dust, Utility Fog & Virtual People: The Future Of Programmable MatterTim Ventura in The StartupEverything about Self Driving Cars Explained for Non-EngineersAman Y. Agarwal in The StartupStudy: Your Smartphone Can Detect Your Drunkenness With 90 Percent AccuracyPCMag in PC Magazine‘Total Chaos’: How Trump’s Washington Is Killing the Next Generation of TechFast Company in Fast CompanyAboutHelpLegalGet the Medium app"
Digital changes,https://medium.com/modihost/digital-changes-da1cc1065fb6?source=tag_archive---------3-----------------------,"Blockchain,Cryptocurrency,Hospitality,Hotel,VR","Traditional tourist attractions, sightseeing, for example, are transforming as well. Tourism becomes digital. Adobe Digital Insights (ADI) analyzed 321 million social engagements and found out 8 out of the 10 largest hotels have tested some VR experience.Developers paired VR devices with consumers’ mobile devices. Virtual entertainment is becoming the most critical part of the program. Moreover, the number of hotels that offer some AR/VR-related experiences have increased by 13% last year.For example, customers scan a map, chose a place of interest and join an online tour there via VR.Gamification elements make it possible for the tourists to make a location part of a famous game. Furthermore, these technologies help to improve service quality.Hilton Hotels Garden Inns implemented a game into employees’ training. They used AR to simulate routine situations to test how employees interact with customers.They then received ratings based on the game’s results as well as customer reviews. It helped to improve service quality, which was also rated by guests.modihostThe Next Step in Evolution of the Hospitality IndustryFollowBlockchainCryptocurrencyHospitalityHotelVRWritten byModiHostFollowThe Next Step in Evolution of the Hospitality Industry. https://modihost.io/FollowmodihostFollowThe Next Step in Evolution of the Hospitality IndustryFollowWritten byModiHostFollowThe Next Step in Evolution of the Hospitality Industry. https://modihost.io/modihostFollowThe Next Step in Evolution of the Hospitality IndustryMore From MediumShould we fear facial recognition?Christopher Koopman in The BenchmarkSmart mobility starts with the cityAfter the floodHow Misty Plans To Build The Most Personable, Programmable Robot EverFast Company in Fast CompanyU.S. Internet Continues to Show Strength Through COVID-19 Stress TestBrendan CarrTechnology in the Classroom: 6 Ways to Get the Balance Rightsmithwillas in HackerNoon.comHow Apple Could Integrate Augmented Reality into FaceTime, but Not YetWill Murphy, MBA in Data Driven InvestorDuckDuckGo, EFF, and Others Just Launched Privacy Settings for the Whole InternetFast Company in Fast CompanyComing in 2020, a Dyson Electric CarMIT Technology ReviewLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Echo VR — Quest Launch,https://medium.com/echo-games-blog/echo-vr-quest-launch-c67f506066cc?source=tag_archive---------0-----------------------,"Echo Vr,Ready At Dawn,Game Development,VR,Community","Highlights: Echo VR on Quest launch, launch rewards, new social tools and features to address toxicity and harassment, bug fixes, and more!Summary· Social Lobbies· Social Lobby Best Practices· Types of Social Lobbies· Social Tools· Social Features· Other Features· Echo VR Resources· Known Issues· Bug FixesEcho VR on Quest LaunchIn March we began Community Testing for Echo VR on Quest, and today we’re excited to announce Echo VR on Quest has now officially launched!We wanted to take a moment to thank you all for working with us during testing. The information on bugs and feedback was helpful, and helped us improve Echo VR so that it is fun and comfortable for all Echo Units.To celebrate launch, we’ll be hosting a special Launch Event!Echo Units that complete one match of either Echo Arena or Echo Combat between today August 27th 10:30AM PST / 17:30 UTC and September 3rd 10:30AM PST / 17:30 UTC will earn a new badge, emote, and decal. (Echo Combat matches are for Rift or Quest + Link players only.)Share pictures of your customized Echo Chassis with us by tagging us on Instagram, Facebook, or Twitter.Over the past couple of months, our team has been hard at work creating new social tools to ensure players have a comfortable experience in Echo VR, can more easily make friends in-game, and are able to quickly access tools in the event they encounter a toxic player.   As mentioned in our previous social tools blog, our team is still working closely with Oculus to create an integrated, in-game reporting system specifically for Echo VR.   Oculus also has a reporting feature that can be used while in your headset and is always available when needed. More information on how to use this reporting system from your Rift or Quest headset can be found here.  All reports should be sent to both our Ready At Dawn Account Admin Team (report@echo.games) and Oculus (via the headset reporting tool) for review.Social LobbiesPreviously referred to as “moderated groups”, Echo VR Social Lobbies are a unique way for players to connect with other like-minded individuals in-game. When viewing the Main Menu on boot, players can choose which Social Lobby they’d like to opt in to. Joining a Social Lobby only affects who you socialize with and matchmaking is unchanged. For example, this means if you choose to socialize with someone in Casual Mature Gamers you can still be matched up with players from the Echo Combat group.Social Lobbies are moderated by Community Moderators who have each established their own list of community rules as well as to the Echo VR Code of Conduct.  Community Moderators have the ability to kick or ban players from Social Lobbies in the event a player violates their rules. If you are kicked or banned from a Social Lobby, you will need to contact the Community Moderators to appeal it.  All Community Moderators must adhere to a Moderator Code of Conduct, as well as the Echo VR Code of Conduct, and if a Moderator fails to do so, we will remove their Echo VR moderator access. The Moderator Code of Conduct is as follows:1. Mods will follow the Echo VR Code of Conduct.No sexually explicit actions or commentsNo sexist, racist, or discriminatory behavior,No harassing, bullying, or threatening othersNo hacking or cheatingNo unsportsmanlike conduct or trollingNo promoting real-world violence or illegal activityNo impersonating Ready At Dawn or Oculus employees2. Mods will remain impartial and moderate based on violations that occur (no favorites, picking on people you don’t like, etc).3. Mod usernames and group names must be appropriate and adhere to the Code of Conduct (not sexually explicit, discriminatory, etc).4. Mods won’t troll or flame other players.5. Mods won’t make false claims against players or other mods.6. Mods won’t abuse their power to harass, stalk, intimidate, etc. other mods or players.Social Lobby Best PracticesHere is a list of Social Lobbies players can choose to join. As mentioned above, these Lobbies enable you to choose your social experience in-game, however gameplay matchmaking is the same. To have the best experience possible, we recommend:· Making friends with other players in your Social Lobby.· Play together with your friends in private matches.· Cue up as a group for public matches.Types of Social LobbiesPlaygroundThis group is for the classic Echo VR Lobby you’re familiar with, welcoming players of all types. Players can meet up with friends, find new players to team up with, or discuss upcoming Echo VR events in an environment open to everyone.**Please note, this is the current Echo VR Lobby you are familiar with and is moderated by our Echo Games Account Admin Team, not Community Moderators.Competitive Gamers Whether you’re looking for a Social Lobby to talk about the game’s meta or interested in highly competitive matches, this is the group for you. Players captivated by competitive play and looking to improve their skills, learn new ones, or participate in community tournaments are welcome to join.Casual Mature GamersLooking to escape some of the noise or mischief of the Playground Social Lobby? This group is for you. Casual mature gamers can socialize in the Lobby with other players looking to unwind after a long day, or find friends to party up with.Echo Combat Players (Rift or Quest+ Link Players Only)We’ve heard from the Echo Combat community, as well as the new Echo Combat Flamingo League, and to help support the community we’ve created an Echo Combat Social Lobby. Combat players can compete in the Echo Combat Skirmish Zone or test out gear while matchmaking in the Training Area, discuss the current meta or preferred load out for certain maps, and meet up with other players to form teams for matches or competitive play. All Echo Combat Units on Rift, or on the Quest using the Link and a compatible gaming PC, are welcome to join this group.Looking to start a Social Lobby?Players looking to start their own Social Lobby can submit an application here.Please note, all Social Lobbies must adhere to the Echo VR Code of Conduct.Criteria for creating a new Social Lobby are as follows:Social Group must have at least 100 active members.Social Group must be at least 3 months old.You must provide us with a link to the space where your Social Group is active (Discord, Facebook, etc.)You must let us know who your Admins and Moderators are.You must let us know the title of your new Social Lobby.You must provide us with a set of rules for your new Social Lobby.You must provide us with a description of your new Social Lobby.If your application is accepted, our team will contact you to begin the process. More information on our application process will be provided in the future.Social ToolsWe’ve expanded the social tools available in-game to help you feel comfortable in Echo VR.Have feedback on any of these features? Let us know what you think by filling out our Feedback Form here.Customize your experience on first bootPlayers will now be prompted to customize their social experience the first time they boot the game to ensure comfortability during their early moments in zero-g.Changing LobbiesLooking for a quieter Lobby or different crowd? Players can now choose to move into a New Lobby via the In-Game Menu Options.Social Control PanelA new social control panel has been added to the Arm Computer. When clicking on a player’s name in the Arm Computer, a new panel will appear with options to mute, ghost, party, or friend that player. Currently this feature is only available on Oculus Quest.Persistent Comfort & SafetyGhosting and Muting will now persist until removed by a player. This means if you decide to ghost or mute someone in the Lobby and encounter them in a match, or reverse, they will remain ghosted or muted until you remove it.Personal BubblePlayers can now set a personal bubble to give themselves the space they need to feel comfortable in zero-g. In the Menu players can adjust the distance their personal bubble spans, and if another player enters their personal bubble they will fade away. Currently Personal Bubbles are only available in the Lobby.Easier access to Ghosting/MutingPlayers now have easier access to Lobby social controls on the new Arm Computer Home tab.Change Voice PitchThis social tool gives Echo Units the ability to deepen the pitch of their voice in the Echo VR Settings Menu.Mute Enemy TeamMatched against a team that’s too loud or rude? Players can now choose to mute the enemy team during a match.New In-Game Menu OptionsPlayers now have new in-game options to quit an activity by hitting the “Menu” button on your controller. Players can now see their Server IP via the In-Game Menu Options.· In Echo Arena, players can choose to Quit to Lobby, Quit to the Main Menu, or Quit Game.· In Echo Combat, players can choose to Quit to Lobby, Quit to the Main Menu, or Quit Game.· In the Lobby, players can choose to Quit to Main Menu or Quit Game.Social FeaturesNew social features in-game help you connect and party up with friends in Echo VR.Have feedback on any of these features? Let us know what you think by filling out our Feedback Form here.Rich PresenceThis feature will now show you where players are in-game. See a friend is online playing Echo Arena? Send them an invite to party up together. 😊In-Game Partying/FriendingPlayers can now party up with other players, that aren’t on their Friend’s List, in their Arm Computer. Additionally, players can now add Oculus friends via their Arm Computer too.*Please note: Due to platform limitations, this is only possible on Quest at the moment.Other FeaturesNetwork IconsIcons on your HUD will now be visible indicating your current connection status. Players can choose to turn on this feature via the in-game Settings.Echo VR ResourcesRun into a bug or have a question? Check out our resources down below.· Find a bug or need technical support? Talk to our Devs in the #quest_bugs channel of the community Echo Games Discord or let our team know in our Bug Reporting Form here.· Learn how to send in reports for Code of Conduct violations and in-game toxicity to our Account Admin Team and Oculus here.· Need some help? View our Echo VR FAQ for technical support or browse the #faq channel of the community Echo Games Discord.· Join the Community and learn more about community events (leagues, cups, Pick Up Nights, bootcamps, etc) in the Echo Games Discord here.Known IssuesGeneralQuest/ RiftA timeout occurs when attempting to join a lobby after opting to enter “The Playground” from a moderated lobby group rules pop-up message and selecting the “Back” button during the transition.The VO “Matchmaking Failed” plays when the player cancels their matchmaking search.The matchmaking status bar remains visible after canceling a search, closing then reopening the Arm Computer.The Arm Computer will become temporarily locked in place if held by the main screen and side tab at the same time with one hand letting go while the other continues to grip it.The Personal Bubble feature functionality does not refresh for player’s either added or removed as a friend until the Arm Computer is closed and reopened.HUD warning sign icon for an unstable ping does not persist with a consistent unstable connectionArt for the ‘Purchase’ button on the Echo Combat billboard on the main menu is corrupt.The Arm Computer will become blank when quickly entering and exiting a player’s stats page from the Friends tab.The list of players on the Friends tab will become temporarily locked when opening a player stats page, closing and then reopening the Arm Computer.QuestA crash occurs when closing and then quickly relaunching the application.The “Social Tab” on the side of the Arm Computer shakes when players move themselves using level geometry.Quest players will not be able to access Social Lobby links unless their Quest browser is set to “Desktop View”.Workaround for this issue:Open the Quest Browser and in the top right corner click the 3 dots. This should automatically toggle on “Desktop View” and allow you to access Social Lobby links.TutorialsQuest/RiftMultiple holo projectors are visible for the highlighted terminal in the Lobby Tutorial.LobbyQuestFigurines for the Arena mini-map team colors are incorrect.CombatRiftSpectator HUD elements are blue instead of the intended neutral color.Bug FixesGeneralQuest/RiftFixed an issue where party invitation notifications would not appear correctly on the Main Menu.Fixed an issue where the Arm Computer’s orientation would not match the player’s orientation.Fixed a consistency issue with the color of the Social Control button for the Arm Computer across multiple tabs.Fixed multiple text issues on the Main Menu.Fixed an issue allowing players to halt their momentum using the Arm Computer.RiftFixed an issue where certain HUD elements would have inconsistent colors between Arena and Combat UI.Fixed an issue where the Arm Computer could be opened while in the Oculus Dashboard.Fixed an issue where certain HUD elements would appear inconsistently when toggled by using the F8 hotkey.Fixed an issue with the Legal button on the Main Menu becoming inaccessible after an interruption in internet connection.Fixed a crash that would occur when attempting to enter the Lobby after interacting with the Discord link while transitioning into a match.QuestFixed inconsistent lighting between the eyes of the Combat chassis.TutorialsQuest/RiftFixed an issue where certain HUD elements would conflict with background graphical elements.Fixed an issue where the “Pitch” and “Roll” stick options were automatically enabled for the Intro tutorials.LobbyQuest/RiftFixed an inconsistency with the Customization Room poster.Fixed the “Matchmaking” label not appearing on nameplates when a player joins the Lobby after another has started searching for a match.QuestFixed miscellaneous graphical issues throughout the Lobby.VS AIQuest/RiftFixed an issue where an elongated name of a bot would be cut-off on the goal barrier for a score assist.Fixed an issue where the experience counter in the Arm Computer would not animate at the end of an AI Teammates match.ArenaRiftFixed an issue where a 3D Spectator’s HUD and Arm Computer would be visible to them when in 2D Spectator mode.CombatRiftAddressed an issue where the cooldown UI for Instant Repair and Arc Mine didn’t match the HUD UI.FissionFixed miscellaneous graphical issues throughout the map.SurgeFixed an issue where the door at the first checkpoint would not open after restarting a private match under certain circumstances.Echo Games: Official Mission LogsThe official development blog for Ready At Dawn’s Oculus VR…Follow66 1 Echo VrReady At DawnGame DevelopmentVRCommunity66 claps66 claps1 responseWritten byEcho GamesFollowLone Echo and Echo VR are Ready At Dawn's line up of virtual reality games featuring zero-gravity movement & full body presence.FollowEcho Games: Official Mission LogsFollowThe official development blog for Ready At Dawn’s Oculus VR games: Lone Echo and Echo VR (Echo Arena and Echo Combat)FollowWritten byEcho GamesFollowLone Echo and Echo VR are Ready At Dawn's line up of virtual reality games featuring zero-gravity movement & full body presence.Echo Games: Official Mission LogsFollowThe official development blog for Ready At Dawn’s Oculus VR games: Lone Echo and Echo VR (Echo Arena and Echo Combat)More From MediumAn introduction and the history of Video Game GraphicsNiall Walker (Theferrariguy5)Live Esports Events Are A Game-Changer For FansIndy Gaming LeagueLevel Progression and Pacing in Puzzle GamesMichael DeLallyDoes Killing My Sims Make Me a Bad Person?Tessa Andrews in SUPERJUMPFirst Impressions of Valorant from a Console GamerJ. King in Casual RamblingReview: PowerA Wireless Controller for Nintendo Switch — GameCube StyleMatthew GoldenAn Octane Guide: Strengths, Weaknesses, and Tips for Optimal PlayChadlantisOvercooked: How Design Creates TeamworkAbhishek Iyer in SUPERJUMPLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
VRChat Spookality 2020,https://medium.com/vrchat/vrchat-spookality-2020-766376560a8?source=tag_archive---------1-----------------------,"Vrchat,VR,Virtual Reality,Halloween","Trapped inside this Halloween? Every haunted house you usually go to shut down? Every porch light down the street turned off? Fear not! Turn off the lights, close your door, and embrace the unknown with VRChat Spookality 2020.While everyday feels like Halloween at VRChat, Spookality is a special time of year where our creator community showcase their fun, strange, and horrifying worlds and avatars.Bigger Prizes!This year’s prizes are bigger and better! The categories and prizes are:Best World (PC) —1x Valve Index VR KitBest World (Cross-Platform) — 1x Oculus Quest or 3x Vive TrackersBest Avatar (PC) — 1x Valve Index VR KitBest Avatar (Cross-Platform) — 1x Oculus Quest or 3x Vive TrackersImage of OCU-QST and VAL-NDX memetic occlusion hardware, along with three HTC-TRK spatial orientation devices.For each of these categories, you can submit using our submission form. Ensure that you read up on our Terms and Conditions for the contest before submitting! These are available at the Spookality website. Violating these Terms (or the Terms of Service / Community Guidelines of VRChat) will result in disqualification.Submissions to the PC categories may contain assets solely for PC. Submissions to Cross-Platform categories must contain assets for both PC and Quest usage, and should function when players from both platforms are present.In addition, all content submitted must employ the latest VRChat SDK3 appropriate for the content submitted. Worlds must use VRCSDK3 for Worlds, and avatars must use VRCSDK3 for Avatars. Use of advanced Udon or Avatars 3.0 features is recommended, but not required. Both versions of the VRCSDK3 are available for download on our website. If you want to learn how to use VRCSDK3, check out our documentation for the core systems in VRCSDK3-Worlds and VRCSDK3-Avatars.Submissions will be accepted starting on August 25th, 2020 and will end on October 23rd, 2020 at 12pm PT. All submissions must consist entirely of original assets and the submitter must own full rights to the content (and all components of the content) submitted.More Prizes!Each category will have 2x runners-up who will receive:1x “Troll” Ceramic Mug and 1x $25 Threadless Gift CardImage still taken from experiment 02–17.In addition to their main prizes, all category winners will also receive one limited-edition “Troll Mug”.Please be advised, specific containment procedures will be included with the VRC-009 shipment and must be followed. Failure to do so will likely result in breach. Recontainment is… difficult.The submissions will be ranked by a spooky mystery panel of judges. The winners of the contest will be announced on or about November 9th, 2020, and will be announced via a post on our blog.In addition, if you want to feature your Spookality-themed world, you can do so with a custom World row we’ll be adding soon! Simply add the tag “halloween” to your world, and it will appear in the World menu. You’ll also see Halloween worlds from previous years appear in this row. If you’d like to show off your Spookality-themed avatars, feel free to put them into an avatar world (tagged with “avatar”) and throw on the “halloween” tag as well.The administration looks forward to your submissions to Spookality 2020. We will observe your progress with great anticipation.Item Number: VRC-009 — Object Class: Ceramic — Special Containment Procedures: [REDACTED]Quick Links:Spookality 2020 Website with Terms and ConditionsSubmission FormVRChat Community GuidelinesVRChat Terms of ServiceVRChatWelcome to the VRChat Universe.Follow10 VrchatVRVirtual RealityHalloween10 claps10 clapsWritten byVRPillFollowFollowVRChatFollowWelcome to the VRChat Universe.FollowWritten byVRPillFollowVRChatFollowWelcome to the VRChat Universe.More From MediumLambda Authorizers to the RescueNick Basinger in The StartupPython Progress Bars with Tqdm by ExampleTimothy Mugayi in Better ProgrammingHow I Built A COVID-19 Fever Detection System Using CNNsAaryan Harshith in Data Driven InvestorEnvironments in Software DevelopmentSteven Curtis in The StartupWhat is `transparent` in Scala?Mark ""Justin"" WaksChoosing Right Partition Count & Replication Factor (Apache Kafka)Ram Gopal Varma Alluri in The StartupSpring Boot Microservices — Developing Service DiscoveryLal Verma in An Idea (by Ingenious Piece)A Conceptual Overview of KubernetesJean-Pascal MEWENEMESSE in Better ProgrammingLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
How To Use the ARLOOPA App: A Step-by-Step Guide (2020),https://arvrjourney.com/how-to-use-the-arloopa-app-a-step-by-step-guide-2020-be2f96b9d4e9?source=tag_archive---------2-----------------------,"Augmented Reality,Tutorial,AR,Virtual Reality,VR","Launching its AR Studio earlier this year, ARLOOPA made creating and having Augmented Reality experiences so much easier.Read also: How to make AR experiences in the ARLOOPA StudioAll the content activated in the ARLOOPA Studio is visualized by the ARLOOPA App, which is an intuitive platform designed to help you easily experience augmented reality for educational, promotional, entertainment or personal needs.However, if you’ve never used ARLOOPA or another AR app before, understanding how to use it might be a bit challenging!But don’t worry.This article is a step-by-step guide to help you get started with the ARLOOPA app quickly. I’ll also cover the tool’s key features to help you and your brand make the best use of it.What Is ARLOOPA?The ARLOOPA app is an AR visualization tool that brings the physical and digital worlds together as one.It places virtual content into your real environment through your device’s camera, creating fantastic, interactive and valuable experiences.Trending AR VR Articles:1. How to use subtle AR filters to survive your Zoom meetings?2. The First No-Headset Virtual Monitor3. Augmented reality (AR) is the future of Restaurant Menu?4. Creating remote MR productionsThe app is especially popular due to the value it adds to remote education for students from around the world.ARLOOPA’s key features include:Marker-based, markerless and location-based ARVideo, photo, GIF recordingSocial sharingIn-app 3D objects library with diverse categories, such as animals, vehicles, educational objects, etc.How to Use the ARLOOPA App (Step-by-Step Guide)ARLOOPA makes it super easy for anyone to experience virtual objects in their real space — but if you’ve never used the tool before, this can still be tricky.To help you out, here’s a step-by-step guide to using the ARLOOPA App the right way.I’ll cover the steps for experiencing:Marker-based ARMarkerless ARLocation-based ARGetting started with ARLOOPAStep 1: Download the ARLOOPA iOS or Android app from the App Store/Play Store.Step 2: Sign up or sign in to ARLOOPA by following the on-screen instructions.Note: The first 100 experiences can be viewed without signing in.Starting a Marker-based AR ExperienceUse the marker-based AR option if you’ve activated your own marker in the ARLOOPA Studio and have it at hand or head to the ARLOOPA website to get some sample markers.Step 1: Open the ARLOOPA app and tap on the scanner icon to open the scanner.Step 2: Hold your device’s camera up on the marker and wait till it recognizes the marker. You’ll see a red loading circle with percentages. Once it reaches 100%, your experience will start.Step 3: Once you see digital content on your marker, you can go ahead and tap on the pin icon at the upper corner of the app. This will pin the digital content to the screen so that you can move the device away from the marker and the content will stay there.Starting a Markerless AR ExperienceThis is probably the easiest way to experience AR with the ARLOOPA app.Step 1: Open the ARLOOPA app and you will see a range of categories. This is the 3D models library.Step 2: Choose a category by tapping on it. Next you’ll see different 3D models. Tap on one to choose it.Step 3: Point your device’s camera to the floor or another flat surface to recognize it. The 3D model you chose will now appear in front of you!Starting a Location-based AR ExperienceYou can create your own location-based AR experience in the ARLOOPA Studio (learn how) or you can look to see if there is already an AR activation near you.Note: Location-based AR experiences can only be viewed when you are physically present at the particular location.Before getting started, make sure that the location services (GPS) are turned on on your device.Step 1: Open the ARLOOPA app and tap on the Map icon.Step 2: Use your fingers to zoom in and find red pins like in the picture.The pins that have the ARLOOPA logo on them are active for you to be viewed. Those that don’t are the ones that cannot be viewed due to their distance from where you are located.Step 3: Tap on a red pin with the ARLOOPA icon. A pop up will open above it showing its name. Tap on the name of the pin.The hidden digital content will now appear in front of you!Taking photos, videos and GIFs and sharing onlineStep 1: During any AR experience, tap the drop-up menu at the bottom center of the screen. The hidden menu will be revealed.Step 2: Tap on the photo, video or GIF icon to capture your AR experience. The media will be saved on your device’s galley with a folder called ARLOOPA unless you choose to discard it.Step 3: Use the Share icon on the upper right corner of the screen to share your maker in case of a marker-based experience or a link to the 3D model in case of a markerless experience.ConclusionMost people have struggled to find an easy all-in-one AR visualization tool that would be free to use. ARLOOPA can be the tool to cater to all your needs for experiencing augmented reality content.Just follow the instructions in this ARLOOPA app guide and you’re all set to experience engaging and useful AR scenarios, share with friends and followers or enrich your TikTok videos with virtual content!Don’t forget to give us your 👏 !AR/VR Journey: Augmented & Virtual Reality MagazineBest place to learn about AR& VR.Follow206 Augmented RealityTutorialARVirtual RealityVR206 claps206 clapsWritten byNar PoghosFollowFascinated about immersive tech, AR/VR, humanism, and writing. Contact for freelance writing. Website: thecopystory.comFollowAR/VR Journey: Augmented & Virtual Reality MagazineFollowBest place to learn about AR& VR. We share the latest AR/VR News, Info, Tools, Tutorials, ARkit, ARcore, & More.FollowWritten byNar PoghosFollowFascinated about immersive tech, AR/VR, humanism, and writing. Contact for freelance writing. Website: thecopystory.comAR/VR Journey: Augmented & Virtual Reality MagazineFollowBest place to learn about AR& VR. We share the latest AR/VR News, Info, Tools, Tutorials, ARkit, ARcore, & More.More From MediumInfographic: The Future of Virtual RealityAlice Bonasio in AR/VR Journey: Augmented & Virtual Reality MagazineReality Check: The marvel of computer vision technology in today’s camera-based AR systemsAlex Chuang in AR/VR Journey: Augmented & Virtual Reality MagazineDead or Alive: What is going on with the Virtual Reality Industry?Andrew Julian in AR/VR Journey: Augmented & Virtual Reality MagazineHow can augmented reality be used in education?Arcitux in AR/VR Journey: Augmented & Virtual Reality MagazineNiantic’s strategy in augmented reality — Pikachus are just the beginningSteph Rhee in AR/VR Journey: Augmented & Virtual Reality MagazineExpert View: 3 ways VR is transforming Learning & DevelopmentAlice Bonasio in AR/VR Journey: Augmented & Virtual Reality MagazineXR and the Self-Inflicted Trough of DisillusionmentJason Pace in AR/VR Journey: Augmented & Virtual Reality MagazineVR and AR in the Mobile WebNiño Ross Rodriguez in AR/VR Journey: Augmented & Virtual Reality MagazineLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Beat Saber & the Future of Custom Songs,https://medium.com/@idolize/beat-saber-the-future-of-custom-songs-d64756818be7?source=tag_archive---------3-----------------------,"Beat Saber,VR,Piracy,Music,Software Development","Why is piracy a requirement to enjoy your own music library in a video game like Beat Saber?Custom Songs and Unofficial Expansions(If you are already familiar with Beat Saber and song mapping you can skip this section)Beat Saber is a popular VR rhythm game where players use sabers to slice blocks in rhythm with music. It’s a simple formula that is incredibly fun and deceptively difficult to master.Beat Saber comes with a relatively sparse selection of songs, and six DLC packs (with about one album’s worth of songs each) that players can purchase to add additional tracks to the game. This is a system similar to other rhythm games, like Rock Band or Guitar Hero, before it.DLC for Beat Saber is great — but limited and slow to materializeWhile new songs are indeed coming to Beat Saber via DLC packs: the pace at which new songs are released is slow, and the breadth of music available is generally minimal. This is primarily due to all the process and negotiation required for the game’s developers (Beat Games) to license the music for the game, as well as the amount of effort required to bring the tracks into the game.In order to make a song playable in Beat Saber, a human has to manually time and place the blocks for the player to hit. Things like the number of blocks, the configuration, the timings, etc. are all important to get right (and typically each song has multiple difficulties as well — each with their own unique block-slicing pattern).This process of placing and configuring the blocks that correspond to a specific song in Beat Saber is called “mapping,” and the data generated in the process is referred to as a song “map.”And this brings us to the not officially recognized yet totally massive elephant in the room when it comes to Beat Saber: custom songs and modding.Want to play a specific song in Beat Saber? Maybe one not included in the official releases? There are thousands of unofficial maps for songs that can be added to the game in a single click.These versions are player-created rather than official DLC, but many of these maps are of equal (or in some cases better) quality than the official ones.There is one major issue with these custom maps, however: they are all currently distributed alongside a full copy of the (oftentimes copyrighted) song.And these mappers put a lot of hard work into their maps, spending hours and hours to perfect them. So it’s always a shame to see this potentially taken offline due to a copyright issue.Even Beat Games’ CEO recognizes the craft and love that goes into these custom maps but is quick to point out the copyright ramifications.An example of a custom mapThe Timing Problem and Why It Affects DistributionSo is this just another example of online piracy and folks looking for ways to get something for free instead of paying for it? Not exactly — in fact there are many reasons why this is done this way that have nothing to do with piracy at all.Sure it’s easier to click a link and instantly download a song for free than it is to go to an online store and pay for it (or rip a digital version of the music from a physical copy like a CD), but that’s only one of the smaller hurdles involved when it comes to custom Beat Saber map distribution.My hypothesis is that Beat Saber players would happily pay for the legal rights to many of these custom songs (similar to how many currently pay to listen to songs on Spotify or download legal .mp3/.m4a copies on iTunes or Amazon Music)Unfortunately, this is not currently an option.Shane Monroe wrote a full article about why custom Beat Saber maps historically needed to distribute the entire song file (and thus are oftentimes at-odds with copyright law) here — it is worth a read.To summarize one of the main issues highlighted in Shane’s post:When it comes to buying a song online there are lots of inconsistencies between various renditions and purchase options.There are radio edits, clean vs explicit versions, differences in audio encoding, etc.Plus, mappers very often like to tweak things about the song, such as adding some silence to the beginning of the track so the notes don’t come flying at you the instant you start the song in the game.If a mapper were to distribute just the map data without the song itself:The players attempting to play the map in Beat Saber would need to provide their own audio file (e.g. purchase it from iTunes)Even after providing the audio for the song: they would likely find out that their copy of the song is totally unplayable because it does not match the timings of the map, or the audio is not in the correct format for the game to recognize.Image via bsaber.comThe result? Piracy — but for technical reasons: all the major custom Beat Saber song websites end up delivering the entire song along with the map. They pretend it’s not a problem and resort to (1) ineffective notices warning users to not distribute copyrighted music and (2) DMCA report links in order to reduce liability. Essentially: “ask for forgiveness instead of permission.”More Software: the Solution to EverythingAs a software engineer, I noticed that some of these issues can be automated.Specifically, there are three main things I believe a computer program can do to assist in making legal custom map distribution (without the copyrighted music file) viable:Request a copy of the song from the user — it is up to them how they purchase or rip the song, but it will no longer be provided as part of the map download — and verify the original (“master”) audio file is the same as the one the mapper started with when they made the map (regardless of audio format or bit-rate). This ensures there are no unexpected differences in timing (e.g. radio edit vs explicit versions of the song).Alter the original “master” audio with any changes the mapper wants to make: such as adding silence, fades, trimming, or adjustments to the dynamic range. These changes would have to be represented as external “patches” instead of direct changes to the audio data, which is different from how existing audio edits are made in the current system.Convert the final audio file into a consistent format Beat Saber understands — regardless of what the source file format was.If we can do these things effectively then we can ensure an easy and consistent experience for players, and without sacrificing very many “features” or capabilities for mappers.This isn’t without prescient either: games like DMT, Beat Hazard, and Audiosurf all allow you to synchronize and play games from music on your hard drive.Saber Song PatcherHere is my attempt to solve the above issues:Saber Song Patcher (github.com)https://github.com/idolize/saber-song-patcherAnd here’s how it works:1. VerificationThe song verification process is done via a multi-step set of checks.The first check it does is against a set of known-good SHA-256 file hashes. This lets us know right off the bat if the user is starting with an exact file we have already verified manually — and if so we can 100% guarantee compatibility with the map.If the check fails though: fear not. Our next check is more sophisticated, and it uses a technology known as “audio fingerprinting.” This technology doesn’t just recognize a specific file, but rather the characteristics of the sound waves. It generates a spectrogram of the song that it can compare sounds to (even if they vary in noise, loudness, format, compression, etc.) — you may be familiar with similar technology used in applications like Shazam or even YouTube’s Content ID system.Using this audio fingerprint (as well as some basic sanity checks around audio length), the tool can detect that the song is the same even if it doesn’t match the file hashes! So, users can download their copy from any number of legal sources (Google, Apple, Amazon, etc.) or even rip their own copy in whatever format they want and it should work all the same.Also, the Saber Song Patcher config format has a place for mappers to direct users to specific URLs where they can buy the song.2. PatchingAudio, like any other data, can be modified. How and what modifications to make can be represented as a “patch” that is applied to an original file.While Shane Monroe says he doesn’t believe mappers are willing to go through the effort of breaking down their changes to the master audio into specific patches, I personally think we can represent the majority of audio changes as simple patches without too much additional work.It’s not without some challenges, however.Challenge #1: Any changes to the master audio track must be stored in a manner that is reproducible from only the original audio track, because the end user will need to perform the same exact set of changes in order to be sure the map stays synchronized.Challenge #2: Any changes must also be stored in a patch format that does not itself contain copyrighted data. For example, if a mapper starts with song A and remixes it to include the entirety of another song B, then the “patch” would necessarily need to include all the audio data for song B as well, which is a no-go.So our patches need to only allow (and store data representing) simple changes to the original song (e.g. tweaks in timing), as these changes themselves are not copyrighted.Here’s the compromise I made in the current version of Saber Song Patcher: the mapper provides a single configuration file along with the song. That configuration file that can contain any optional combination of fades, trims, and silence padding as patches, and are written in a simple JSON format:""patches"": {    ""delayStartMs"": 5000,    ""padEndMs"": 5000,    ""trim"": {        ""startMs"": 0,        ""endMs"": 30000    },    ""fadeIn"": { ""startMs"": 0, ""durationMs"": 10000 },    ""fadeOut"": { ""startMs"": 20000, ""durationMs"": 10000 }}I’ve been chatting with some folks on the Beat Saber Modding Group Discord channel about additional types of patches, as well as better and easier ways to generate and test these patches (e.g. an Audacity plugin or GUI tool instead of editing a JSON file by hand).3. ConversionFinally, (thanks to the wonderful ffmpeg project) Saber Song Patcher can take the patched audio and convert it to the proper format — ready for use in Beat Saber just like any other custom map you download today!Where to go next?Now that Saber Song Patcher exists, is the problem “solved”?I think in order for there to be any meaningful impact we (the Beat Saber community) need to adopt the tooling into existing software like ModAssistant and BeatSaver.For example, perhaps in addition to the existing “1 click install” option in ModAssistant, we could also have a “2 click install” option where you have to first select the master audio file for the song on disk (at which point it is verified, patched, and converted) and then the map is automatically installed like today. Hardly any more work for the user, and no copyrighted song is distributed illegally.Stay tuned — I believe with better tooling integration, continued improvements to the verification and patching process, and the idea of a robust system that isn’t subject to takedown — we can make it a reality.Other QuestionsWhat about streaming services like Spotify or Apple Music?While that would be really nice to have, it is even harder to synchronize streaming music than downloaded songs (e.g. what if it needs to buffer?). Plus, Beat Saber itself is not set up to work with external audio sources so there would be additional work required to mod the core game engine itself. Very tricky.Written byDavid IdolSoftware Engineer. Currently @ Snap. Previously @ Xbox, Google, IBM.Follow2 2 2 Beat SaberVRPiracyMusicSoftware DevelopmentMore from David IdolFollowSoftware Engineer. Currently @ Snap. Previously @ Xbox, Google, IBM.More From MediumPC Games To Check Out: 1st Quarter of 2019Ramesh RadhakrishnanJournal Entries of a Developer Crafting His First Roguelike GameE.T. DeubnerGaming in 2020: 4 Reasonable Predictions and 2 Ridiculous OnesPCMag in PC MagazinePushing the Sega Dreamcast to its Absolute LimitAlex Beyman in PredictMoney Making Colonies In Fallout 76Anthony Mountjoy in Verboten PublishingHow I Began to Avoid the “Hours Played” Meta GameJakub CernochAndroid 3DS Emulator : Is It Possible Now?Yoga AdiBug Fables Review: Paper Mario 3?Cole Durrett in SUPERJUMPAboutHelpLegalGet the Medium app"
Locomotion in VR: Procedural Generation of a Scene,https://blog.prototypr.io/locomotion-in-vr-procedural-generation-of-a-scene-2e1cc22c1f8b?source=tag_archive---------4-----------------------,"Procedural Generation,VR,Game Design,Game Development,Locomotion","In my article Physical Spaces in Virtual Realities, I motivate the use of procedural generation in VR development as a tool for creating custom environments tailored to the user’s play area.By using procedural generation in this way, we can expand the limitations of movement in VR — that is, we can make experiences that allow users to explore all of the available play space. In essence, we can have a new tool that allows us to build environments that scale and allow for more locomotion within the virtual world.In this article, I will illustrate the generation of procedural environments by creating an island. Many VR platforms let the user define boundaries that set the play area (mostly for avoiding walls and physical objects), but Oculus actually provides this as an API with the Guardian system.Footage of the final result from Oculus Quest. The Guardian input is drawn on the island.Let’s understand how we can use its data for curating an experience. While I focus on Oculus Quest, this walkthrough is relevant for Oculus Rift as well.Getting the InputsThe play area, which is accessible to developers as a polygon or a rectangle, can be used to procedurally generate the scene.We will create an island where sand marks the play area (bounded by the polygon) and the ocean around it the unplayable area (everything outside the polygon) and connect the two with a smooth gradient.We will place interactive props procedurally, ensuring they are physically reachable to the user despite the size of the play area. Here are several islands generated from various inputs (the inputs are shown below):To start playing with the idea, I recorded several Guardian configurations in my living room and saved them locally. You can access my living room data here, or record it yourself using this script. Here are few boundaries I recorded (I tried to create interesting shapes):Guardian recordings from my living room.To get these shapes, we make two queries to the GetGeometry API call. One, to get the outer boundary polygon (which is used for creating the environment):OVRManager.boundary.GetGeometry(OVRBoundary.BoundaryType.OuterBoundary);And the second, to get the play area rectangle (which is used to properly position the props):OVRManager.boundary.GetGeometry(OVRBoundary.BoundaryType.PlayArea);Now that we have our inputs, we can start thinking about what features our island will have.What Makes an Island an Island?An island is a piece of land protruding from the ocean. So, our island should be elevated and smoothly transition into the ocean surrounding it.Translating this to some technical terms:Floor Level — the height of the island relative to the user spaceLow Level — the height of the ocean relative to the user spaceHorizontal Distance — the horizontal length of the transition from Floor Level to Low Level (how far the island stretches until it reaches the ocean)Floor Elevation — the horizontal length of the transition from Floor Level to Low Level (how far the island descends until it reaches the ocean)Falloff Function — a function we will use to generate a smooth curve between Floor Level and Low LevelFinding The FloorNext, we will generate a basic mesh from the outer boundary we extracted. To do this, we will need the position of the physical floor relative to our scene and use this position to create a mesh (in which the island is heightened).To get Floor Level, we need to use Oculus APIs. The Oculus SDK for Unity abstracts this information to fit most scenarios. There is even an enum called Tracking Origin Type in OVRManager that we could theoretically set to FloorLevel.The problem with this approach is the space we’re building won’t stay in the correct position relative to the physical space when the headset re-centers. If you dig really deep into Oculus Documentation, you find this explanation:The default tracking space is Local, which means re-centering works as normal. This is the correct behavior for most apps.Some apps may want to remain anchored to the same space for the duration of the experience because they lay out according to the user’s Guardian bounds. […] These apps may want to use the Stage tracking space.From this, we can understand that we need to set Tracking Origin Type to Stage — it saves us from worrying about accumulating offsets when the app re-centers. But, using Stage also means floor level is arbitrary, so it alone won’t suffice. In contrast, the play area polygon described earlier is calibrated to the actual floor level. So, we can use a combination of the two!Creating ElevationNow we know how to position things relative to the player’s floor. It’s a good start which allows us to easily create an elevation difference between the island and the ocean below it. The elevation can be achieved in multiple ways, and here is an overview of my strategy:Procedurally generate a dense plane around the polygonGet all the plane vertices which lay outside the polygonLower these vertices to Low Level (the “ocean level”)Generating a planeDepending on the polygon, the plane might look like this:The Horizontal Distance we defined earlier should pad the entire island’s perimeter.Notice how the plane is generated from squares (pairs of triangles, to be precise). The square count is proportional to the density of the mesh and therefore will affect how smooth the island and its edges will appear.Generating environments with different vertices count affects the fidelity of the final result.As vertex count increases, the model’s resolution increases. I found that 1000 vertices provided a good balance between smoothness and performance.Lowering the height of vertices outside the polygonNext, we will lower the position of all points outside the polygon to Low Level. I used this code snippet to help me find whether a point is inside a polygon. This generated a promising result:Our plane with all the vertices outside the polygon lowered.Smoothing the ElevationThe result so far is literally rough around the edges, but it’s definitely starting to look like an island. What we need now is to smooth things out .Recall that we created some spare mesh around the polygon using the Horizontal Distance. We can take the edges of the polygon and gradually heighten the mesh until it reaches sea level:It’s subtle, but the points closest to the polygon have lowered. If we repeat the process over and over again until we reach Horizontal Distance away from the island, all vertices will be lowered in gradient fashion.To get a basic algorithm working, let’s define a simple linear transition between the island (Floor Level) and the sea (Low Level). A straight line would radiate from every point on the island perimeter towards the surrounding ocean.We need to know the distance of every mesh vertex to the polygon in order to know how much to lower it. Theoretically, this would require checking the distance between the point and each side of the polygon (each line segment). Since the polygon we get from Oculus is dense enough we can just assume it’s roughly the same distance to the closest point on the polygon.With all the pieces in place, multiple iterations of the algorithm generate this:The island mesh, built iteratively from the perimeter of the polygon.After 13 iterations, the outermost vertices reach sea level and the smoothing is complete.PolishingBeautify the transitionUntil now, we used a linear falloff function to smooth the island’s transition into the ocean. To make the transition look even more natural, we can apply a non-linear falloff function. There are many interesting falloff functions we can choose from.With a non-linear falloff function, vertices are positioned in different heights.After playing with some options, I chose 3x² — 2x³. Using this function instead, we get the final result:The island mesh with a non-linear falloff function (3x² — 2x³)This transition looks natural and convincing! After applying shaders to render the sand texture and the ocean, we get this:A custom shader is used on the generated mesh, creating a natural-looking island.Spice with some propsLastly, we can decorate our environment with interactable props. I chose to use the playable rectangle to procedurally position the props, but the polygon could also be used.Using the play area rectangle to generate props.This gives us the complete interactive island:Same Concept, New EnvironmentsI tried to keep the island parameters flexible enough to play with. By just changing a few of them, we can generate vastly different results:Tweaking the elevation:Changing Horizontal Distance and Floor Elevation can dramatically change the resulting mesh.Reversing the roles of Floor Level and Low Level:Setting Floor Elevation to have negative values can create interesting valley-like meshes.I uploaded the source code and a playable demo of everything I showed here, in case you want to try it yourself.Wrapping It UpSince Oculus exposed the play area polygon in their APIs, I haven’t been able to find any VR experiences that utilize it (if you’ve seen one, please let me know in the comments!). I have played the innovative indie game Tea For God, which uses the play area rectangle to procedurally generate a maze, but that’s the extent of what I found.Perhaps this is because the information is buried deep in the Oculus documentation and is mostly left unnoticed; maybe it’s too new, underdeveloped and a bit buggy; or perhaps its usage and potential just isn’t obvious.Whatever the reason, I believe the VR world should be more aware of its existence. My goal here was to demonstrate that, despite the currently limited capabilities of this new input, it’s still possible to explore its potential.In this particular demo, we saw how the play area polygon served as an input to the procedural generation of an environment, allowing us to create a custom environment that scales to the user’s playable surroundings. This is just one thing we can do with the user’s physical space, and more generally, with Virtual Reality as a whole.Many thanks to Polygon Punch for the great 3D assets.Written byOmer PerryEngineer | Gamer | VR PrototyperFollow322 3 Sign up for By Design.By PrototyprStay in the loop with the design industry - get weekly digests of news, stories and tools. Take a lookGet this newsletterBy signing up, you will create a Medium account if you don’t already have one. Review our Privacy Policy for more information about our privacy practices.Check your inboxMedium sent you an email at  to complete your subscription.322 322 3 Procedural GenerationVRGame DesignGame DevelopmentLocomotionMore from PrototyprFollowPrototyping, UX Design, Front-end Development and Beyond 👾Read more from PrototyprMore From MediumUX Specializations. Let your skillset do the talking next time.Avinash Bussa in PrototyprIntroducing Figma to React.Overlay in PrototyprHow to set up design principles with your team (remotely)?Naïma van Esch in PrototyprHow to setup retrospectives in Figma for more motivation during remote work ⚡⚡⚡ (Template)Joschka Wolf in PrototyprReflections from a 2 time Amazon UX InternChristian Leong in PrototyprBuilding a multi-platform Figma/Sketch plugin with ReactKévin Jean in PrototyprA Sneak Peek Behind Upcoming Tech at AdobeJoanna Ngai in PrototyprVideo Call Super PowersAlex Jones in PrototyprAboutHelpLegalGet the Medium app"
Everything Immersive This Week (8/1/20),https://noproscenium.com/everything-immersive-this-week-08-01-2020-65c50682aaeb?source=tag_archive---------5-----------------------,"Eitw,Immersive Theatre,VR","Look: life happens.So you’re getting double the W in this week’s EITW. That’s a lot of show listings, reviews, features, and news. Some of the latter of which is disconcerting as some long whispered issues with a seminal immersive project are starting to come to the surface.Yet the overall thrust of Pandemic Era immersive and experiential remains surprisingly strong.Let’s get into it.Office facilities for No Proscenium are provided by…No Proscenium is made possible by our generous Patreon supporters.[We’re on the march to 1000 backers. Every $1 and $5/month pledge makes all the difference in the world.]ON THE PODCAST THIS WEEKSean Stewart has been a lot of things in his storied career in telling stories. Novelist, LARPwright, actor, theatre tech, and most famously of all: one of the creators of the modern Alternate Reality Game.Now add “internationally produced playwright” to the list.Sean and Noah talk about his upcoming interactive play Roundabout, which will be performed by students of Australia’s National Institute of Dramatic Art via Twitch, and the evolving nature of theatre (yes with the “re”) in the Pandemic Age.Show NotesAustralia’s National Institute of Dramatic Art production of RoundaboutSwings And Roundabouts: Theater Strikes Back — Sean StewartNoPro Episode 156 — Sean Stewart & The Birth of the ARGFROM THE WIRE: SHOWS, EVENTS, & EXPERIENCESWe’re still running the Newswire here at NoPro while the public beta of Everything Immersive shakes out. To get your work on the Newswire, submit at EverythingImmersive.comThe House That SlippedAn online immersive show from Teatro Vivoeach and every“to the makers of music”Greenfield, MA: Under the StarsA Covid-friendly drive-in theatre experienceEngland ExpectsCommand a Royal Navy Warship in the Mediterranean during WW2… over Zoom.Instructions for a Habitat InventoryAn on-demand examination of the place where you areThe Wizards of Oakwood DriveA La Jolla Playhouse Digital Without Walls (WOW) ProductionThe Officially Licensed Evil Dead 2™ Live Remote Escape RoomYou have 70 minutes to save the world in this Groovy game via ZoomFour LoversA game that is (not?) about love.Agent Venture Mission 1: The HeistBond has Q-Branch, Jack Bauer has CTU, Inspector Gadget has Penny & Brain, Agent Venture has… youDr. Crumb’s School for Disobedient Petsbe clever. be quick. be disobedient.LA/Remote: C(ovell) in the C(loud)The Game Goes VirtualElectric Dreams Online FestivalCelebrating the best of cyberspace storytellingSign up for our newsletters to get new immersive experiences sent straight to your inbox.Source: Pixel PlayhouseREVIEWSPandemic Age immersive is taking making forms, and the past two week’s worth of reviews shows off some of that breadth.We kick things off with Definitely Not Clue, which completed its run on Twitch last month. A musical from the gang at Pixel Playhouse, who, in their IRL incarnation as After Hours Theatre Company, have had no small measure of success with immersive experimentation.Definitely Not Clue plays with the chat feature of Twitch to create a dynamic audience experience that influences the way the show is received. This notion of the audiences’ experience as being a distinct element that can be designed and developed is the lodestone by which NoPro as a whole navigates, and its what sets Definitely Not Clue and the upcoming Roundabout (see the Podcast) apart from your basic livestreamed play.Suffice it to say, we’re thinking a lot about this topic these days.Spoilers on the review: Blake loved it.‘Definitely Not Clue’ Lets Loose in a Lively Livestream (Review)Pixel Playhouse brings high school drama archetypes galore to Twitchnoproscenium.comKlaxAlterian Sequester is a podplay that lives up to the experiential potential of the form, and delivers a fantastically polished production right onto the smartphone of your choice for the low low price of nada.Our reviewer, NoPro publisher and third person writing enthusiast Noah Nelson, found the meta-frame of the largely meditative experience a tad depressing as the whole thing is meant to be a transmission from an even darker future, but there’s so many textual layers baked into the production that you might find yourself drawing some hope from what’s sandwiched in between the darker vibes.One way or another: this one is worth the time for the production values alone.The ‘KlaxAlterian Sequester’ Broadcasts From An Even Darker Timeline (Review)It is the Twenties and is there time for KlaxAlteria?noproscenium.comAllie gets to be part of an anarchic audience experience as performer Brian Feldman gives himself over to their control in the improvised #txtshow, which sounds like a blast and the platonic ideal of all those improv shows you went to back in college.Maybe stack the deck with your friends, yeah?Socially Distanced Anarchy Runs Amok in ‘#txtshow (on the internet)’ (Review)Brian Feldman does… whatever we want him to in the audience-led experimental piecenoproscenium.comLaura writes up the team’s experience with B.O.W.L.I.N.G. Night, which they were granted a preview of by creator Brett Jackson.I think this sums it up:I laugh so hard my notes are simply: “lick sauce hole.”Honestly, if I can’t get you to read this based on that there’s no hope for any of us.No Gutterballs Get Rolled in ‘B.O.W.L.I.N.G. Night’ (A NoPro First Look)Live Action Attractions’ Brett Jackson stands out as the game’s kingpinnoproscenium.comFinally this week, Asya takes at look at The Delegation from London’s Coney, which dives into pandemic capitalism via a game-like simulation of a diplomatic summit. Multiple platforms — Zoom, Whereby, and the web — get used to create an evening-long version of a multi-day conference.There’s a lot of ideas packed into this show.‘The Delegation’ Reminds Us of the Power of the People (Review)Coney puts Russians and Brits into a virtual hotel for a diplomatic treatynoproscenium.comFood For ThoughtThis week our executive editor Kathryn Yu published a feature looking at how creators are devising new ways to set the tone for experiences in the Pandemic Age.With so many of the tools of immersive and experiential taken away from us at present, this is a fascinating look at how people are doing more than just “making do” in this digital focused era.Setting the Tone, Virtually: Creating the Magic Circle Online (Feature)How immersive creators can help participants suspend their disbelief at homenoproscenium.comLook, I’m a broken record at this point, but Sean Stewart’s essay Swings And Roundabouts: Theater Strikes Back, is a must read about the role of the audience in the theatre of now. Not just immersive theatre, but theatre in general. Expect more on this anon.Swings and Roundabouts: Theater Strikes Back - Sean StewartWith the advent of live streaming platforms such as Twitch and Facebook Live, theater can draw even with film for the…www.seanstewart.orgNews From around the Immersiverse — Part One: NonchalanceEarlier this week, the NoPro Twitter account was tagged in a tweet by the account of Nonchalance, the production company behind the seminal alternate reality game The Jejune Institute which was the subject of the film The Institute and inspiration of the AMC series Dispatches From Elsewhere.When Nonchalance’s follow up experience The Latitude ended, there was a fracture in the community that had built up around the show. In short: there was a lot of bad blood in the wake of that one, and people weren’t always up for talking on the record. While in private conversations it was obvious that wounds had never fully healed, in public bygones were largely being allowed to be bygones.In the past year, the arrival of Dispatches From Elsewhere and a second film about Nonchalance — developed with their cooperation and focused on The Latitude — called In Bright Axiom stirred up the past. At least one screening of In Bright Axiom appears to have been pulled because of objections from somewhere in the community. That right there is important as the “who” and “why” drives some of what follows.The Nonchalance tweet was followed by a response from Michelle Krasowski, who both challenged Nonchalance’s premise and then proceeded to recount parts of her own experience of Latitude, its creators and the aftermath.Krasowski also made reference to her partner Uriah Findley’s experience as one of the producers of The Latitude. Findley has long since parted ways with Nonchalance, and indeed already had at the time that we interviewed him on our podcast back in 2016.The Nonchalance account and Krasowski had a back and forth, and in the wake of it Nonchalance posted a call to get the stories out in the open.(According to Krasowski, the Nonchalance account would end up blocking her at some point in this window of time.)This call prompted a response from Findley, who released a lengthy thread about his interactions with the director of In Bright Axiom, Spencer McCall, and the head of Nonchalance, Jeff Hull, on Friday night.Findley goes into exhaustive detail on one particular exchange around the time of the festival circuit screenings of In Bright Axiom. As of this writing the Nonchalance account has yet to respond publicly to the thread.So why are we posting this here since Twitter drama isn’t something we normally cover?Well, for one, “Twitter drama” isn’t what this is about. This is a look — messy as it is — at how one of the more controversial projects of the past five years was made and the fallout of the way in which it ended. The Latitude was heavily buzzed about at the time, and the initial fallout was the subject of a feature article at Vice.We’ve been tagged in this, so we were asked to bear witness. The timing of the initial tweet may or may not have to do with the release of In Bright Axiom on VOD, and if there had been no follow ups we likely wouldn’t have had responded, since tagging us isn’t a great way to get our attention for PR purposes. Since there is a dialogue — of sorts — and things that have been talked about on background in the past have started to be surfaced, we have an obligation to draw what meager spotlight we have on to the exchange.Getting to the bottom of all this would take a level of resources that we just don’t have. However, addressing the pains of the past — and, from the outside looking in, there seems to be a lot of pain to go around — is a much needed process. From our previous looks at The Latitude, we know that there are those who have been reluctant to go on the record, so where their stance is at present remains to be seen.We will continue to follow this story as it develops.Her name is Rashin, Tara Rashin. She’s a pirate. Source: ILMxLABNews From around the Immersiverse — Part Two: Everything ElseHey! Who wants some fun?I do! I do!Great!Star Wars: Galaxy’s Edge is is coming home in the form of Star Wars: Tales from the Galaxy’s Edge by way of the Oculus Quest. The experience is still under development, but who knows: we might just be able to go to the digital version of Black Spire Outpost before we can go to the real one.No I will NOT put quotes on “real one.” And I’m sorry but Batuu East is a myth. ;-)5 New Things We Announced This Week About Star Wars: Tales From The Galaxy's Edge - ILMxLABIn a new video, our Star Wars: Tales from the Galaxy's Edge creative team announced story details and casting news for…www.ilmxlab.com44 immersive projects have been selected for the Venice Biennale, greatly expanding the festival’s VR footprint. And the whole thing will be ONLINE. The Venice VR Expanded projects hail from 24 different countries and the jury includes of Celine Tricart (USA), Asif Kapadia (BG), Hideo Kojima (Japan).The online platform is supported by HTC VIVEPORT, Facebook’s Oculus, VRChat and VRrOOm.Oh, how we hope our Quests work for this! It all starts September 2nd.Biennale Cinema 2020 | Selection complete for the works of Venice VR ExpandedVenice VR Expanded The selection is now complete for the Virtual Reality works to be presented at the 77th Venice…www.labiennale.orgIn case you’re not tired of hearing about Roundabout yet, the UK’s Guardian wrote up how Australia’s NIDA is managing the pandemic. No word yet on the secret classes where they teach Australians how to have better accents than any American or British person. Only Canadian actors can stop their plot for global cinematic domination!'It's been deeply odd': how NIDA, Australia's most prestigious acting school, is managing the…Final-year acting student Alex Stamell was deep into rehearsals for Will Eno's Middletown when the Covid-19 shutdown…www.theguardian.comImmerse has this deep dive with the one and only Nonny De La Peña, whose work set the table for the VR renaissance we are currently living in.The World Is 3D and Media Should Be TooNonny de la Peña reflects on her experience as a VR pioneer.immerse.newsFilm Independant interviewed the creative forces behind The Under Presents: Tempest, including one of our favorite immersive actors in any reality: Dasha Kittredge.Tender Claws Uses VR to Re-Imagine Immersive Theater During Lockdown - Film IndependentIn world where real reality increasingly seems like the far inferior of any two given options, it's no wonder that…www.filmindependent.orgAnnnnd just because we can’t have only good news: London’s VAULT festival postpones until 2022.It sucks. But is obviously for the best.VAULT Festival London postpones until 2022In consideration of the significant financial and safety risks brought about by COVID-19 and that each festival takes…britishtheatre.comOpportunities: Professional & EducationalOculus Lauch Pad Scholarships — 2020 Applications OpenOculus, the Facebook owned VR company that makes the popular Quest headset, has announced the winners of its 2019 Launch Pad Scholarship program and that applications for 2020 are now open:Our fourth annual Oculus Launch Pad program has come to a close! Last year, we welcomed 100 new developers from diverse backgrounds to join us for two days of hands-on learning and invited them to continue that momentum through Oculus Connect. At boot camp, we spent two days sharing best practices, unique perspectives, and inspiring ideas. Launch Pad attendees then had four months to build a prototype that could be submitted for consideration as part of our Launch Pad Scholarship program. Today, we’re excited to introduce the 2019 Launch Pad Scholarship recipients and their VR projects that are helping to push the industry in exciting new directions.Oculus Launch Pad 2020 applications are open through August 20. Click here to apply.NoPro is a labor of love made possible by our generous Patreon backers. Join them today!In addition to the No Proscenium web site, our podcast, and our newsletters, you can find NoPro on Twitter, Facebook, YouTube, Instagram, in the Facebook community Everything Immersive, and on our Slack forum.Office facilities provided by Thymele Arts, in Los Angeles, CA.No Proscenium: The Guide To Everything ImmersiveImmersive theatre, virtual reality, escape rooms…Follow2 EitwImmersive TheatreVR2 claps2 clapsWritten byNo ProsceniumFollowThe Guide to Everything Immersive: immersive theatre, virtual reality, escape rooms, LARPs, site-specific dance/art.FollowNo Proscenium: The Guide To Everything ImmersiveFollowImmersive theatre, virtual reality, escape rooms, site-specific dance/art, and moreFollowWritten byNo ProsceniumFollowThe Guide to Everything Immersive: immersive theatre, virtual reality, escape rooms, LARPs, site-specific dance/art.No Proscenium: The Guide To Everything ImmersiveFollowImmersive theatre, virtual reality, escape rooms, site-specific dance/art, and moreMore From MediumBuilding a New World Together with ‘Project Ascension’ (A NoPro Adventure)Leah Ableson in No Proscenium: The Guide To Everything ImmersiveTake a Journey Through 7 O’Clock with ‘The Mile Long Opera’ (Review)Asya Gorovits in No Proscenium: The Guide To Everything ImmersivePast and Present Collide at ‘The Soiled Dove’ (Review)Brian Resler in No Proscenium: The Guide To Everything ImmersiveA Wonderland Indeed with Upended Productions’ ‘Alice’ (Review)Patrick B. McLean in No Proscenium: The Guide To Everything ImmersiveBirds and Bees and Multiple Realities — ‘Loveseat’ at Venice VRPola Weiß in No Proscenium: The Guide To Everything ImmersiveExperience the End of Humanity in ‘Jeff Wayne’s The War of the Worlds’ (Review)Edward Mylechreest in No Proscenium: The Guide To Everything ImmersiveFollow This ‘SCARECROW’ Into the Dark (Review)Kathryn Yu in No Proscenium: The Guide To Everything ImmersiveIt’s A Bloody Good Time at ‘Murder at the Drive-In’ (Review)Danielle Look in No Proscenium: The Guide To Everything ImmersiveLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Terra Virtua — Development Update,https://medium.com/terravirtua/terra-virtua-development-update-29b34e5f4018?source=tag_archive---------6-----------------------,"Nft,Crypto Collectibles,Blockchain,VR,AR","August 2020Welcome to our development updates! We will endeavour to keep this channel as an ongoing information source of everything going on in the engine room in Terra Virtua. We will try to keep to a bi-weekly schedule, and talk about what we are currently up to. Our development roadmap is pretty expansive, and we are adjusting to life after launch, where we are making tweaks and optimisations to the existing platform as well building cool new stuff.One thing we would like to do though, is thank the incredible art, development and production team who have always, always pulled out all the stops to make things happen. Huge shout to everyone! You know who you are…. :)Ok let’s get started:The Ecosystem1: Fancave CustomizationUp until now, all of the Terra Virtua Users had similar Fancave instances; your 3D environment to view, arrange and show off your prized digital collectibles, on your PC and Laptops.This is our most active user touch point at the moment (right after web marketplace).Moving forward, you’ll be getting an ability to customize the following inside your Fancave;WallsFloorsFurniture (Sofas, Cupboards)Ornaments (Lamps, Planters)This will allow you to have a personalized instance of your fancave, based upon the collections you have. These customizations will be available for purchase as non-nft items on a sub marketplace very soon.A Beta for Fancave Customization has already been submitted to the Epic Store for this purpose. (or, we might even let you buy it from within the Fancave without leaving the PC environment at all!)Fancave CustomisationsThere is also a future suggestion of allowing the users to upload their own mesh files for Fancave customizations. What are your thoughts on that?2: The Terra DomeTerra Virtua is bringing more and more licensed IPs from some of the biggest names in the entertainment industry for you and that simply means, you need a bigger space to show them off.The Fancave serves as a PC environment for your vFlects, Posters and basic 3D models. The Terra Dome is going to be the place to put your bigger items, like Planes, Spaceships, Creatures and more.Here’s a sneak preview of how it is looking.. (and it is looking good!)Terradome Preview ImagesThe Terra Dome is in final stages of development with Q/A and optimization updates going on. You can expect to see new and upcoming Lost in Space and Top Gun collectibles in this amazing environment this October.3: The Terra GalleryThis is a big one!Since the Crypto Art space is growing as the next generation of Art Collectibles in the world, our amazing community has been asking for this for a while now. Here we’re responding to what they want from us! We however are taking a slightly different approach and even working with mainstream artists to help them advance their art into VR and animation. We are initially working on a curated marketplace with partners, then will be opening it up to the wider art community.The Terra Gallery will be launching with two sets of “1 of 1” collectibles- Stunning Concept Art pieces behind every vFlect Family- Curated Art Collections from some unique talent(V2 will be opening up the platform for Crypto Artists to upload and mint their artworks on demand, and put for sale directly on Terra Virtua Marketplace. Keep your inner artist updated with news from this space!)The Terra Virtua GalleryThe V1 of Terra Gallery is going to be a 3D Environment for your PC and Laptops. Once signed in, you’ll be able to glance through various Artists’ and Collections, and add them to your wishlists.Then you’ll go to the Terra Virtua Website, and you’ll find your amazing artwork waiting for you to be added to your cart and bought, just like any other NFT on the marketplace.You’ll also have the ability to glance through the “Art Gallery” section of the website, filter and search through artists and collections, and just buy them with your regular Metamask ETH account or via Credit Card. It does mean some updates to our current filter and search sections, but you can expect to get your hands on this exciting new offering by Terra Virtua by Mid-September.4: Web MarketplaceFirstly, we’d like to take a moment to thank our community for loving our website. We’ve been getting praises, feedback and comments from our Discord and other support channels, based upon which, we’ve also made some adjustments in our filter, navigation and cart system.Now, it is time to change some look and feel of the main Marketplace landing, to a much simpler view..The White Mode! The entire team has been split down the middle in terms of preference. We are also making the thumbnails larger without breaking the mobile view, which happens if titles are too long.White modeThis not only will allow you to see a clearer detail on your high fidelity items, but will also serve a great view for showing up digital artworks, at par with 2D and 3D collectibles, in the same view.And for those of you, who asked for, and loved our Dark Mode, it will now be available as a toggle on all mobile and desktop webviews as default!Dark ModeSome other “secret news,” our cart checkouts now support PROMO CODES.Just for that announcement, use PROMOLAUNCH the next time you buy something from Terra Virtua, and the first 30 orders will get a 10% discount. (This is a reward for reading so far..).5: Augmented Reality Mobile AppsSince we’re still in process for app store approval for our iOS application, however Android users can enjoy the luxury of seeing their digital collectibles in augmented reality, snap and record it, and share it across all social media platforms directly!Lost in Space on Your Driveway in AR!These applications initially were meant to be just viewer applications for 3D view of your inventory, much more is coming! Grab it here!6: VR Fancave:This is one of our most awaited product modules which our community has been patiently waiting for since the very start.- The ability to hold your Collectibles with your bare hands in VR.- The ability to touch and interact with your Avatar- The ability, simply to be “in” your Terra Virtua environments!Well guess what, we’re just on final stages of submission for both Oculus Rift, and Oculus Quest!VR FancaveFancave is going to be your first Terra Virtua 3D environment for VR built on Unreal Engine and Terra Dome is following up. We’re expecting the VR part of our ecosystem to come alive this holiday season.THE SYSTEM:This part of the update covers the systemwide important updates happening and scheduled for launch in next 5 months.1: BlockchainAt the moment, Terra Virtua is only supporting the Ethereum MainNet. Since we’re absorbing the costs for gasless transactions for our FIAT customers, factors like the network congestion, ever-fluctuating ETH prices and dApps overload, is causing delays sometimes in transactions in past few weeks.Since our customers are great, our support is (very) good, and our blockchain team is watching over the network 24/7, we’re able to process 100% of transactions happening on our system successfully.But to rectify such problems, once and for all, Terra Virtua is restructuring its blockchain layer. In a nutshell, this update will allow;- The opening up of terra Virtua contracts to the main ETH net, allowing Terra Virtua Legacy users to take their inventory to any outside marketplace OpenSea and trade/auction/sell it there.(In that case, of course, you’ll not be able to use the amazing digital products of our ecosystem, like Fancave, or terra Dome, or AR mobile App, but you’ll always have the ability/option to bring it back to ecosystem)- The ability to support cross-chain transactions for all EVM based sidechains- Maintaining Cross-chain providence of every Terra Virtua asset on our ecosystem!We’re hopeful, as you are, that Ethereum 2.0 update will solve most of the above mentioned problems by default, still, we’re committed to provide our audience with the best, seamless NFT buying and transferring experience for every asset we’ve ever created, for the all of times!2: 2D Animated Assets:The launch of the Crypto Art section, is also coupled with the launch of 2D animated NFTs, we classify as 2DA.The first batch of inventory is going to be the rarest Iconic Collection, for the greatest movie of all times, “The Godfather.”So if you’re a movie buff, this is going to be your chance to collect these beautiful 2D animated art works, for this timeless classic very soon.One of the Godfather 2DA CollectiblesYou will be able to use these 2DA items in your customizable 3D environments and AR app, just like other 2D posters, (but yeah, they’ll look way more cool than them!)PARTNERSHIPS1: MaticWhile our quest with side-chains is still on, we’re happy to find partners every now and then, who are as enthusiastic about their product, and their business as we are. Matic is turning out to be one hell of a crew!The product not only solves all the transaction and minting related issues on Ethereum MainNet which is halting developers from blockchain at the moment, but is also led by a team of seasoned, supportive professionals.Their proposed POS transactional solution for ERC-721 is one of the most promising prospects available on market. It’s in the finalization stages, expected to be deployed on Matic MainNet later this month.Terra Virtua is looking forward to working with MATIC as a true scalable sidechain solution but which gives our crypto customers the most flexibility. For our casual users they get speed and security without the congestion issues plaguing the mainnet right now.That’s all folks, you’re all caught up!Dont forget to follow us on Discord, Telegram, Twitter and Instagram. There is a LOT more to come, so keep following!Jawad and Azeemicollecting. reinventedTerraVirtuaCollecting. Reinvented.Follow154 NftCrypto CollectiblesBlockchainVRAR154 claps154 clapsWritten byTerra VirtuaFollowCollecting. ReinventedFollowTerraVirtuaFollowCollecting. Reinvented. A truly immersive collectibles platform across Mobile, AR and VR, enabled by blockchainFollowWritten byTerra VirtuaFollowCollecting. ReinventedTerraVirtuaFollowCollecting. Reinvented. A truly immersive collectibles platform across Mobile, AR and VR, enabled by blockchainMore From MediumCreate Zero-Point Failure Distributed Tasks With Python and ZeroMQTimothy Mugayi in Better ProgrammingThe Wonders of OOPSArunangshu Biswas in The StartupHow I Stopped Learning to Code and Started CodingE.T. Deubner in Better ProgrammingWeb Scraping MQL5 Signals With PythonMatheus V de Sousa in The StartupWhat Does Modular Architecture in Angular Even Mean?Aphinya Dechalert in mad<hashmap>Kubernetes From Scratch (Part 2)Randal Kamradt Sr in Better ProgrammingClassification of Whether the Car Accident Is Day-Time or Night-TimeBERFİN SARIOĞLU in The StartupDebugging Mainframe COBOL programs with VS CodeIurii Shchekochikhin in Modern MainframeLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
How VR Porn Impacted in Porn Industry,https://medium.com/@grahammaloney7/how-vr-porn-impacted-in-porn-industry-d951eb4a72e9?source=tag_archive---------7-----------------------,"Virtual Reality,VR,Vr Experiences,Vr Device,Porn","There has been a massive transformation of the porn industry in the past few years. A lot has changed since porn found its way to the internet from DVDs. One of the latest developments is none other than VR porn, which has been growing rapidly since its prominence took a toll somewhere around 2015–2016. In fact, Pornhub reported massive growth in its VR porn category in 2016 itself.Source: Pornhub InsightsWith traditional porn grown prominent, there is nothing much left to explore by the consumers. VR has made its way to offer comfort, which although is not as good as the real thing, but is indeed the closest alternative.What is VR Porn?In the last decade, Virtual Reality (VR) has grown massively popular in multiple segments of the market. One such segment is the adult entertainment industry, where VR has put the actions from the porn scenes right in front of our eyes.Starting from era of VHS tapes to DVDs, VOD streaming, Live webcam streaming, and now VR. It was inevitable, considering that porn has always found its way to the consumers in every era.VR porn is not about watching random porn videos on a VR headset. Although you can still watch VR enabled regular scenes on a VR headset, but it’s not at all close to the actual VR porn.A legitimate VR porn is made for VR. The viewing experience in such a scene is 3D, of course, but it’s also more immersive when scenes are shot in POV style. Such a shoot will put the viewer at a perspective where they can experience the scene from one of the participant’s viewpoint. That’s why VR porn is also called as 360 camera porn with viewers in the perspective.Caption: August Ames and Tommy Gunn Virtual Sexology. BADOINKVR 2016That’s what VR in general is, isn’t it? The viewer dips into the scene and feels as it’s happening right in front of their eyes, like in the actual 3D world. The production of immersive VR porn is way different than regular porn scenes.Source: BADOINKVRSource: VR BangersRight from the kind of equipment to the position of the cameras closer to the performers, the production of VR porn is yet another massive topic for discussion. For now, let’s just grab the fact that VR porn or 360 camera porn is a whole another industry in itself, and it is still in its budding phase.Except for a little improvisation with cameras and custom components, VR porn production is similar to regular porn. Performers need a little training with the new stuff, but the rest of the parts are still the same for them. The actual enhancements are observed from the viewers’ perspective, as an immersive experience makes them feel like they can reach out and touch the performer as a participant in the scene.Why should we try VR Porn?Believe it or not, VR is the next big thing and it’s going to have a significant impact on at least the two major segments of the adult industry for sure. I am talking about traditional porn scenes and live webcam streaming, too.Every production house in 2020 is now investing in this new trend. With more than 78% of the users in the US being familiar with VR technology and over 14 million AR VR devices sold in 2019, it’s not wise to ignore such a significant market. It is expected that stand-alone VR devices will grow by 16X between by 2022 (source).As of now, adults have grown saturated with the same experience with the regular scenes. There is hardly anything new to explore. If you are into the porn industry as a producer or as a porn website owner, it’s a good time to explore this new niche in its budding phase, before it gets even competitive.Here are some more reasons to explore VR porn for business:Users are looking for an immersive experience. VR porn, 360 camera porn, or webcam VR porn is the answer to their search.Both paysites and free live stream porn sites have been experimenting with this new niche, and they have been successful, even with the inferior quality of VR scenes.In 2020, VR headsets have grown even cheaper. More people have access to these tools and they are looking for new ways to explore the realm of VR.After the COVID-19 pandemic, people are looking for innovative ways to spend their time in isolation. The stats about the increase in porn consumption in this time has already skyrocketed. The global porn consumption in 2020 is touching the skies, up to a level that Pornhub made premium subscription free for a month in April. Both adult and the non-adult industry is seeing a massive implementation of VR. Now is the right time to stand out from the regular competitions and offer something new.Evolution of VR PornVR in general is a rapidly growing industry. The global VR market was measured as a $10.32 billion industry in 2019. The reports also suggested that the same will grow at a CAGR of 21.6% from 2020 to 2027, which seems pretty possible as of now. Especially with the latest technological developments making VR headsets more protuberant, both VOD and live porn VR streaming is now a granted behavior.VR as a high-flying technology has come a long way from the first VR tech patent being filed by Sensorama in 1962 to VR becoming prominent in mobile phones and headsets today.It wasn’t until 1968 when the first fully functional head-mounted VR display made its way in the market by “The sword of Damocles”. Although it was so massive and immobile that users needed to hang it from the cleaning to watch, it’s was quite a leap and that introduced the concept of wearable VR headset in the market.However, it was only after a few decades, in 1993, the consumer-focused VR products were released in the market by Sera VR. It was a massive leap, as for the first time, in 1995, the gaming industry saw the application of VR with Nintendo releasing it’s “Virtual Boy”.Even though Virtual Boy did not see much of a success, it led the way for other developments, which came out in the form of standalone VR products by the likes of Oculus Rift and HTC by the second decade of the 21st century. However, these devices were still not as portable, as they still required powerful hardware.Caption: Oculus RiftThen came 2014 when Google approached with its revolutionary Google cardboard, which they later upgraded as Google Daydream project in 2016. For the first time, we had access to a truly portable VR platform that did not require massive PC hardware but just smartphones to work.We can say that devices like Google Cardboard and Google Daydream were the first to stimulate a consumer-focused application of VR for the masses, which later found VR porn and 360 camera porn as few of the applications of the new portable VR technology. Users could watch regular smartphone content in VR and get a better experience.In 2020, we have been eyeing on developments like Oculus Quest, which provide a mixed reality experience by combining VR and AR into one device. Today, smartphone-compatible VR devices have gone much affordable, and now we are moving towards standalone devices that would allow direct VR streaming.Although such devices are already in the market, they are not as prominent as they should be for turning VR porn a regular experience for everyone. However, the adult industry is already taking the trend by storm, as content creators are coming up with all kinds of VR content, ranging from VOD streaming to live stream porn in VR.Top 5 VR Porn SitesA few years ago, there were hardly a few websites that offered even semi-immersive VR porn. Today, there are 100s of them with a high-quality and completely immersive experience in both on-demand and webcam VR porn format. Following is a list of top VR porn sites with best user experience and cost-effective plans:VRBangers: Stream up to 6k quality VR porn from more than 190 performers. Plans start from $24.95/month. The site is dedicated to VR porn only. You can live stream porn in VR or download for offline playback.VirtualRealPorn: Stream up to 5K quality VR porn with both interactive and non-interactive content from over 200 performers. The cheapest plan begins at $19.99/month. It’s the best site to go for VR porn Game Scenes to make the experience more immersive.WankzVR: Enjoy up to 5k quality immersive porn in VR with some awesome POV scenes in the catalog with other non-interactive scenes, too. The website features 360 camera porn from more than 300 performers and members get access to 31 additional non-VR porn sites. Its most affordable plan begins at $1.99 for 2 days.SexLikeReal: You can stream 6K resolution high-quality VR scenes from more than 1700 performers. It’s one of the biggest repositories of VR porn in the market, with membership plans starting from as lows as $29.99/month. You can find both interactive and non-interactive content on this website.BaDoingkVR: Offers high-quality VR porn in 5K resolution from over 300 performers. It has one of the best virtual theater experiences for plans starting at as low as 24.99/per month. Also offers a one-day trial for $1. If you want to enjoy VR porn on your smartphone with a decent VR headset, this is the website to go.How Virtual Reality Livestream WorksLast but not least, VR has created an impact on not just regular porn streaming but live webcam VR porn has also become a thing now. Today, both premium and free live stream porn sites have started conducting live VR and 360-degree streams to enhance their UX.If you have been running a live webcam site or thinking about building one, including porn livestreams in VR is indeed a great idea. In fact, it won’t demand much effort than setting up a regular webcam site using a turnkey webcam script. You just have to ask your streaming solution provider if they support VR live streaming.For example, if you have been using Wowza live streaming solutions, you can simply upgrade your plan and get their VR live streaming API to start streaming webcam VR porn. This is how a typical VR streaming works using such a solution on your webcam site:Source: WowzaThe same is also compatible with turnkey webcam scripts like xCams. One simple integration in your existing webcam site and you can allow your models to stream at up to 4K resolution in real-time. You don’t require any additional tech in your website. Your webcam models can rig their webcam for 360-degree streaming or purchase compatible webcams, while the rest can be taken care of by your streaming solution partner.Written byMaloney GrahamAdult Model and Adult Business Expert.Follow2 1 2 2 1 Virtual RealityVRVr ExperiencesVr DevicePornMore from Maloney GrahamFollowAdult Model and Adult Business Expert.More From MediumAre we going to take advantage of this small window of opportunity for change?Enrique Dans in Enrique DansAI Will Eclipse Moore’s Law As A Driver of Tech Innovation.azeemThe Complicated Politics of Palantir’s CEOBloomberg Businessweek in Bloomberg BusinessweekApple Silicon and macOS Big Sur, the Mac Gets Closer to an iPadCharles Tumiotto Jackson in Mac O’ClockWhy IBM Decided to Halt all Facial Recognition DevelopmentLimarc Ambalina in Data Driven InvestorThe Future of Construction and DronesMuza MarketingHow the Smart Home and the Internet of Things (IoT) May Materially Impact Non Catastrophic Peril…David WechslerDoes Job Automation Consider Gender Equality?Jurgen G in The StartupAboutHelpLegalGet the Medium app"
Building Reality…,https://medium.com/xrpractices/building-reality-793573ce6520?source=tag_archive---------8-----------------------,"Unity3d,Game Development,VR,Virtual Reality,Tutorial","As pain requires to be felt… reality requires to be perceived.Disclaimer: This article doesn’t deal with the philosophy around perception and reality, if you are here for such things, turn back… or find me... :POk, now that the romantics are gone… This article outlines a detailed technical approach to creating a virtual reality (VR) experience and designing interactions around it.We would be using Unity3D and building to Google Cardboard for the same.Let’s get this party started…1. Project SetupStart by setting up a basic Unity project, if in doubt refer to below article.Let’s get Started with Unity…Well let me tell you this won’t be the end all be all… This is just the beginning of a series of Journal log styled…medium.comYou can find the complete code at the following Repository (I’m using Unity3D 2019.4.4 but any 2019.4 should work). To get synced up you can use the following…git clone git@github.com:Neelarghya/reality-vr.gitgit checkout 1429b492. Setting up of SDKs for VR.Once the project is ready we will set up the SDKs required for VR.[Alternative] If you want to use GoogleVR (Since it simple to start with has good examples and docs, literally a dev’s … dream! XD) for the legacy GoogleVR (Legacy but Matured) feel free to follow the below article…Setting up Google VR in UnityA Quick-start for setting up Google VR (GVR)medium.comFor our case we would be targeting Google Cardboard using Cardboard SDK, refer setup below…Quickstart for Google Cardboard for Unity | Google DevelopersThis guide shows you how to use the Google Cardboard XR Plugin for Unity for Unity to create your own Virtual Reality…developers.google.com[Commit: 43a9fca]3. Setting up a basic SceneStart by organize the Scene into Player (0, 0, 0) > Head (0, 1.8, 0) > MainCamera (0, 0, 0) structure. Note the Head is at an height from the body we will come back to this later.Player and MainCamera set upAdd an environment to your Scene, I personally am a sucker for a Plane with a Grid texture and Pro-builder’s bathroom tile like wall material, so… :PLet’s also add something that looks intractable for good measure.Game view for the basic scene setup[Commit: 36f900d]4. “How is this VR..?”Start by adding a TrackedPoseDriver component to the MainCamera, this will sync up the camera’s orientation to the user’s head movement.MainCamera componentsNext we need to set up the whole VR context by configuring the XR-Cardboard Plugin. We will add a basic setup script to check for updates in the device parameters and to manage closing of the app, and add it to a GameObject....using Google.XR.Cardboard;public class CardboardSetup : MonoBehaviour{    public void Start()    {        Screen.sleepTimeout = SleepTimeout.NeverSleep;                if (!Api.HasDeviceParams())            Api.ScanDeviceParams();    }    public void Update()    {        if (Api.IsGearButtonPressed)            Api.ScanDeviceParams();        if (Api.IsCloseButtonPressed)            Application.Quit();        if (Api.HasNewDeviceParams())            Api.ReloadDeviceParams();    }}Adding CardboardSetup scriptNext thing we need is the basic intractability.public class GazeInteractionSource : MonoBehaviour{    [SerializeField] private float intractableDistance = 10;    ...We will start a basic script (GazeInteractionSource) with an exposed field (intractableDistance) which would define how close you need to be to the object to interact with.    private GameObject _gazedObject;    private PointerEventData _eventData;    private void Start()    {        _eventData = new PointerEventData(EventSystem.current);    }    ...We will also define two variables one to to keep track of the object we are focusing/gazing at (_gazedObject) and another would be the pointer event data we use to Invoke pointer event (_eventData).public void Update(){    UpdateInteraction();}private void UpdateInteraction(){    if (Physics.Raycast(transform.position, transform.forward,                     out var hit, intractableDistance))    {        if (_gazedObject != hit.transform.gameObject)        {            if (_gazedObject)                 _gazedObject.GetComponent<IPointerExitHandler>()?                            .OnPointerExit(_eventData);                        _gazedObject = hit.transform.gameObject;            _gazedObject.GetComponent<IPointerEnterHandler>()?                            .OnPointerEnter(_eventData);        }    }    ...So with every update we will check if a ray cast from the current object hits any other GameObject, if so that would be out newly gazed GameObject. We could call the OnPointerExit for the object that loses focus and OnPointerEnter for the object that gains focus.    ...    else if (_gazedObject)    {        _gazedObject.GetComponent<IPointerExitHandler>()?                             .OnPointerExit(_eventData);        _gazedObject = null;    }    ...And if the raycast misses we let the previously focus object lose focus and get rid of its reference.    if (_gazedObject != null &&            Google.XR.Cardboard.Api.IsTriggerPressed)    {        _gazedObject.GetComponent<IPointerClickHandler>()?                            .OnPointerClick(_eventData);    }}Finally when ever the cardboard api’s trigger is pressed we want to perform the click actions on the focused object.Finally Let’s add the script to our MainCamera, and an EventTrigger to out Intractable Object, also make sure it has a collider.Setting up interactions (GazeInteractionSource and EventTrigger)[Commit: e9c95e3]VR view, (screen recording)So what we get is the ability to look around and interact with different objects. This is where you can make a build and experience it in your VR Box/Cardboard.5. “How am I not gazing at it..?”That’s seems like an odd question, but that’s a very valid query when it comes to immersive designing, simply because gaze is subjective (unless you are using eye tracking). What I mean is the intractable point on the screen is only at the centre but as a user I am free to gazing at let’s say the top right corner of my FOV (field of view). So even if I’m gazing at any intractable object I might not be gazing at it (i.e. the raycast might not hit it). Thus visually representing the point of interaction is paramount! This point is represented by a Reticle/Gaze Pointer in most XR mediums. That’s exactly what we are missing…Start by adding a World Space Canvas as a child to the MainCamera.Setting up Canvas to display ReticleNotice the Event Camera and the RectTransform properties. Also there is a more advance way of displaying the reticle at the point of the raycast hit along with scaling based on distance to get around the parallax effect the current method has. But that would just bloat things.Let’s design a Reticle then!All you need though is some UI and animation to start with… For our purposes we will set up a basic Reticle with 2 animations one to hover and one to click. All in all things should look kind of like…Reticle’s Animator ControllerReticle Roll (in and out) and Click AnimationsOne call out don’t spend too much time on designing the reticle (…I spent way more time than I’m willing to accept on these god awful designs :| …)And more importantly you will need to add a material with a Custom Shader to the reticle that that will turn off the ZTest, i.e. render the reticle above the rest of the objects regardless of the Z depth that it has in the scene.What’s more important than spending 4hrs designing and animating a damn reticle is making it actually work with the gaze interactions… :PLet’s start by adding the events to our GazeInteractionSource class.public class GazeInteractionSource : MonoBehaviour{    [SerializeField] private UnityEvent onFocusIntractable;    [SerializeField] private UnityEvent onLoseFocus;    [SerializeField] private UnityEvent onClick;    ...We will update the Update function (:P) to accommodate for these events...    if (_gazedObject != hit.transform.gameObject)    {        if (_gazedObject)        {            _gazedObject.GetComponent<IPointerExitHandler>()?.                            OnPointerExit(_eventData);                        if (IsGazedObjectIntractable())                 onLoseFocus?.Invoke();        }        _gazedObject = hit.transform.gameObject;        _gazedObject.GetComponent<IPointerEnterHandler>()?                           .OnPointerEnter(_eventData);                if (IsGazedObjectIntractable())             onFocusIntractable?.Invoke();    }}else if (_gazedObject){    _gazedObject.GetComponent<IPointerExitHandler>()?                        .OnPointerExit(_eventData);    _gazedObject = null;    onLoseFocus?.Invoke();}if (_gazedObject != null && Api.IsTriggerPressed){    _gazedObject.GetComponent<IPointerClickHandler>()?                        .OnPointerClick(_eventData);        if (IsGazedObjectIntractable())         onClick?.Invoke();}...Also we will add a function to check if the currently hovered object if Intractable. (I will skip optimizations not to bloat this article)private bool IsGazedObjectIntractable(){    return _gazedObject.GetComponent<IEventSystemHandler>() != null;}Link the reticle’s animator to these events and you should be good.[Commit: 534acc3]6. “But I want to explore!”The worst feeling is to be in a new world but not be able to explore it! In the current state the user can only look around and interact with objects it feels restrictive so let’s add some movement to it…Let’s start by setting up a NavMesh for out Environment, and a NavMeshAgent to the Player (keep angularSpeed as 0). (Ref: https://docs.unity3d.com/Manual/nav-BuildingNavMesh.html)Baking NavMesh and adding NavMeshAgent to PlayerNext we need the Player to do is move or should I say navigate… So Let’s add a NavigationControllerpublic class NavigationController : MonoBehaviour,                             IPointerClickHandler{    [SerializeField] private NavMeshAgent playerNavMeshAgent;        public void OnPointerClick(PointerEventData eventData)    {        playerNavMeshAgent.SetDestination(                    eventData.pointerPressRaycast.worldPosition);    }}But we also need to set this worldPosition before we can use it properly. So in GazeInteractionSource.Update()… We update the _eventDate.pointerPressRaycast...if (_gazedObject != null && Api.IsTriggerPressed){    var clickHandler = _gazedObject                  .GetComponentInParent<IPointerClickHandler>();    if (clickHandler != null)    {        _eventData.pointerPressRaycast = new RaycastResult        {            worldPosition = hit.point        };        clickHandler.OnPointerClick(_eventData);    }    if (IsGazedObjectIntractable())        onClick?.Invoke();}...Also we can change all the GetComponents to GetComponentInParent keeping in mind child object can contribute to the colliders.[Commit: 3b9162a]With all that we should be ready to experience the Reality that we have built!A few lines of code here while a new skybox there and we have…Post polishing, view for userLook and feel, source: https://www.youtube.com/channel/UC64M3FR1UBOdn6cL9PnXbgA (self)[Commit: 36f08a9]…Wow still here, quite the journey! Hoping this gave you a head start in VR and looking forward to see the exciting things you folks would come up with! :DXRPracticesThis publication covers the AR VR MR practices in the…Follow34 Unity3dGame DevelopmentVRVirtual RealityTutorial34 claps34 clapsWritten byNeelarghyaFollowStuck between being the Fly on the Wall and the Eye of the Storm!FollowXRPracticesFollowThis publication covers the practical knowledge and experience of software development practices such as TDD, CICD, Automated Testing, Agile for ARVRMR development, and UX design. It is an open community initiative for and by the XR enthusiasts and is maintained by ThougthWokrs.FollowWritten byNeelarghyaFollowStuck between being the Fly on the Wall and the Eye of the Storm!XRPracticesFollowThis publication covers the practical knowledge and experience of software development practices such as TDD, CICD, Automated Testing, Agile for ARVRMR development, and UX design. It is an open community initiative for and by the XR enthusiasts and is maintained by ThougthWokrs.More From MediumOur Firebase Tech StackGeoffrey Bourne in The StartupLearn How to Learn How to ProgramLucas PenzeyMoog in The StartupDetermining the effectiveness of Selective Memoization to defeat ReDoSDionnetakudzwachasiAll Your Travel Plans in One Place With One WebsiteIrene Scott in The StartupHow to Stay Up to Date With Programming TrendsThomas Guibert in Better Programming[GSoC][LibreHealth] Work around for app freezing on READYash SarafHow to choose which programming language you should learn in 2019Ariel Camus in freeCodeCamp.orgHow To Iterate Over Two (or More) Lists at the Same TimeJonathan Hsu in Better ProgrammingLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Physical Spaces in Virtual Realities,https://uxplanet.org/physical-spaces-in-virtual-realities-cf11e9205f20?source=tag_archive---------9-----------------------,"Game Design,Game Development,VR,AR,Procedural Generation","Should VR Care About Physical Space?Respecting the user’s physical space is an integral part of keeping experiences authentic and immersive in augmented reality.If a user throws a virtual ball, the program should bounce the ball on their actual floors and walls. If they want to play a robot-shooting game in the living room, the game needs “know” about the room’s boundaries to generate well-placed robot-spawning portals.Footage of the AR robot-shooting game mentioned above, Dr. Grordbort’s Invaders.In contrast, virtual reality (VR) experiences typically do not rely on “knowing” the physical space — and understandably so. Since the essence of VR is to completely immerse the user in an experience, should the developer consider anything about the user’s real-world physical space?I say the answer is yes — and my explanation has to do with the limitations of movement in VR.Movement in VR — What’s Missing?Well, let’s imagine we wanted to create a VR version of the robot game. In the AR version, the robots “know” about the living room, bedroom, backyard, or wherever the user is playing. Thus, the program is able to spawn robots in appropriate locations, making them reachable to the user and guaranteeing the user’s ability to interact with them.The VR program would know nothing about the user’s space, so how could it ensure users can easily interact with the robots? The radius of the VR world would be fixed and practically endless — so where would the robots spawn? And if they spawn far away, how would the user get to them?VR developers would generally tackle these design challenges in one of three ways:Full Virtual MovementWith full virtual movement, users can walk/run/hop/etc. virtually while staying static in the real world. This is usually done using the controller’s joystick (Journey of the Gods) or adding point-and-teleport abilities (Half Life: Alyx).Journey of the Gods. Notice how the player remains static while the digital world movesIn some contexts, these methods would make perfect sense (say, teleportation in a Harry Potter game, or the joystick in a flight simulator).However, choosing all the movement to be virtual treats the user more like a camera than an actual agent. In the wrong contexts, this can feel contrived and weaken the immersion.Static SettingBuilding the virtual space around the user statically is another option. Here, the user doesn’t move in the world; rather, the virtual scene changes in front of the user. In the puzzle-platformer Moss, for example, the setting and perspective change with a fade in/out effect when the user finishes a level.Moss. Environments change around a static playerAs with full virtual movement, using static settings in the right context can also be a great design choice, especially if the experience wants the user to take on an observer role. This is exactly the case with Moss, which even refers to the player as the “Reader”.Limited MovementFinally, developers can use a mechanism that relies on physical movement. The resulting experience assumes the user can move a few steps in every direction, and all user interactions with virtual objects occur within this small radius of allowed movement. This can be seen in the arcade sport games Beat Saber and Racket NX.Beat Saber. Encourages player to move around within a small areaIn my opinion, this type of movement best leverages the VR medium. While many aspects in games like Moss and Journey of the Gods can be ported to flat-screen gaming consoles, it’s practically impossible to do the same for games like Racket NX, which powerfully utilize the headset’s ability to track the user’s movements.A Fourth Way?So — which of these methods would allow us to create the robot game Dr. Grordbort’s Invaders in VR? The closest would be deploying limited movement. But, as with the beats in Beat Saber or the racket ball in Racket NX, the robots would always have to approach the user.This is vastly different from the AR original, in which users are encouraged to physically explore the space, approaching robots themselves and avoiding projectiles with their body. Would it be possible to immerse the user entirely in a virtual world while also letting her move freely?Perhaps — but we would need information about the user’s play area. Until recently, such an input wasn’t readily available in VR. However, the new generation of Oculus headsets changed that — not only does it allow users to easily define the playable area, it also exposes this data to developers in the form of a play area polygon.Setting up the playable area with Oculus Guardian system. Saves players from accidents while playingUpon discovering the availability of this data, I had an interesting thought: what if we dynamically designed the environment given the polygon as an input? That is, instead of creating a predefined environment with fixed asset positions, we could use the polygon to generate custom environments that fit the user’s space.If we did, this input could be used for more than just protecting pinky toes from hitting table corners. We could program the robots to spawn in locations that the user can actually walk to. The actual boundaries of an experience could be presented using scenery, such as a fence or the sand on an island.More broadly, we could have a way to ensure the user can interact with our assets without relying on external movement mechanisms. Most people use VR in their homes, so why not have a tool to design experiences that scale to their living rooms?Tea For God. A game that utilizes the physical input to procedurally generate a mThe indie game Tea For God does something similar in a very refreshing way — and actually lets the player walk around (it even counts how many meters you hiked), but focuses on a rectangular play area. I wanted to take this and push it a bit further, building the entire environment around the play area polygon.Let’s Get PhysicalExample environment generated with the playable area input that Oculus provides.In my article Locomotion in VR: Procedural Generation of a Scene, I explore this idea with a technical walkthrough.This demo illustrates how the use of this input uncovers an alternative locomotion method: by utilizing the play area and building a custom environment, users can physically approach points of interest no matter the space constraints.For my demo’s design goals, the other methods would work, but do not feel quite right. Teleportation or joystick-ing would have been overkill given the island’s intended size (that of an average room). A static setting would feel artificial given that I want the user to feel they are on an island, not just looking at one. Limited movement would be unnecessarily limited.The solution I presented allowed me to create exactly the experience I aimed for: a person on an explorable island with objects they can approach and interact with.Several islands generated from various play areas in my living room.This tool may be a powerful addition to the VR toolkit. As I discussed in my article Virtual Reality — A Medium For Reimagining Human-Machine Communication, VR lets us explore more natural and intuitive ways of interacting with our devices, and new tools are needed.Whether used exclusively or in combination with other methods, this tool provides a new technique for customizing and scaling VR experiences. We can even adopt a new perspective on design: instead of having the user step into the environment, the environment can step into the world of the user.UX PlanetUX Planet is a one-stop resource for everything related to…Follow140 1 Sign up for Design newsBy UX PlanetGet the latest news from the world of UX design   Take a lookGet this newsletterBy signing up, you will create a Medium account if you don’t already have one. Review our Privacy Policy for more information about our privacy practices.Check your inboxMedium sent you an email at  to complete your subscription.Game DesignGame DevelopmentVRARProcedural Generation140 claps140 claps1 responseWritten byOmer PerryFollowEngineer | Gamer | VR PrototyperFollowUX PlanetFollowUX Planet is a one-stop resource for everything related to user experience.FollowWritten byOmer PerryFollowEngineer | Gamer | VR PrototyperUX PlanetFollowUX Planet is a one-stop resource for everything related to user experience.More From Medium5 Essential Laws for UX Designersuxplanet.org in UX Planet6 methods to understand the user in web designAli ÇORAK in UX PlanetHow to create a good onboarding and engage users from the startInês Bernardino in UX PlanetThe ROI of UX DesignPriyanka J in UX Planet5 Essential Properties Of Good Product DesignNick Babich in UX PlanetCheckboxes vs multi-select dropdown — A comparative studyVasudha Mamtani in UX PlanetAvoiding Bias in Survey Forms (a.k.a Skewing Research Data to Prove a Point)Christine Kane in UX PlanetUI/UX Future: Increasing Your ValueNick Lawrence in UX PlanetLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Pico Neo 2 Eye Review: Untethered 4K VR In A Tidy Little Package,https://medium.com/edtech-trends/pico-neo-2-eye-review-untethered-4k-vr-in-a-tidy-little-package-3f6559e53947?source=tag_archive---------0-----------------------,"Pico,Neo,2,Eye,VR","Enterprise-level Tobii eye-tracking and foveated rendering at an affordable price.The newly launched Neo 2 & Neo 2 Eye headsets from Pico Interactive are lightweight, untethered, deliver 4K, and look most like a beefed-up Oculus Quest. “Great!” I can hear VR enthusiasts and gamers around the world exclaim, but hold your horses. Closer inspection reveals these headsets are very definitely industry-only, at least for now.To be fair, Pico never said otherwise, and that doesn’t mean the package doesn’t present a value proposition for developers, and maybe a teaser of what that big consumer headset we are all waiting for will look like.Compatible with a wide variety Android peripherals, the Neo 2 features a comfortable and hygienic all-PU facial interface. A unique counterbalanced design allows for extended use, with plenty of room for prescription glasses. There’s also an SD slot for expanding memory and adding additional content.Pico’s Neo 2 line includes two headsets: the Neo 2 and the Neo 2 Eye. Both are all-in-one (AIO) devices with 6 degrees of freedom (DoF), head and magnetic controller tracking, wireless & wired streaming from a PC, spatial stereo audio, and BT 5.0 compatibility. The slightly more expensive Neo 2 Eye offers integrated Tobii eye-tracking and foveated rendering powered by their Spotlight Technology. This system scans your eyes 90 times a second and uses your own retina position for cursor control.Quality eye-tracking in an untethered headset is a big deal and enables companies to follow and learn a customer’s in-app behavior, enhance training efficiency, improve productivity, and possibly increase user safety in busy, shared work environments. Along with the eye-tracking comes dynamic foveated rendering, another big deal for a high resolution untethered headset. This translates into improved battery life through refined graphics performance, reducing shading load in some applications by up to 72% while increasing the possible frame rate by a supposed 66 percent.“Over the last two years, we have seen Tobii eye-tracking become a foundational technology that makes XR devices better and improves the user experience,” said Anand Srivatsa, Division CEO of Tobii Tech. “It is fantastic to partner closely with Pico on the extraordinary Neo 2 Eye and to enable enterprise and professional users to unlock greater operational efficiency, provide powerful user insights, enhancing training, simulation and product development capabilities.”Pico Neo 2 Specs:– Display: 4K resolution, 101 FOV, 75 Refresh. — Components: 845 Snapdragon, 128 GB Storage, 6GB RAM, Micro SD Card Slot. — System/SDK: Android8.1/Pico XR SDK/Qualcomm XR SDK. — Design: 2 Electromagnetic Controllers (6 DoF), Hygienic Replaceable PU Face Inserts. — Weight: Less than 340g without a headband, Counterweighted Battery for Maximum Comfort. — Audio: Integrated Spatial stereo speaker, Dual Mic EC/NR, 3.5mm Jack. — Connectivity: USB-C, BT 5.0, Wi-Fi 802.11a/b/g/n/ac, 2X2 MIMO Dual Antenna.Using Qualcomm’s 845 Snapdragon processor with Boundless XR, the Neo 2 also allows content streaming from a VR-ready PC and existing PC VR platforms over wireless 2X2 MIMO 802.11ac 5G link with a common MIMO 5G router. I was also pleased to see they also integrated Firefox Reality and Hubs by Mozilla. Firefox Reality is an open, accessible, and secure browser built specifically for mixed reality (including WebXR support) to create a better immersive web browsing experience. Mozilla’s Hubs allows users to collaborate online around virtual objects, spaces, and tasks — all without leaving their headsets.Before I get into how the Neo 2 Eye performed during my hands-on, it is important to address the inevitable comparison with the game-changing Oculus Quest as all my feedback — both good and bad — is framed around that comparison. To be blunt, the Neo 2 feels like a Quest with upgraded hardware and capabilities. However, when you first start it up and are presented with a Quest-like environment and menu system, it quickly becomes apparent that the Neo 2 isn’t the most consumer-friendly headset. But that is only because the available content is not there — yet.While the Quest may feature less powerful hardware, the content and software are what makes the device so damn user-friendly. It’s incredibly easy to jump in and start having fun. The Neo 2, on the other hand, is marketed as an enterprise headset, and while I have no doubt it would serve as a fantastic platform to build 4K resolution apps that can make the most of its impressive eye-tracking, rendering, and connectivity, the low-quality software and demos that are now available make the headset feel like a letdown when compared to the Quest. Most of the Neo 2 apps aren’t even in 4K, so apart from the menus, most of the content looked visually underwhelming.I was disappointed that Pico sent this for a review missing any preloaded software, links, or instructions to demo apps that might have exposed the true capabilities of this impressive headset. But that frustration aside, the Neo 2 Eye is nothing to be dismissed, as it is clearly a very exciting, professionally supported, blank slate. Essentially, it’s an impressive evolutionary step forward in untethered enterprise VR headsets on to which companies can build their own technology.“Few non-tethered headsets offer this level of visual quality, design and support,” said Henry Zhou, CEO of Pico Interactive. “We’re focused on ‘user first’ in all sense of the term and are constantly looking for ways to improve our product offering,” he added.I did come across a few hardware niggles in my testing that might present an issue for some. For instance, there is no manual IPD adjustment, and I could not find the digital one in the settings. This was a persistent annoyance and it made me feel a bit like my head was stuck inside a glass jar, with my vision compressed slightly on both sides. If IPD adjustment is digital, however, this issue could be addressed by software updates so might not be a deal-breaker as the product rolls out.Both the controllers and the headset are ‘functionally’ designed, which means they are bulky and practical while not being ugly. They are hard-wearing and meant for constant heavy use, but it is worth noting that after 30 minutes I did start to feel some discomfort, specifically in my cheeks and ears.On the plus side, the battery is part of the adjustment strap, and the fact the weight is at the back of the head counterbalances the screen at the front nicely. I didn’t notice any neck strain at all while using the Neo 2 Eye. The padding is also composed of a super hygienic design that is comfortable, easy to clean, and replaceable.USB-C charging ports on the controllers and headset are practical and the firmware updates were quick and easy to install. The easy-access SD card slot will be a real time-saver for software testing or the quick swapping of demo content in a sales environment. All around the Neo 2 Eye is a practical solution for businesses, not a toy or gaming device.I have read some criticism of the high cost of the Neo 2 and the Neo 2 Eye, but as an enterprise solution, they offer great value for companies seeking a sturdy, visually-impressive headset that’s easy to use in a busy work environment — from a shop floor to an architectural office. When you consider that the Oculus Quest for business platform costs roughly $1000, the Neo 2 models actually offer more bang for your buck.The Neo 2 is now available for purchase at $699 USD and the Neo 2 Eye for $899 USD. More information on both headsets is available here. As Pico focuses on enterprise, these headsets are only sold directly to companies via a dedicated sales team spread across the globe, including offices in San Francisco and Barcelona. For more information visit Pico Interactive.Tech TrendsShowcase for the latest disruptive technology that is…Follow4 PicoNeo2EyeVR4 claps4 clapsWritten byAlice BonasioFollowTechnology writer for FastCo, Quartz, The Next Web, Ars Technica, Wired + more. Consultant specializing in VR #MixedReality and Strategic CommunicationsFollowTech TrendsFollowShowcase for the latest disruptive technology that is changing the education landscape globallyFollowWritten byAlice BonasioFollowTechnology writer for FastCo, Quartz, The Next Web, Ars Technica, Wired + more. Consultant specializing in VR #MixedReality and Strategic CommunicationsTech TrendsFollowShowcase for the latest disruptive technology that is changing the education landscape globallyMore From MediumA Guide to PC Building: Some Advice From My Experience Over The YearsAbheek Gulati in High Tech AccessibleMore devices don’t mean more intelligenceEnrique Dans in Enrique DansIris Xe Max: 5 Things You Need to Know About Intel’s First Discrete GPUPCMag in PC MagazineTwitter: the lights are on, but there’s nobody homeEnrique Dans in Enrique DansJust How Fast Is Apple Silicon?Michael Long in The StartupCan Augmented Reality Help a Struggling Industry Survive?Mark Persaud in Data Driven InvestorPhotoshop on iPad and 9 Other Exciting Announcements From Adobe MaxPCMag in PC MagazineNo, Your Smartphone Isn’t Secretly Listening to YouLara Hayes in The StartupLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
The Infinite Retina | Irena Cronin on The Artists of Data Science Podcast,https://medium.com/@theartistsofdatascience/the-infinite-retina-irena-cronin-on-the-artists-of-data-science-podcast-80fd9759a95e?source=tag_archive---------1-----------------------,"Spatial Computing,VR,Data Science,Podcast Recommendations,Podcast","On this episode of The Artists of Data Science, we get a chance to hear from Irena Cronin, the co-author of The Infinite Retina.She currently serves as CEO of Infinite Retina, an organization which provides research and business strategy to help companies succeed in spatial computing. She gives insight into what sparked her interest into spatial computing, how she sees spatial computing influencing our world, and the potential data problems that will result from more spatial computing technology.Irena shares with us what led her from leaving her career as an equity research analyst on Wall Street to working with AR/VR and other spatial computing tech. This episode is packed with interesting insights in our future, and I believe anyone listening will have something to ponder on!Some notable segments from the show[8:15] Some concerns with spatial computing[11:10] What makes us human, and how it related to spatial computing[17:20] The four technical paradigm shifts[28:56] How spatial computing and autonomous vehicles will shape our future[43:12] Advice for women that want to break into techWhere to listen to the showListen to the episode on Apple Podcasts, Spotify, Overcast, Stitcher, Castbox, Google Podcasts, TuneIn, YouTube, or on your favorite podcast platform.Irena’s journey into spatial computingIrena was an economics major, and her education led her to become an equity research analyst on Wall Street. She spent 8 years working as an equity research analyst, and in 2015, she was introduced to VR through a friend of hers. Ever since then, she has focused her attention into this space.[3:00] “This is a nascent kind of industry. It’s going to still take a while for it to develop, but that’s what makes it really awesome.”Where is the field of spatial computing headed in 2–5 years?The field of spatial computing should be going more mainstream. Everyday people will start having access to this technology within the next few years.[6:53] “Okay, so it’s been leaked Apple is going to come out with their headsets on 2020–2023… However, in two to five years, it should be going more mainstream, so regular everyday people will be able to access and use it. Additionally, I’m currently working with a company called Mojo Vision, which is working on an augmented contact lens. So this is another way you could integrate spatial computing into your world.”Key takeaways from the episodeWhat is spatial computing?[4:09] Spatial computing is all the technology associated with bringing a 3D realm to it’s users. This encompasses artificial intelligence, computer vision, augmented reality, VR, sensor technology, automated vehicles, etc.Concerns of spatial computing[8:15] The biggest issue associated with the technologies associated with spatial computing is the data that will be coming in. Privacy is also a concern, and details around privacy will need to be hashed out regarding what information companies will be collecting. Another concern is tech addiction, which will only get worse with spatial technology.The four technical paradigm shifts[17:20]1) The desktop computer: everyday people begin using computers2) Graphical interface: everyday people can now use interfaces without having a technical background. Example would be being able to print a document by clicking “print” rather than running a command to do so.3) Mobile: phones become cell phones, and computers become laptops.4) Spatial computing: combines all of the previous aspects and adds a third dimensionality.Spatial computing and autonomous vehicles shaping our future[28:56] Autonomous vehicles can affect our culture in various ways. One example is that these vehicles can be used to bring things to you, rather than you having to leave to go somewhere. This is similar to us watching movies on Netflix in our homes, rather than going to the movie theater. Secondly, these vehicles will allow for the decentralization of cities. Public transportation will not be needed anymore, and commuting to work takes on a whole different meaning.Being a woman in STEM[43:12] The most important thing women can do is be extremely persistent. Any setback, whether real or imaginative, should not stop someone from going after their goals. Obviously, everyone needs to learn certain technical skills to succeed, but the continuous persistence is the key.Memorable quotes[16:59] “Technology…it’s always been a tool for us. But even more so with spatial computing.”[43:12] “I’d say the most important thing you can ever do is to be extremely persistent, no matter what”[44:42] “I think it’s extremely important to have professors and the students in a class, …take time to listen to everyone who wants to speak… and not let anyone monopolize that precious time.”The one thing that Irena wants you to learn from her story[46:12] Just do what you want to do and don’t let anybody stop you.From the lightning roundBest adviceDon’t always listen to others’ advice, even if it seems to be well intentioned.Saying on billboardHave courage to do what you want to do.Advice to 18 year old selfTravel more.Topic outside of data science we should studyBehavioral science. You need to understand people, and how data affects people.Recommended bookAnimal Farm by George Orwell.FIND IRENA ONLINEInstagramTwitterLinkedInEpisode TranscriptYou are welcome to share the below transcript (up to 500 words) in media articles (e.g., The New York Times, LA Times, The Guardian), on your personal website, in a non-commercial article or blog post (e.g., Medium), and/or on a personal social media account for non-commercial purposes, provided that you include attribution to “The Artists of Data Science” and link back to the https://theartistsofdatascience.fireside.fm/articles URL.For the sake of clarity, media outlets with advertising models are permitted to use excerpts from the transcript per the above.The transcript for this episode can be found here.Full episode on YouTubeWritten byThe Artists of Data ScienceThe ONLY personal development podcast for data scientists.Follow1 1 1 Spatial ComputingVRData SciencePodcast RecommendationsPodcastMore from The Artists of Data ScienceFollowThe ONLY personal development podcast for data scientists.More From MediumCosts and performance lessons after using BigQuery with terabytes of dataAntonio Cachuan in DataSeriesArithmetic Mean and Its Applications in Data AnalyticsMahbubul Alam in Towards AINeural Network on Beer DatasetOscar Rojo in The StartupGroup Manipulation In R — 3Vivekanandan Srinivasan in Analytics VidhyaPredicting Incumbent Party Vote ShareRidley LeisyLearn to Find Topics in a Text CorpusSooraj SubrahmannianA diagram type for a niche data use caseSuperdot in Superdot25 ways to excel with ExcelHelen Anderson in Analytics VidhyaAboutHelpLegalGet the Medium app"
AR/VR Revolutionizing the Automobile Industry,https://medium.com/@vrarmr/ar-vr-revolutionizing-the-automobile-industry-ad0abb440b0?source=tag_archive---------0-----------------------,"Augmented Reality,Virtual Reality,Automobile,Cars,VR","Buying an automobile can be strenuous, whether it is fancying a model or choosing the right interior — especially viewing the plethora of options available. With recent advancements in AR and VR, the automobile industry is staring at immersive technologies to help them overcome these challenges in an affordable and scalable way.Brands in the Automotive Industry are under ceaseless obligation to reduce time-to-market, overcome cost, and enhance the quality of the product. Given these demands, Automotive Industry is using VR/AR pertinence across the product life cycle — Design, Production to Deals & Marketing.VR use cases in the automobile industryA car often exhibits an individual’s character. As previously stated, with the help of AR/VR, automotive companies are now equipped to create a more personalized retailing platform for their customers. Immersive reality can help businesses form a deeper sentimental kinship with their clients.1. Virtual Car SimulationIt is a superior driver aid system bulging real-time erudition to help a driver stay more focused. This data is exposed to the windshield and generally consists of warning signals, speed, engine status, navigation, and more. Although many carmakers have previously implemented this technology, its full potential is yet to be unleashed.The most prominent edge of this technology is that the stereoscopic image can fix the driver’s viewing angle. Navigational information, directions, and signals can now be grasped by drivers as a part of the road. This will most aptly have a literal impact on security because drivers won’t be distracted by other sources of information from phones or built-in screens.2. Immersive ShowroomingOpening a car dealership is a vital but rather high-priced move. The aggregate cost of furniture, rent, demo cars, inventory, and paychecks make it merely a viable venture, notably for smaller carmakers. Nevertheless, R technologies permit car retailers to subdue the showroom size, cut costs, and intensify customer encounter all at the same time.When in a virtual showroom, clients can sit on a seat that simulates a real car chair and get a real-time sense of driving this particular car. Moreover, a buyer can change the car’s contour or color in a matter of seconds by themselves.3. Virtual PrototypingMany alterations and late disclosure of design flaws are amid the major predicaments in acquiring a new car model. Building a new prototype is often costly and time-consuming. However virtual prototyping is commonly used by all the preeminent car manufacturers, VR exerts this approach to the next level.It helps both drafting and engineering units better fabricate prototypes in terms of capacity and size, and get a more precise view of how all vehicle parts are equated. This improves the chances to detect conception errors earlier, and better understand if there are faulty connections between vehicle parts.AR use cases in the automobile industryAR is on its way to reconstruct the employee training process in the automobile industry as well. AR tools allow new agents to be completely immersed in the rendering process without any risks.Adopting AR for Self-ServicingThe exceptional thing about augmented reality is that it allows users to associate with the real-world using tech-supported graphics. For things that can be easily resolved without troubling a mechanic, operators can provide this technology for self-service. It could be for more intricate tasks, like making sure that all of the installations are properly configured under the shade or simple ones like how to put wrap-around washer fluid in your new car. Even if it is something the customer can’t fix without going to the mechanic, clients can also use AR to get an idea of what is wrong with the vehicle before taking it in. This will make the relationship between manufacturers and the customer more transparent.ConclusionVR and AR can assist car companies cut the time-to-market and require costs for designing and welding vehicles. Used for training, the immersive technology enables car brands to exceedingly speed up and advance the training process and, as a result, boost their productivity.Moreover, car dealerships can double their values by conceding customers in immersive reality to customize their dream car and then safely test-drive it. Our immersive technology can also significantly cut time to market for self-driving-cars by speeding up its safety system testing.In other terms, the automotive industry can significantly serve virtual reality and augmented reality by employing this technology for several use cases.VR | AR | MR is the world’s fastest-growing Virtual Reality and Augmented Reality company. We employ cutting-edge immersive technology to advance service technician tools, assistance in skills training, and provide remote services to Businesses, Anytime, Anywhere.For more similar solutions specific to your industry visit www.mrarvr.inor contact us at ashutosh@mrarvr.inDon’t forget to give us your 👏 !More similar contentVR AR MR on LinkedIn𝐕𝐑 𝐒𝐇𝐀𝐏𝐈𝐍𝐆 𝐓𝐇𝐄 𝐀𝐔𝐓𝐎𝐌𝐎𝐁𝐈𝐋𝐄 𝐈𝐍𝐃𝐔𝐒𝐓𝐑𝐘 VR has become an indispensable phase for the car…www.linkedin.comWritten byVR | AR | MRVR | AR | MR is the world’s fastest-growing Virtual Reality and Augmented Reality Company.Follow7 7 7 Augmented RealityVirtual RealityAutomobileCarsVRMore from VR | AR | MRFollowVR | AR | MR is the world’s fastest-growing Virtual Reality and Augmented Reality Company.More From MediumYour modern kitchen appliances probably won’t catch fire — yes, even Crock-PotsPopular Science in Popular ScienceThe Future of Data Centers Might Be UnderwaterSarvesh MathiAmazon Is Invading Your Home With Micro-ConvenienceIan Bogost in The AtlanticThe Secret and Frustrating Life of a Google Contract WorkerBloomberg in BloombergMicrosoft: Nobody Is Asking for VR on XboxPCMag in PC MagazineFord Tests Folding and Walking Delivery Robot — Market Mad HouseDaniel G. Jennings in Future VisionIf you’re not Breaking Rules you’re Doing it Wrong — Bittorrent Lessons for Crypto (2 of 4)Simon MorrisHow to Free Up Space on Your Apple WatchPCMag in PC MagazineAboutHelpLegalGet the Medium app"
"<strong class=""bt"">US Pharma — Time to Configure for Verifications</strong>",https://medium.com/@info_70242/us-pharma-time-to-configure-for-verifications-2f6482e2f139?source=tag_archive---------1-----------------------,"Pharmaceutical,Counterfeit,Dscsa,Vrs,Verification Services","Less is MoreWhy less is more in the world of Product Verification.The second major phase of the Drug Supply Chain Security Act is just around the corner. If you are a manufacturer you’ve already got unique serial numbers out there on all of your products destined for sale into the United States market. Now your verification router service provider is asking you how you want to answer questions about your products. The standards around verifications offer some flexibility on how certain responses can be returned to the inquiring party. While your first reaction may be to offer as much information within the return message as to why you just refused to verify one of your products, this article is here to persuade you otherwise.Verifications can be negative for multiple reasons, ranging from a request that is for a nonexistent product line a simple GTIN does not exist response to a nearly right, good product, bad product identifier request. At this second level, nuanced responses are possible but we would advise you to veer away from them. The GS1 lightweight verification messaging standard as adopted across the industry allows manufacturers some discretion on how much detail they return within the message and your system providers can all technically support the more detailed responses. Please don’t take them up on the offer. When requesting a verification during testing, knowing that the serial number is the only error and that all the other identifiers exist within your data is extremely useful. In a live environment, it is a free gift to any counterfeiting bad actors out there.The FDA requires that only Authorized Trading Parties are able to send verifications. All service providers are all implementing checks, both on setup and on an ongoing basis that the companies using their platforms are genuine participants. BUT the standards allow users to manually enter data (in our other platforms we require the user to scan a physical item, and for secure systems, we capture the background image as users scan, to help ensure that the label is on a physical product and has not been regenerated to trick the system.) It only takes one bad employee in an otherwise honest company to misuse the system and fish for good product identification codes to copy and counterfeit to turn the work achieved by the industry for DSCSA against itself. For these reasons we urge all manufacturing participants to opt for the ‘no-reason-provided' option on a response that could otherwise specify if an enquiring party has got the serial, batch, or expiration date incorrect. Your distributor won’t deal with the unverified product any differently, you’ll still know why it failed and the bad guys won’t get a data point they can use against you or your patients in the future.For more on Pharmaceutical Verification see www.track.one/cloud Verification Router Services for all sizes of Master Authorization Holders. For more on Authentag see www.Authentag.comWritten byAuthentagMaking the world's supply chains safer, one item at a timeFollowPharmaceuticalCounterfeitDscsaVrsVerification ServicesMore from AuthentagFollowMaking the world's supply chains safer, one item at a timeMore From MediumMarking the Polluting Industries along Ganga with QGISShashank Singh in Shashank SinghAre more ideological European political parties more popular on Twitter?Kat Devlin in Pew Research Center: DecodedSurvival of the Fittest: Can Hollywood Adapt?Natasha Malpani Oswal in The StartupApache Cassandra for Structured and Semi-Structured DataMunish Goyal in The InnovationPredicting Mother NatureDaniel ChoLearnings from a Data Science Conference, Open Data Science EuropeRebecca Vickery in vickdataA Data Science Approach to Choosing a PhysicianAmeen Al-Khafaji in The StartupBinary Decision TreesPackt_PubAboutHelpLegalGet the Medium app"
Ethical challenges in AR/VR,https://medium.com/@javier.gutierrez.cruz/ethical-challenges-in-ar-vr-68e2b94a8571?source=tag_archive---------2-----------------------,"Augmented Reality,Virtual Reality,Mixed Reality,AR,VR","Photo by stephan sorkin on UnsplashAugmented Reality and Virtual Reality have been with us for more than we think and it is not as recent as we think“The origin of augmented reality (AR) and virtual reality (VR) came way back in 1838, when Charles Wheatstone invented the stereoscope. This technology used an image for each eye to create a 3D image for the viewer. 1”Even though development on these technologies has been done for some years back, it has not been since a few years back that it has really made an impact in the tech scene, due to the fact that the hardware has become smaller and cheaper thru the years making it more portable, more realistic and less expensive to produce as well as to market them.This has led to multiple companies to start exploring the different uses of this technology in diverse sectors such as education, entertainment, health, and industry among others. Being that its possible applications are so vast we now have all types of companies not just big tech companies, involved in the development of products but also thousands of start-ups entering the market with their product may that be hardware or software for the multiple gear sets offered today.With competition between content and hardware creators, accessible prices and a variety of products it has become more common to have some sort of access to Augmented Reality, Virtual Reality or Mixed Reality technologies and with situations such as 2020’s pandemic “consumer spending on reality technologies is projected to reach $7 billion, and distribution and services spending on the technologies could reach $4.4 billion.2”, we get closer to the idea that it may soon be a part of every household or company which has or plans to adopt it, to allow better interaction between costumers, products and employees during this bizarre and for the time being, new reality.But with the increasing expansion of Augmented Reality and Virtual Reality, there come some issues that will and have to be addressed as there is the possibility for abuse in the case of privacy and data collection, harassment, social isolation, and others that we will be discussing along the way.Privacy and Data CollectionOne of the most talked-about issues is Privacy and data collection, which is a part of the data protection area that deals with the proper handling of data.“This includes how data should be collected, stored, and shared with any third parties, as well as compliance with the applicable privacy laws.3”With this type of new immersive technologies, privacy is a big concern as it provides a platform for collecting information “that to date has not generally been collected, certainly not in any broad-scale. 4”.There are new types of information that companies will be able to collect, for example, we can customize our avatar for the virtual world to mirror our real-world allowing for our movements and gestures, “Motor intentions” and “kinetic fingerprints” to be tracked, read and used by all sort of entities for their own benefit.With the use of VR technologies, user psychological responses to certain environments such as eye movement or heart rates can be exploited for economic benefit as it would be valuable information for consumer research. This information could be used by companies or even authorities to analyze employee’s or citizen’s physiological “well-being” without their authorization and used to fire or red-flag any of them.Real VS Virtual worldWith time both Virtual Reality and Augmented Reality have made huge leaps in their development as mentioned before, this has allowed them to achieve levels of realism that are closer to real-world experiences. This has been called hyperrealism and it has brought to us virtual experiences that feel very real.This has brought some questions related to social isolation. Even though developers are creating not just single-player experiences but like in the case of Facebook “have been busy inventing communal meeting places like Spaces, which help VR users meet and interact in a virtual social environment.” The question still lingers how it could affect extreme immersion into these spaces, especially as the main users, such as it happens now with console games, are mostly teenagers.It has been argued how can these virtual forums, detach users from their real-life “Studies have already demonstrated that our existing social media consumption is making many of us feel socially isolated, as well as guilty and depressed.”In the use of game consoles, it has been common to find people totally absorbed by video games, spending most of the time playing and not interacting in the real world and having their mothers, girlfriends, and even wife’s fighting for attention against a piece of microprocessors and plastics.Psychological impactOne topic that worries is the dangers in psychological effects even though there is not enough that yet, there are several aspects experts are worried about, one of them being “depersonalization,” “which can result in a user believing their own physical body is an avatar.”As mentioned before due to the hyperrealism Virtual Reality offers there is a worry that in gaming for example the experience could lead to real-life post-traumatic disorders or even desensitization. Desensitization can be more troublesome in younger users who have less real-life experience but will be exposed to virtual ones that are far from everyday normality. What are the consequences of a young user playing a Virtual Reality game where a character has no respect for his counterparts what are going to be his views on gender, race, and even respect to animals?Another point to take into account is the use that Virtual reality can have in the medical fields, doctors can treat patients with phobias for example in a very realistic but controlled environment, but what will happen if users are confronted with worst fears without any supervision for example in a game, what could be the outcome both physically and psychological of that experience is yet to be fully researched and documentedConclusionsVirtual Reality and Augmented Reality are here to stay, their development has come in huge leaps of advancement.It has provided an entirely new and exotic frontier that couldn’t be explored before. It has created jobs, and uses that can help most of society by implementing its use in industries like medicine, where it is has become a powerful tool to treat certain patient’s conditions like phobias and post-traumatic disorders among others in a new and more effective way than before. It has helped to educate youngsters and adults alike by transporting them to Africa, Asia, the Amazon, or back in time to ancient worlds allowing for education to be as dynamic and interactive as it has ever been. It allows doctors, engineers, firefighters, and many more to train in the most realistic sceneries, but without the actual dangers, to be prepared for when their skills are required.But like any new emerging technologies, there are unchartered ethical and legal territories that have to be explored. A lot of information is going to be collected that wasn’t been collected before and who knows who is going to be storing our data and what use it is going to have, and imagine if it was hacked? It will not be just a credit card or social network password.Also, continuing research has to be done to further understand the phycological impact of Virtual Reality usage, both in children, teenagers, and people who will be presented with situations that they are not prepared without the proper professional guidance when confronting those fears.Like any new technologies, there is still a lot to learn but the prospects of what Virtual and Augmented Reality can offer are limitless.ResourcesInfographic: The history of AR and VR, and what the future holdsDid you know augmented and virtual reality started in 1838? Check out this infographic for more information on the…www.techrepublic.comPandemic could lead to higher AR, VR adoptionA Coresight Research report emailed to Retail Dive estimated that the reality technology market, which includes…www.retaildive.com5 things you need to know about Data Privacy - Data Privacy ManagerIt is a broad term, but essentially data privacy is a part of the data protection area that deals with the proper…dataprivacymanager.netVirtual reality is booming in the workplace amid the pandemic. Here's whyVirtual reality usage is booming in the workplace as companies use it for training, customer service, hiring and work…www.cnbc.comWritten byjavier gutierrezFollowAugmented RealityVirtual RealityMixed RealityARVRMore from javier gutierrezFollowMore From Medium11 Practical Tips for Successful Schooling at HomePCMag in PC MagazineSilicon Valley Abandons the Culture That Made It the Envy of the WorldThe Atlantic in The AtlanticThe Best Weather AppsPCMag in PC MagazineEverybody Wants to Take a Bite Out of Big TechBloomberg Opinion in Bloomberg OpinionOne Google Staffer Fired, Two Others Put on Leave Amid TensionsBloomberg in BloombergVirtual RealityShivu Chauhan in The StartupWhy More People Should Consider Wearing Bone Conduction HeadphonesPedro Costa in The StartupPlease Feed the LionsThe SpaceAboutHelpLegalGet the Medium app"
Mary Shelley + VR,https://medium.com/@jackylee0424/mary-shelley-vr-e5b8ca8f7529?source=tag_archive---------3-----------------------,"Science Fiction,Frankenstein,Shelley,VR","“It was on a dreary night of November…I collected the instruments of life around me, that I might infuse a spark of being into the lifeless thing that lay at my feet.”, Mary Shelley writes at the beginning of chapter five of Frankenstein. She is a novelist, activist, and a poet who is also recognized as the first author of the Sci-Fi genre.“We will each write a ghost story,” said Lord Byron.Percy Shelley, Mary Shelley, Lord Byron, and you are having a ghost story contest.“The Year Without a Summer”It is 1816. Mary Shelley, Percy Shelley, and Lord Byron stay at the Villa Diodati near Geneva, the villa once occupied by John Milton, author of Paradise Lost. Summer temperatures in Europe happen to be the coldest on record accompanied by heavy thunderstorms. As Shelley recalls during her trip “never was a scene more awfully desolate”.Villa Diodati near Geneva was once occupied by John Milton, author of Paradise Lost.Lord Byron’s Darkness“I had a dream, which was not all a dream. The bright sun was extinguished, and the stars.“Byron is the only one who can write under this climate anomaly, as he is working on the 3rd canto of Childe Harold. He also completes a catalytic poem — Darkness. Milton’s shadow animated by lightning amidst the darkness transitions their discussions into electricity and galvanism.John Milton’s Paradise Lost illustrated by Gustave Dore (left). Galvanism to re-animate the dead (right)Shelley’s CreationIn ScienceVR, we re-create the scene from 1816, so that our users can answer Mary Shelley’s question:“Would life be given? Perhaps a corpse would be re-animated; Galvanism had given token of such things: perhaps the component parts of a creature might be manufactured, brought together, and endued with vital warmth.”In Alien: Covenant, David, the android, asks a similar question and starts his journey of understanding whether creation can become a creator.“May I ask you a question, Father?”“If you created me, who created you?” asked David.ScienceVR’s upcoming lab — Shelley’s Creation made with Unreal Engine.“My dreams were all my own; I accounted for them to nobody; they were my refuge when annoyed — my dearest pleasure when free.”Mary Wollstonecraft ShelleyAug. 30, 1797–1851ScienceVR’s Shelley’s Creation preview—Thanks to Nathalie and Jason for reviewing this draft. Thanks to Lisa for her voice.Written byJackie LeeFounder @sciencevr AWE Nextant Rising Star 2020. MIT Media Lab. Affective Computing. Intel RealSense. RockHealth. Oculus Start/Launch Pad 2020. Epic MegaGrantsFollowScience FictionFrankensteinShelleyVRMore from Jackie LeeFollowFounder @sciencevr AWE Nextant Rising Star 2020. MIT Media Lab. Affective Computing. Intel RealSense. RockHealth. Oculus Start/Launch Pad 2020. Epic MegaGrantsMore From MediumA Biblical Scene: The Mountain That CollapsedMartina Petkova in History of YesterdayVanishedDale M. Brumfield in The StartupThe Racism Behind Street Names in Louisville, KentuckyZed Saeed in Louisville, KentuckyA Brief History of Fascism in the United StatesShawn HamiltonThe Horrors of Poison Gas in WWILauren Marie in History of YesterdayA Radar Blip, a Flash of Light: How UFOs ‘Exploded’ Into Public ViewThe New York Times in The New York TimesU.S. Bombs, the Khmer Rouge and Cambodian GenocideMarpheen ChannNadezhda Vasilyevna PlevitskayaThe Faded RiverbankAboutHelpLegalGet the Medium app"
Dark Room VR | Superhot Style Horror Game,https://medium.com/@nickhulse/dark-room-vr-superhot-style-horror-game-996aa058c7c3?source=tag_archive---------0-----------------------,"VR,Horror,Gaming,Gaming News,Indie Game","Dark Room VR is a free to play survival horror game developed and published by Royce Charles Fernandes launching on Steam for PC September 1st, 2020. This game is quite simple, you play as a character in the middle of a dark room trying to not be killed by a herd of demons coming to steal your soul.This game is very similar in many ways to the popular game ‘Super Hot’. You play from a first person perspective with a weapon in your hand looking from all angles as to where the person trying to kill you is coming from. The demons make soft and quiet noises from all angles but only slight, so stay aware of the sounds around you.This game is designed to work on PC for Oculus Rift and motion controllers.Written byNicholas HulseSpoopyGamesFollowVRHorrorGamingGaming NewsIndie GameMore from Nicholas HulseFollowSpoopyGamesMore From MediumVR Games to Play in LockdownBlueBubbleBee in SUPERJUMPAnimal Crossing: New Horizons’ Firework NightLizzie Bestow in SUPERJUMPVictor Vran Console Version ReviewAlex RoweThe Rise (and Further Rise) of Pokemon Go: product lessons learned from the hit gameEric FengTeaching about Marginalized Voters through Games: Avian CityJailene Enriquez in Design for Understanding: CS 247i Fall 2019Big Kids in Tough TimesJacky TangTurn Your Game Boy Advance into the Console You’ve Always WantedCameron Coward in Hackster BlogInterview with Vladimir Kurochkin, President of The AbyssThe Аbyss Team in The Abyss PlatformAboutHelpLegalGet the Medium app"
Aardvark and Augmented Virtual Reality,https://medium.com/@joe_28841/aardvark-and-augmented-virtual-reality-7bf018e04b84?source=tag_archive---------0-----------------------,"VR,Virtual Reality,Augmented Reality","Applications vs. ToolsOften when a user wants to do something in Virtual Reality, they want to be immersed in an experience. The thing could be bashing monsters in Skyrim, it could be visiting digital worlds with people around the world in VR Chat, or it could be creating artwork in Tiltbrush. This experiences forms the backbone of every user’s time in VR. They are the base-level reality that users are opting-into when they put on their headset. They expect to spend somewhere between tens of minutes and several hours in these experiences before they take the headset off and pop back out to the real world.But there’s another kind of interaction that many users want that is poorly served by building it into a full immersive base-level world. These are the kinds of things that you would do for seconds or minutes at a time, rather than hours. They’re also tools or applications that run in the background while you’re doing other things. They are things you would do while waiting at a load screen, or while taking a breather before diving into the next quest.In many ways, the tools I’m talking about here are the same things you would use your smartphone for in the real world: checking email, yelling at somebody on Twitter, streaming music from Spotify, getting a notification that you’re about to be late for a meeting from your calendar, or pulling up a note-taking app to write down something you want to remember later. Almost none of these applications exist in VR.OverlaysA few early steps have been made in this direction. In 2015, SteamVR added an overlay interface that allows applications to draw rectangles of arbitrary content on top of whatever main app the user is running. That was later extended to support 3D panorama. This has resulted in a few applications: OVRDrop and OVR Toolkit let you interact with desktop windows from inside VR, PlutoVR lets you chat with your friends, and Turn Signal tells you when you should turn left instead of right to avoid wrapping yourself up in your tether. Oculus later built similar desktop window functionality into their system direction with Dash 2.0. Building these applications has turned out to be challenging for developers, however, and they have not arrived in the quantities I expected when the overlay interface was first coming online.The biggest reason for that is that the existing overlay interfaces expose the wrong set of primitives. They allow applications to produce 2D textures and accept “laser mouse” input from the system. Exactly how to wrangle a UI system into producing off-screen textures is left as the developer’s responsibility. If the developer wants to draw something move complex like a 3D model the difficulty increases significantly. Laser mouse interfaces work for 2D desktop windows, but most other applications need some kind of 3D spatial interaction if they really want to be VR-native. Existing overlay interfaces don’t provide anything like that.AardvarkEnter Aardvark. Aardvark is an Augmented Reality layer that incorporates multiple applications, or “gadgets”, on top of existing VR worlds. These gadgets can come from any number of different authors and all draw and work together to provide the user with a set of standard tools they can bring from one VR experience to another. No gadget takes up your entire view; they are all expected to work in concert, not just with each other, but also without interfering with the base-level world that the user is currently in.An Aardvark gadget is inherently spatial. Instead of handing a 2D quad to be composited, a gadget provides a scene graph that can include quads, models, transforms, and any number of interactive components. This graph is then rendered together with all the other active gadgets’ graphs to produce a single layer on top of the base-level VR application. This eliminates strange depth behavior between gadgets. It also allows gadgets to interact with each other much more directly than is possible with overlay applications.Aardvark also brings the ease of deployment and development from HTML, CSS, and JavaScript into VR. Each gadget is essentially an off-screen browser “tab”. Gadgets can be bookmarked and reopened later and shared via URLs. They also be run on-demand when the user wants to use a gadget without the need to install anything. Deploying a new build is as simple as uploading to a web server. The gadgets themselves can be entirely client-side, or can contact back-end services using any network or streaming capabilities they could use in a desktop browser.Aardvark is an open-source browser that runs on Windows and can run over any SteamVR application on any SteamVR-compatible headset. It is now available as an alpha build you can download from GitHub. It is in good shape for developers to start building gadgets to fill in this empty middle ground in VR. If that sounds like you, go grab a build, read the documentation, run through the tutorial, and get started. If you run into trouble, hit us up in the slack and we’d be happy to help out.Celebratory HackathonTo spur everyone’s creative juices, we are running a virtual hackathon for Aardvark gadgets on September 25–27, 2020. You can sign up for that now. It should be a good time for one and all. If you don’t have an idea for your own gadget, that’s fine! We’ll be forming teams and there will definitely be opportunities for programmers, designers, artists, and more to help out.Written byJoe LudwigFollow71 Thanks to Jared Cheshier. 71 71 VRVirtual RealityAugmented RealityMore from Joe LudwigFollowMore From MediumProperty Getters and Setters in SwiftSteven Curtis in The StartupIntroduction to Linked Lists in CSahil Bhosale in Better ProgrammingLinux Productivity: Integrate Web Apps and the DesktopAl Williams in For Linux UsersPerformance of Regular ExpressionsMaciek Rząsa in TextMaster EngineeringHow to Make Your Website Themeable With CSS VariablesAli Kamalizade in Better ProgrammingProgressive Front-end CI on Github Actions.Sviat KuzhelevSorting in pythonAshok Kumar in Analytics VidhyaWatch Multiple Namespaces With Cass OperatorJohn Sanda in The StartupAboutHelpLegalGet the Medium app"
"<em class=""ec"">Making a New Reality Toolkit</em>",https://immerse.news/making-a-new-reality-toolkit-provides-resources-for-boosting-equity-in-emerging-media-d5f1712c0b4a?source=tag_archive---------1-----------------------,"VR,AR,Diversity,Equity,Inclusion","Kamal Sinclair conducted more than 100 interviews for Making a New Reality, a series Immerse published in 2017–2018. Now, two years later, we are thrilled to launch a new toolkit based on her important work.With Making a New Reality: A Toolkit for Inclusive Media Futures, Jessica Clark and Carrie McLaren have updated and supplemented Sinclair’s original research with recommendations and resources to help readers further diversity, equity, and inclusion in emerging media.The project is available as a free PDF download or a beautiful, print-on-demand book. The Making a New Reality website also offers a few excerpts, as well as direct links to resources featured in the book’s solutions.As Clark writes in her foreword, quite a bit has changed in this short time: The pandemic. Protests over police violence. New, rising concern over social media, algorithmic opporession, and mental health. So, correspondingly, we made quite a few changes:We took the insights Kamal gleaned from her interviewees and research, and reorganized them around three key targets for action: things that each of us can do to increase equity in emerging media, ways that institutions can pitch in, and systemic interventions — which require collaboration across institutions, sectors, and governments. For each of these sections, we did original research to add resources designed to help readers get a better grasp on each recommendation, and find ways to move forward.We also stepped back and took a deeper look at what we meant by “equity” — not just in terms of race, but gender, class, religion, ability, and ideology.We hope all of our readers share this work and its long list of resources with your networks and contacts. And, as always, we welcome your feedback.Immerse is an initiative of the MIT Open DocLab and The Fledgling Fund, and it receives funding from Just Films | Ford Foundation and the MacArthur Foundation. IFP is our fiscal sponsor. Learn more here. We are committed to exploring and showcasing media projects that push the boundaries of media and tackle issues of social justice — and rely on friends like you to sustain ourselves and grow. Join us by making a gift today.ImmerseCreative discussion of emerging nonfiction storytellingFollow57 1 Some rights reservedVRARDiversityEquityInclusion57 claps57 claps1 responseWritten byMaking a New RealityFollowFollowImmerseFollowCreative discussion of emerging nonfiction storytellingFollowWritten byMaking a New RealityFollowImmerseFollowCreative discussion of emerging nonfiction storytellingMore From MediumThe Diffusion of XR and New Digital ParadigmsPHI in ImmerseMoving Towards, Moving BetweenPHI in ImmerseFeeling at Home: Between Human and AIlauren mccarthy in ImmerseHuman AssetsMark Atkin in ImmerseBefore Everyone Was Talking About Decentralization, Decentralization Was Talking to EveryoneAmelia Winger-Bearskin in ImmerseDismantling the Metrics of Empathy (in 360 video)Dan Archer in ImmerseWhen Machines Look for Order in Chaos~shirin anlen in ImmerseAlmost Human: Goodbye Uncanny ValleyOr Fleisher in ImmerseLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
VR & AR Parent & Student Resource #7,https://medium.com/vr-ar-parent-student-resource/vr-ar-parent-student-resource-7-2aee8c762d3a?source=tag_archive---------2-----------------------,"Virtual Reality,Augmented Reality,VR,AR,Edtech","StudentsOlivia Wenzel, Student & Founder of AltruTec, LLC, Ohio, United StatesEliot Advani, Student, Massachusetts, United StatesAlex Advani, Student, Massachusetts, United StatesAlex McNeilly, Student & Founder of Puzzil AR, Illinois, United StatesHelen Liu, Student, Massachusetts, United StatesMymoon Bhuiyan, AR/VR Group Team Leader for the Massachusetts Science & Engineering Fair Inc., Ontario, Canada/Massachusetts, United StatesShravya Anisetti, Student, Massachusetts, United StatesArnav Mishra, Student, Massachusetts, United StatesMentorsJulie Smithson, Co-Founder of MetaVRse, XR Ignite & XR Collaboration, Ontario, CanadaHelen Rosenfeld, Executive Director of the Massachusetts Science & Engineering Fair Inc.Fallon Brewington, CEO of the Boys and Girls Club of the Sandhills, North Carolina, United StatesReynaldo Zabala, Extended Reality Strategy Director of RazorEdge, Ohio, United StatesRohit Chaube, Co-Founder of VRoKCs, Kansas City, United StatesIntroductionTARGET AUDIENCE: Grades 6+In the previous issue, we reviewed tech terms, worked on building a house in Tinkercad, and learned how to create 3D models.In this issue, we will be introduced to new tech terms and learn more about making realistic, interactive 3D experiences in the fourth phase of the Curiosity Project.Tech Term RemindersGIF from MEL Chemistry VRImmersive TechnologiesImmersive technologies encompass virtual reality, augmented reality, and other related technologies that use 3D to create or extend a reality.GIF from NearpodVirtual Reality (VR)VR is a simulation of a 3D environment viewed through a headset. With hand-held controllers, gaze, or other means, the user is able to interact with virtual content.GIF by Chung-Yi Weng on YouTubeAugmented Reality (AR)This technology places an image (a hologram) in a user’s view of the real world through digital devices, such as a smartphone, tablet, or headset.New Tech TermsImage from CGTrader3D ModelA 3D model is a digital representation of an object that has length, width, and depth. Models are built from meshes, which you can read more about in Issue 6.GIF from GIFER3D AnimationAfter modeling a 3D object (and providing it a skeleton in skeletal animation), you can create a sequence of poses. When done carefully, this sequence can create the illusion of lifelike movement; i.e., an animation.Image from Entrepreneur MagazineCode and Programming LanguagesCode is simply a set of instructions that a computer can execute. These instructions can be written in a number of programming languages, some of the most popular being Python, JavaScript, Java, and C#. The result of writing these instructions is a computer program, which, taken together, make up immersive experiences.Image from CodeSnipperCode SnippetCode snippets allow us to easily reuse and repurpose old code and code from other sources. It can save a developer a significant amount of time when building a project.Image of WordPress from WPBeginnerLow-Code / No-Code DevelopmentInstead of writing instructions for your computer in a programming language, low-code/no-code development allows you to do so with a visual, often drag-and-drop-based, approach. WordPress is a popular example of a low-code content management system and website builder.Interactivity in VR/AR and its BenefitsImage from Orboot GlobeInteractivityInteractivity in VR/AR enhances learning. Its benefits in education and training include but are not limited to:Offering experiences that promote retention.Allowing for easier and increased engagement in classes.Expanding possibilities of what to learn and how.Permitting hands-on learning.Increasing the range of industries and topics that can be studied safely and feasibly.Promoting creativity and curiosity.Gazing, controllers, and hand motions are the primary inputs of VR (Image from Teague Design)Interactions in VR/AR come in many different forms. As you will soon learn, these interactions are largely dependent on their types of inputs. For a more in-depth explanation of the different types of inputs for VR and AR, read this addendum from the Curiosity Project Phase 2.Interactions in VRIn VR, the main goal of most interactions is to maximize the user’s sense of immersion. Interactions depend on the technology used and the type of input, as well as the features you want to include in your project.For example, a VR system that includes controllers, such as the HTC Vive Cosmos, permits swiping, tapping, dragging, holding, and scrolling up and down, among other inputs.Some VR systems, such as the Oculus Quest, allow for hand tracking. In this case, users can open and close their hands, pinch their fingers to shrink or enlarge an object, drag and drop items, or swipe to rotate an object.Mission: ISS is an educational game that takes advantage of the Oculus Quest’s 6 degrees of freedom Touch controllers: the user can float on the International Space Station in zero gravity and perform hands-on work that NASA astronauts do.Image from SpringerLinkInteractions in ARIn AR, the main goal of most interactions is to enhance the real world around the user with virtual content. AR’s interaction is dependent on the type of input, the type of virtual content, as well as the features you want to include in your project. An AR app’s interaction can also depend on whether the AR comes from a native app or the web.AR apps often allow you to modify or view virtual objects by tapping, scrolling, pinching, or swiping your device screen.For example, you might resize an object in your AR experience by pinching it to make it larger or smaller. Then, if you wanted to view this object from a different angle or have it spin 360 degrees, you might swipe it.Elements 4D by DAQRI is an educational AR mobile app where you can learn Chemistry by bringing elements to life and visualizing their chemical reactions. You can examine the elements at different angles and scales by swiping them or pinching them.Image of Elements 4D from DAQRIThe vast majority of AR experiences take place on a smartphone. These experiences are divided into native AR applications (where the app is built specifically for your phone’s operating system) and WebXR/Web AR.Unlike native applications, WebXR and WebAR don’t require the user to download and open an app. On the contrary, this group of web standards simply require the user to open up a browser.Video of ‘Hello WebXR’ demo by MozillaMetaVRse, as you might remember, is an online, browser-based 3D engine that allows you to create VR and AR projects. However, do not confuse MetaVRse’s online presence with WebXR/WebAR. The MetaVRse Engine provides a 3D engine on the web. It allows you to create VR, AR, and 3D projects on the web, not for the web.Curiosity Project Phase 4Recap of the Curiosity ProjectIn Phase 1 and Phase 2 of the Curiosity Project, we showed you how to research and brainstorm ideas for your prototype and create a wireframe for your immersive experience.In Phase 3, we explained where you could find 3D models online, what you could use to make your own 3D models, and how to make 3D models using 3D modeling software.Bring Your Project To Life!In this phase of the Curiosity Project, you will be inspired to add depth to your project, including the environment and interactivity.First, we will create a simple, interactive experience with the MetaVRse 3D Web Engine based on your wireframe. This will lay a solid foundation for an AR or VR experience.Creating a Simple DemoImage from Viar3601. Review the prompt and the problem you’re solving.You’re ready to dive into development. Before you move full speed ahead, ground yourself in the problem you’re solving. The Curiosity Project asked you to reflect on the following: What concept is difficult to learn in school? How could it be improved with 3D?ACTION: Answer the following questions in a sentence or two: What concept did you choose? Why is it difficult to learn? Who is experiencing this difficulty?2. Examine your idea and your wireframe.Now that you’re refreshed on the problem you’re solving and the audience you’re serving, take some time to extract the core features of your prototype and your wireframe. If needed, check back in Phase 2 or read this addendum from the Curiosity Project Phase 2. Note which features are crucial to solving your problem, to creating the desired user experience. You might categorize these by environment/setting, interaction, etc.ACTION: Choose one simple interaction to develop first. Then, decide how that interaction could be implemented with a button push. Here is an example: Assume your response to the Curiosity Project prompt is that it is challenging to visualize surface areas and volumes. So, you decide to create a virtual geometry classroom. For this particular step of the Curiosity Project, you isolate the feature of spinning a sphere that the user needs to find the surface area of. When the user presses a button, a model of a sphere spins.Video from MetaVRse Engine Tutorial Page3. Set up your project in MetaVRse.If you haven’t already, create an account on MetaVRse, and create a new project called “Curiosity Project” (or another title of your choosing).ACTION: Follow the second tutorial on the MetaVRse tutorial page to import the assets (3D models, textures, materials, etc.) you found and/or created in the previous phase of the Curiosity Project. (Note: You can import assets later in development as well.) Choose a few assets that are central to the environment, and follow the second tutorial on the MetaVRse tutorial page to place them in your scene. As in the above example of the virtual geometry classroom, an asset that is core to the scene and the experience is a sphere. So, in that case, you would import a model of a sphere.Video from MetaVRse Engine Tutorial Page4. Create a Heads Up Display (HUD) in MetaVRse.As stated in the tutorial, a HUD is “particularly useful when you want to have some buttons that appear 2D or fixed to the screen that interact with your scene”. This is indeed the case for the simple button interaction you’re implementing.ACTION: Follow the fourth tutorial on the MetaVRse tutorial page to create a HUD.Video from MetaVRse Engine Tutorial Page5. Implement the simple interaction.Now that the environment is set up in MetaVRse and you have your plan in place, you’re ready to add some interactivity.ACTION: Follow the eighth tutorial on the MetaVRse tutorial page to link the HUD button to a simple animation. In the case of the virtual geometry classroom and this tutorial, a press of the button would cause the 3D model to spin!Now that you have your simple interaction, you’re ready to start fleshing it out into a full prototype. This next section will walk you through building an environment for a VR, AR, or 3D project.Building An EnvironmentImage from VakomsTo build the environment for your immersive experience, you should look back to your wireframe again. Note the visuals, purpose, and whether your project is in AR, VR, or 3D.Remember, although AR, VR, and 3D projects are similar in many respects, there are key differences we need to consider as we dive into development.Image of a skybox from Unity 3DIf your wireframe is in VR, your project’s environment is a virtual world. When building your virtual environment, remember to take into account the 3D models, the 360° environment, and the way the user will interact in the experience with gestures and controllers.If your wireframe is in AR, your environment is the real world. Remember that AR content is overlaid digitally through your smartphone device camera on top of the real world. Therefore, you don’t need to build a virtual environment; you need to focus on the 3D objects represented in the augmented space.If your wireframe is for a “normal” 3D project, the focus of the wireframe should be the platform to support your models, their file size, and its interactivity. To power this interactivity, we will use code.Image of the MetaVRse Engine showing a menu on the right, where you can drag-and-drop code snippets to enhance your project.Code, Low-Code, and No-CodeEverything in your project, including the interactions, is powered by computer code. The properties and actions associated with your 3D model, for instance, can be altered by modifying its code or creating code that acts on it.The MetaVRse Engine is a low-code/no-code 3D engine. To animate objects and add interactivity to your experience, you can drag and drop code snippets. The editor opens JavaScript code in the engine to allow additional coding for those interested to scale the interactivity of the experience.To learn more about MetaVRse code snippets, take a look at this page and, if you haven’t already, watch this tutorial about JavaScript coding in the MetaVRse engine.If you wish to create a fully immersive, more interactive, and graphically intensive AR or VR experience, you can use an engine other than MetaVRse.VR and AR experiences require more complicated components such as intensive graphics. Those more intricate projects are usually created in 3D engines such as Unity or Unreal Engine and often require knowledge of programming languages such as C# for Unity and C++ for Unreal.Takeaway ResourcesCheck out this issue’s recommended resources, which build on our themes of creation, enlivening environments, and immersion.This “Think With Google” article dives deeper into the concept of immersion in technologies such as VR and AR. It also explains the potential of immersion with YouTube’s very accessible 360-degree videos.Made for the Oculus Rift, Quill is an illustration and animation app that brings a new experience to artists and VR users. Instead of just bringing life to technology, do it with technology!Image of Oculus QuillIdeas for this resource were fostered by the VR/AR Association Student Committee. Follow us on Facebook, Instagram, and Twitter @vrarastudents.VR & AR Parent & Student ResourceAn introduction to VR, AR, & 3D learning & their impact on learning & workFollow3 Virtual RealityAugmented RealityVRAREdtech3 claps3 clapsWritten byOlivia WenzelFollowFollowVR & AR Parent & Student ResourceFollowWe aim to support parents, students, and schools in adopting immersive technologies and 3D learning. This summer, we are focusing on inspiring curiosity and innovation through VR/AR/3D in youth.FollowWritten byOlivia WenzelFollowVR & AR Parent & Student ResourceFollowWe aim to support parents, students, and schools in adopting immersive technologies and 3D learning. This summer, we are focusing on inspiring curiosity and innovation through VR/AR/3D in youth.More From MediumIt’s Time for Digital Products to Start Empowering UsJesse Weaver in The StartupHow to Fix a Noisy Computer FanPCMag in PC MagazineWe will never escape emailColin HorganThe iPhone 12 Power Adapter ControversyThe Tasty CookieThere Is Nowhere to Hide From Trauma When You’re a Black Person on the InternetFast Company in Fast CompanyMagic Leap’s Possible Death Throes Have Little to Do With COVID-19Fast Company in Fast CompanyThis Silicon Valley Space Startup Could Lace the Atmosphere With MercuryBloomberg Businessweek in Bloomberg BusinessweekWhy are we negative about the future?Deborah Nas in The StartupLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
My wishlist for Oculus Quest 2,https://medium.com/@raymondmeester/my-wishlist-for-oculus-quest-2-4d96d69f66d4?source=tag_archive---------3-----------------------,"VR,Vr Experiences,Oculus,Oculus Quest,Facebook Connect","Though some of us suppress it, we all know that Facebook is the owner of Oculus for years. This became obvious again when recently the yearly conference Oculus Connect changed its name to Facebook Connect.The fact that Facebook owns Oculus, the recent name change of Connect and that in the near future you need a Facebook account to log in gives me mixed feelings. On one hand I desperately want that VR succeeds (and Facebook is a key player). On the other hand I want to distance me from how Facebook deals with users and their data.When product development and research is backed by such a big tech company it has much higher chance of success. Especially because Mark Zuckerberg really takes VR seriously. Sometimes this is getting uneasy though. This iconic picture in Barcelona says it all:We all like to be immersed in VR, but are uneasy that Mark walks around.Still a fanMaybe we are not all fans of Facebook, but we sure are VR fans. That being said. VR is here. You don’t have to wait for the future. It’s cool and it’s fun. That’s what a year with the Quest told me.Still, it’s far from perfect. I think that especially for mass adaption, Oculus is on the right track. Hardcore VR enthusiasts (and former employees) might wish for a more high-end approach. They wish that more resources are going to the development of the Rift 2 so it could compete with Valve’s Index. Still, as John Carmack also stated a few years ago, it’s better to accept the level of the technical capabilities and build great experiences for that.Better specs are always good and opens the door to new experiences. A lot of techies are salivating at the ideas of better specs. I wrote about this earlier in this blog:The road to better VR specsIs this the real life?"
Virtual Showrooms: The Present & Future of Any Business,https://medium.com/@yepparwebindia/virtual-showrooms-the-present-future-of-any-business-27d57926c79a?source=tag_archive---------4-----------------------,"Virtual Showrooms,VR","Virtual Showrooms: YepparCovid-19 has made a huge impact on the retail industry worldwide. While the retailers and offline businesses had to shut their stores, employees were furloughed. Since the outbreak of the pandemic, economists and retail analysts are questioning what would be the next step for the B2B and B2Cindustry.Any industry can adapt to technological hybridizations to safely serve their consumers in innovative ways. The Internet has already powered retailers and other businesses with eCommerce capabilities. But now, with modern technologies like augmented reality and virtual reality, there could be more transformation made possible in the retail offering a totally advanced shopping experience to consumers.In this tech-dominating era, audiences expect a hi-tech solution for shopping with immersive customer experience. With tech rising in the business industry, we could promise that something amazing is to take it a level up.Virtual Showrooms: Benefits to BusinessesA virtual showroom is an interactive experience that introduces clients to an entirely digital environment, letting them take tours, see showcased products, and even purchase them. Be it retailers or any other business, some factors are common in how a virtual showroom could benefit.#1 Lesser Bounce RatesThe bounce rate is the number of visitors who leave the website after seeing the landing page. Other than just posting quality content, you as a brand or business can make use of a virtual showroom to keep the visitors engaged on the website. A virtual showroom takes more than a minute of the visitors, and thus they spend more time on the website. AR-powered 3D technology makes the virtual showroom an immersive experience for the visitors.Bounce rates play a vital role in bringing in more traffic and also improves the search engine rankings. A virtual showroom engages customers by gaining their attention and boosts your digital footprint to give you more online exposure.#2 Makes You ReliableDue to the pandemic, people are scared to step out in public places and are not inclined towards trying products often. Yeppar offers virtual try-on tools as add-ons to add more essence to the immersive virtual experience. Be it apparels, accessories, footwear, furniture, beauty products, automobile, or machinery, let your customers try it to see whether it suits them or their space before they purchase it.With such virtual try-on and 3D demonstrations, you can build reliability within the visitors and makes it favorable to be converted. It also helps keep the customers stick to your brand by proving yourself authentic and reliable.#3 Offer Convenient ShoppingThis is not just a benefit for businesses but also the customers. Offering a convenient shopping experience is an absolute thing to do to retain customers for businesses. As customers are sitting safely at their homes and visiting your website to shop, a virtual showroom could invite them over for a tour.They could digitally walkthrough past different aisles with proper highlighted labels, picking required products to be added in the card. With no worry of being in contact with the virus, or without stepping outdoor, they could easily shop from the virtual showroom, and the quicker the delivery, the more impressed the customer would be.#4 Greater ROIAny investment done is with a vision to harvest greater returns. As lockdown has already brought in a struggling time for usual retail businesses, you could not get the reaping results as you used to do before the pandemic.Virtual showroom from Yeppar comes with a bonanza of features and add-ons to take full advantage of the technology and people’s interest in it. The analytics and reports would help you analyze which are the least-liked and favorite products. Infinite customizations allow you to keep the virtual showroom attractive alongside the immersive 3D virtual environment.With such supportive add-ons and interactive features, virtual showrooms are already creating a huge impact on businesses to regain customers. And, thus this brings more results and high Returns of Investment.Immerse into the FutureWith the twenty-first generation witnessing the establishment of virtual showrooms for retail and businesses, the world is going to adapt to these technologies as they are gonna stay long in the future.As the world would be connecting via WiFi and 5G, virtual reality and augmented reality would be highly utilized to engage users online to convert visitors for more sales. Modern tech like VR and AR would be making products digitally appealing to the users, as what appeals to the eye appeal to the mind!Written byYeppar — Augmented, Virtual and Mixed RealityYeppar is specialized in providing innovative Augmented, Virtual and Mixed Reality solution across the globe. #AR #VR #MR Website: www.yeppar.comFollowVirtual ShowroomsVRMore from Yeppar — Augmented, Virtual and Mixed RealityFollowYeppar is specialized in providing innovative Augmented, Virtual and Mixed Reality solution across the globe. #AR #VR #MR Website: www.yeppar.comMore From Medium5 Ways to Create the Perfect CTA for Your AdsJason J. Zotara in The StartupIs It Worthwhile To Build Links For SEO Without Content?Jayson DeMers in The StartupSupercharge Your Business Development With The Saturation MethodAndrew Holliday in The StartupWhy names and refreshed brands matter when building up your nonprofitDavid LangtonWhy Your Startup Should Be Stalking InfluencersSophia Sunwoo in Big Hairy GoalsWhat Actually Happens Inside a Marketing AgencyLeo Saini in The Startup3 Ways to Avoid Greenwashing and create genuine green marketingMap-Collective in EARTH by map-collective.com7 Tips to Build Your Brand EmpireAlyssa Satara in Better MarketingAboutHelpLegalGet the Medium app"
Virtual Reality is Reshaping Healthcare,https://medium.com/@tanveerinamdar/virtual-reality-is-reshaping-healthcare-5e124bc698db?source=tag_archive---------5-----------------------,"VR,Healthcare","Source: InstaVRVirtual Reality has become more than just an immersive entertainment experience, VR has ventured into the healthcare field and is making revolutionary changes in the way treatments are done. Planning pediatric and neurosurgery, training surgeons, increasing mental and physical disorder awareness, managing PTSD, phobia, anxiety, and autism are a few of the many potentials that VR has in the healthcare field. Doctors can also conduct entire therapy sessions remotely. With the current COVID-19 quarantine that we all are facing, this technology has come as a blessing. Read on to find out how VR is reshaping healthcare.Precise Surgical Planning with VRSource: Ghost ProductionsPediatric SurgeryPlanning surgery on a child can be a very complicated procedure. Children cannot be considered as smaller adults. A growing child’s internal anatomy and physiology differ from that of an adult. VR is a game-changer in this situation. The doctors will take multiple CT and MRI scans of the child and feed into the VR software to render a 3D image that is a 360-degree view of the anatomy. The doctors can then play out their plan on these 3D figures and come out with the best course of action.Neurosurgery PlanningNeurosurgery is one of the most complex surgeries to perform and learn about. An operation theatre is a hectic environment with no room for error. Each procedure must be done swiftly and with intense care. It’s not a place for learning so upcoming surgeons cannot really learn much by just watching neurosurgeries. With Virtual Reality, students can work in a simulated environment as many times as required. There is no risk to patient health. Expert surgeons can also visualize their patient’s brain anatomy and plan their actions before the surgery.VR Surgical TrainingSource: TekshapersMost beginner surgeons get to perform their procedure on a cadaver once or twice at best before going to the actual surgery. There is a need for better training methods. This is where VR comes in. VR can be used to create close to realistic simulations of surgery procedures. Trainees will be provided the tools required to use during the actual surgery. Osso VR can also assess the duration and efficiency of the surgeon’s procedure. The surgeon will have to go through the simulation by memory but will be provided hints in case they get stuck. The simulation also scores trainees on how well or poorly they did.VR Builds EmpathyVR can be used to create immersive content depicting the daily struggles that come with neurodegenerative diseases like Parkinson’s and Alzheimer’s disease. It will also help form a community of the affected people where they can share and learn about their conditions. Doctors, nurses, and other healthcare workers can undergo this as a part of their training. This builds empathy for patients. In turn healthcare professionals provide better care as they understand better by putting themselves in the shoes of the afflicted.VR for Mental HealingSource: Samsung InsightsPhobia and PTSD TherapyPTSD and phobias can be hard to manage and can make day to day life difficult. People who suffer from phobias often feel helpless and do not seek treatment as progress is slow with just therapy. Both of these conditions require many therapy sessions involving direct contact with triggers. This can be traumatic and can even make their disorders worse. VR can help to treat these conditions safely. A medical professional will expose the patient to certain pictures and stimuli which trigger their phobia or trauma. By varying the degree of stimuli slowly, the patient will eventually develop an immunity to what scares them and overcome their issues.Anxiety and PainThere are a lot of medications out there that help people with dealing with their anxiety or pain. However, these medications are known to cause addiction problems. Instead, a patient can just put a VR headset on and select a soothing video watch. This immersive experience takes their mind off the pain and they slowly become less dependent on drugs. Burn victims have been known to benefit from this VR tech the most. According to a study, burn patients experienced up to 50% lesser pain while using VR.Autism TherapyAutism can be managed using speech and language therapy. Since children with this condition become anxious in foreign environments, VR can come in handy. A VR headset could simulate their room or wherever they are most comfortable. Doctors can then proceed with the session with minimal stress for the child.ConclusionAs we are all stuck in the worldwide quarantine right now, many healthcare providers have found ways to provide the care that people need through telehealth and VR. Not only has Virtual Reality given people a platform to converse with their doctors and gain therapy, but it has also provided a new means of training medical professionals in complex procedures. This is just the beginning, as healthcare innovators are developing new ways to utilize this profound technologyWritten byTanveer InamdarThought leader, Consultant, Observer , Realtor, Pilot , Banker, Educationist, Reader & Entrepreneur.FollowVRHealthcareMore from Tanveer InamdarFollowThought leader, Consultant, Observer , Realtor, Pilot , Banker, Educationist, Reader & Entrepreneur.AboutHelpLegalGet the Medium app"
VR & AR Parent & Student Resource #8,https://medium.com/vr-ar-parent-student-resource/vr-ar-parent-student-resource-8-d8b63898cf04?source=tag_archive---------0-----------------------,"Virtual Reality,Augmented Reality,VR,AR,Edtech","StudentsOlivia Wenzel, Student & Founder of AltruTec, LLC, Ohio, United StatesAlex McNeilly, Student & Founder of Puzzil AR, Illinois, United StatesEliot Advani, Student, Massachusetts, United StatesAlex Advani, Student, Massachusetts, United StatesHelen Liu, Student, Massachusetts, United StatesMymoon Bhuiyan, AR/VR Group Team Leader for the Massachusetts Science & Engineering Fair Inc., Ontario, Canada/Massachusetts, United StatesShravya Anisetti, Student, Massachusetts, United StatesArnav Mishra, Student, Massachusetts, United StatesMentorsJulie Smithson, Co-Founder of MetaVRse, XR Ignite & XR Collaboration, Ontario, CanadaHelen Rosenfeld, Executive Director of the Massachusetts Science & Engineering Fair Inc.Fallon Brewington, CEO of the Boys and Girls Club of the Sandhills, North Carolina, United StatesReynaldo Zabala, Extended Reality Strategy Director of RazorEdge, Ohio, United StatesRohit Chaube, Co-Founder of VRoKCs, Kansas City, United StatesIntroductionTARGET AUDIENCE: Grades 6+In the previous issue, we reviewed tech terms, learned about interactivity in VR and AR, and we showed you how to create a simple 3D demo in Phase 4 of the Curiosity Project.In this issue, we will be introduced to new tech terms and highlight storytelling and gamification in education using immersive technology. Lastly, we will show you how to publish your project and share it online in the fourth phase of the Curiosity Project. In addition to the Curiosity Project, we will explore resources that allow you to learn VR and AR.Tech Term RemindersImage of Job SimulatorImmersive TechnologiesImmersive technologies encompass virtual reality, augmented reality, and other related technologies that use 3D to create or extend a reality.GIF of SUPERHOT VRVirtual Reality (VR)VR is a simulation of a 3D environment viewed through a headset. With hand-held controllers, gaze, or other means, the user is able to interact with virtual content.GIF from MITAugmented Reality (AR)This technology places an image (a hologram) in a user’s view of the real world through digital devices, such as a smartphone, tablet, or headset.New Tech TermsImage from KasperskyQR CodesQR (quick response) codes are similar to black and white barcodes, except in various square-shape patterns. They are becoming increasingly common and more technology is adapting to the codes which typically store URLs and other forms of data/information and make them easily accessible.Gamification & Game Based LearningImage from HurixGamification as a digitization to non-game applications to encourage a specific response. Using gamification to interact with users to complete a task or levels of engagement with point scoring, paths of engagement and rules of play with a reward system to enhance personal achievement. Rewarded levels are able to measure focus, success and failure. Gamification can be connected to education, training and marketing for engagement & measurement.Image from BrainScape.comGame-based learning is simply learning through games with re-packaged academic content to promote critical or strategic thinking and also used to support students otherwise not engaged.Transportation & TeleportationImage from O’Reilly.comInside our VR worlds, the controls allow user avatars to slide across the floor with a push button or transport across a room, or have the ability to teleport to another location on the other side of the world or the universe.Transportation tools allow you to move inside the worlds and experiences and can be viewed from different perspectives. Teleportation tools (portals) will take you into other worlds for multi-experiences to visit places or events in the current day or in the past like a time machine.Image from Steam UpdatesPresence“To have these worlds “feel real”, you need to have presence when you are there, inside the virtual space. The feeling that comes with transportation into virtual worlds along with a complete “believability” in the interactive digital world that we have become a part of.” — Caitlin Krause — Founder of MindWise & Author of Designing WonderImage Cred: — XRCollaboration.com — Caitlin Krause, Founder of MindwiseStorytelling in Immersive TechnologiesWhat do Romeo and Juliet, Good Willing Hunting and Diablo 2 all lack? True immersion, no matter how captivating, how complex the characters, or how enthralling the story is, there is still a separation between you and the world you are experiencing. Virtual reality is the key to gain full immersion in digital technologies and to be able to tell a story.Image Cred: Mobile Groove — From Storytelling to StoryLivingWith virtual reality, more senses to tell a story are engaged to a fuller extent. This is a powerful tool to bring to students, clients, or end-user into the experience you want them to have. We still lack the sense of feeling and smell, but virtual reality proves to be a vital tool in breaking the degrees of separation between your user and your world.A very prominent example is horror games. It is much scarier to be in a room with a Lovecraftian horror than staring at it from a screen. Just search up the hundreds of hours of YouTube gamers screaming for their moms in an Oculus. This sort of technology can change the interaction between the user and the computer.However, no matter how immersive technology is, good storytelling is still crucial to making a captivating world. There are reasons why a 16-bit game like Pokemon Red still has millions of hearts, whereas many modern 4k games leave less than to be desired.For VR to work, you should aim to create branching storylines. There are consequences for your action in real life, and this should be emulated in your story. Having different ends for your users’ actions not only adds repay values but also a feeling of realness. Skilled developers can have up to 50 or more different endings depending on the actions of the player.Image Cred: Linked — Megan GoldenStorytelling has the most benefit within the educational sphere. It’s hard to tell a story about a tangent function, but essential skills like empathy and critical thinking can be taught to students.A non-VR example of this is Minecraft. Hundreds of schools over introduced Minecraft into their curriculum to inspire creativity, and problem-solving in their youth.Image Cred: EngadgetThe students further loved this because they got to play their favorite game at school. Studies show [1] that this sort of immersion in the classroom increased motivation towards school, more creativity, increased level academic efficacy, and development of autonomy.More pertinent to VR, when a study by the University of Southern Queensland, used VR in Australia, The US and Latin America, it found the student was enthralled by the “realistic features” [2]. A VR study, including 1350 high school students [3] by foundry10, found that it could improve STEM education by the distribution of VR. Before the study, the student found topics like history and science to be inaccessible. However, being immersed in the middle of these historical events, it was easier for students to comprehend the topics being told.Moreover, to gain excitement for STEM, showing another world or watching chemical reactions occur at the molecular scale never hurts. In the end, virtual reality is fun, and it breaks away from the monotony of regular school scheduling. You will not be teaching about trigonometry in virtual reality (though you may need to know some), but the essential life skills that all students need can be enhanced through this medium.[1] https://education.minecraft.net/wp-content/uploads/Minecraft_Research_Report_Karsenti-Bugmann_2017.pdf[2] https://www.researchgate.net/publication/228724825_The_use_of_virtual_reality_in_education#:~:text=It%20was%20concluded%20that%20virtual,relationship%20with%20the%20real%20world.[3] https://www.digitalbodies.net/learning/a-vr-in-education-study-of-1350-students/Gamification of LearningToday’s generations are growing up in a world packed with various, revolutionary intelligent systems and technologies. Among this mass of tech and knowledge are methods to engage people and encourage an attitude of problem-solving. One of these methods, employed in everyday activities like driving and exercising, is called Gamification.Image Cred: elearningindustry.comGamification is defined as using game mechanics into your site, service, community or campaign to engage people, drive participation, motivate action, promote learning, and solve problems.The ability to engage and motivate people at normal (sometimes boring) activities is so useful. Gamification utilizes features such as challenges, points, incentives etc. to encourage people to work harder and achieve goals.Image Cred: elearningindustry.comOne task that some people find hard to enjoy is learning. Educators struggle to engage students and encourage them to show interest in the subjects they learn. A study conducted in the Spring of 2019 showed that 71% of High School students were bored all/most of the time, or some of the time. Only 29% said they were never bored.We talked in a previous issue about how immersive technologies can be used to motivate and excite students about learning. Immersive technologies offer a new, interesting perspective (literally and figuratively) to people who are learning. To combine immersive technologies with gamification would mean a new outlook on topics, as well as motivation to explore the topics further.One great example of this combination is HoloLab Champions, a VR game show about chemistry and experiments in a virtual lab. It uses quiz questions and a score system to engage players/students. The player is scored on accuracy and safety, when completing tasks in the game. A brief and official description of the game can be found here.Other examples of gamification for education: MEL VR Chemistry Lab, HoloLab Champions, To Catch a Mimic — Prodigy Math Game & CalcFlowCuriosity Project Phase 5Final Recap of the Curiosity ProjectIn Phase 1 of the Curiosity Project, we showed you how to research, brainstorm, and form an idea for your prototype. In Phase 2 of the Curiosity Project, we introduced you to wireframing, and we showed you how to wireframe.In Phase 3, we showed you resources where you could download or create your own 3D models. In Phase 4, we showed how to create a simple prototype in the MetaVRse engine that answered your prompt and adhered to the wireframe you created in Phase 2.In this final phase of the Curiosity Project, we will show you how you can finalize your project, deploy it, share it, and look further into developing for AR and VR.Refining Your PrototypeBefore we publish and deploy your prototype, we need to add some finishing touches and double-check that it works the right way. A good immersive project reaches its goal(s), fulfills the user’s needs, and instructs the user on what to do in a clear and concise way.Before you publish your project, look at your prompt again. Does your prototype help visualize something that is hard to learn in school? If you want, have your friends test your prototype. Make sure to ask them for feedback, this will help you to improve your prototype overall.Image Cred: TERC.eduAlso, look at your wireframe, does the layout and design you created in your wireframe match the design and layout of your prototype? Double-check your wireframe to make sure.Lastly, is the text in your prototype (if you included any) readable? Are the images in your prototype (if you included any) high resolution? Make sure the elements in your prototype are readable and visually-appealingIf you wish to build out your prototype further, or if you wish to build a new project using AR or VR, take a look at the “Continuing Your Project” and “Exploring AR and VR Further” sections in this issue.Publish and Deploy Your ProjectWhen you’re done with your 3D MetaVRse prototype, click the “Preview” button in MetaVRse. Make sure you have everything ready and double-check that every component of your project is in the correct place.When you’re done double-checking your finished project, watch this video on how to publish your MetaVRse project. Publishing on MetaVRse allows you to implement your project on Android, iOS, and other places on the web.VRARA Student 3D CubeSCAN the QR CODE with your CAMERA, OR CLICK THIS LINK TO TRY OUR PROJECT!Share Your Project With The VR/AR Association!We want you to be able to share your immersive projects with the world! That is why we are introducing the #CuriosityProject2020 hashtag. Follow the VRARA Student Committee on Facebook, Twitter, and Instagram.Post your project on social media. Make sure to tag us and use the #CuriosityProject2020 hashtag in your post. We’ll take your project and showcase it on the VR/AR Association website!Continuing Your ProjectThroughout the Curiosity Project, we’ve shown you how to brainstorm ideas, plan your project using wireframes, find or create 3D models, and add interactivity to your projects. In our previous issues and this issue, we have given you resources that allow you to learn and perfect the immersive technology development process.Image Cred: Innovec GamesThough we’ve only built a simple 3D prototype over the course of our resources, that DOES NOT mean you can’t add to the project we have helped build with you. Feel free to add more models to your project, create more intricate animations, or make greater interactivity. The XR development process is a collaborative one that requires lots of developers, testers, and designers. We encourage you to work with friends and build up your immersive project. If you want to learn more about the AR and VR development process, make sure to read the “Exploring AR and VR Further” section of this issue.We want you to push the limits of what you can do with XR and revolutionize how we learn and visualize new things.We want you to see education (and the world) differently!Exploring AR and VR FurtherThroughout the Curiosity Project, we’ve shown you the basics of prototype, wireframing, and designing for immersive projects. However, these eight issues have only scratched the surface of what the XR development process consists of. Below there is a collection of online resources, courses, and organizations that can assist you in learning more about developing for AR and VR and XR industry at-large.We understand this school year is different than many before due to COVID-19. Learning remotely or from inside the classroom, there are many things to learn this year as we as humans accelerate the use of digital applications in our daily lives. There is so much to know that is new, and new for everyone, please be kind and patient with yourself and others, be creative and share your ideas to help innovate and design the future!We are excited to see what YOU create!VRARA Student CommitteeAugmented Reality (AR) Development ResourcesGoogle ARCoreGoogle provides tutorials for its mobile phone AR platform, ARCore. Their documentation is easy to read and follow for beginner AR developers.Apple ARKitApple provides tutorials for its iPhone AR platform, ARKit. Their documentation is easy to read and follow for beginner AR developers. Note: you will need an Apple product with Xcode installed to develop using ARKit.Snapchat Lens StudioLens Studio is an AR development platform created by Snapchat that allows you to create your own face filters called “Lenses.”Spark ARSimilar to Lens Studio, SparkAR is an AR development platform by Facebook that allows you to create your own face filters for the Facebook app and Instagram.Unity ARUnity is an industry standard for AR app development. They offer AR plugins for their 3D engine including: AR Foundation, their very own AR platform, Vuforia, another widely used AR platform, Google’s ARCore, and Apple’s ARKit. In addition, Unity has plugins for Enterprise AR and Advertising. All of these plugins give you a lot of freedom to build whatever you want in AR.Puzzil ARPuzzil is one-part AR educator; one-part AR developer. Puzzil provides resources about AR technology and the XR industry at-large through its blog, podcast, and videos. In addition, Puzzil provides consumer AR apps that are fun and easy to use.Virtual Reality (VR)Google VRGoogle provides a VR software development kit that can be used in Unity, Unreal, Android, and the web. Their documentation is easy to read and follow for beginning VR developers.Unity VRUnity is an industry standard for the development of VR. Their VR solutions come with ultra-immersive features such as spatial audio and stereo instancing (better VR performance). Unity allows you to build for multiple VR platforms and different forms of VR hardware. Unity’s VR software development kit gives you a lot of freedom to build whatever you want in AR.Unreal VRThe Unreal Engine is a game engine developed by Epic Games. Initially developed for first-person shooters, Unreal is now used to apply VR game design in a variety of other industry and business applications and genres.VR/AR OrganizationsVR/AR AssociationVR/AR AssociationThe VR/AR Association (VRARA) is an international organization, made up of XR companies, researchers, and developers, designed to foster collaboration between innovative companies and brands in the VR and AR ecosystem. It’s the association’s goal to develop XR industry standards and promote XR in education and enterprise.The AREAThe Augmented Reality for Enterprise Alliance (AREA) is a global non-profit organization dedicated to promoting widespread adoption of AR in enterprise and business applications. If you’re interested in the business aspect of the XR industry, or want to learn more about AR’s applications for companies, check out this organization!XRAXRA is a global association whose goal it is to lead the way for the responsible development and adoption of XR across industries. It’s also their goal to develop best practices and research the XR industry in-depth. Members of the XRA include Facebook, Google, Oculus VR, Microsoft, and Sony.Takeaway Learning ResourcesCheck out this issue’s recommended resources, which build on our themes of creation, enlivening environments, and immersion.How to Use Gamification to Motivate LearnersCheck out this book called Designing Wonder by Caitlin Krause!XRCollaboration.com — A Resource to collaborate in VR & AR & a Directory of the hosting platformsVictoryXR — immersive learning platform for every subject and multiple explorations in the present, the past and out of this world! Experienced in ENGAGEVRIdeas for this resource were fostered by the VR/AR Association Student Committee. Follow us on Facebook, Instagram, and Twitter @vrarastudents.VR & AR Parent & Student ResourceAn introduction to VR, AR, & 3D learning & their impact on learning & workFollow2 Virtual RealityAugmented RealityVRAREdtech2 claps2 clapsWritten byAlex McNeillyFollowFounder & CEO of Puzzil AR, the one-part XR developer, one-part XR educator. I’m devoted to spreading awareness of XR technology to students and teachers alike.FollowVR & AR Parent & Student ResourceFollowWe aim to support parents, students, and schools in adopting immersive technologies and 3D learning. This summer, we are focusing on inspiring curiosity and innovation through VR/AR/3D in youth.FollowWritten byAlex McNeillyFollowFounder & CEO of Puzzil AR, the one-part XR developer, one-part XR educator. I’m devoted to spreading awareness of XR technology to students and teachers alike.VR & AR Parent & Student ResourceFollowWe aim to support parents, students, and schools in adopting immersive technologies and 3D learning. This summer, we are focusing on inspiring curiosity and innovation through VR/AR/3D in youth.More From MediumIoT applications in agriculture: the potential of smart farming on the current stagePaul Stokes in Data Driven InvestorTechnology Could Make a Hard Border Disappear, but at a CostThe EconomistAre Platforms Commons?Stowe Boyd in Work FuturesSmart Speakers and the Future of Music ConsumptionDmitry Pastukhov in SoundchartsSatellites Are Reshaping How Traders Track Earthly CommoditiesBloomberg in BloombergAn alternative to Apple’s paid private business model and Facebook’s free (but data mined) model.Steve FroehlichThe Burden of ConvenienceTaylor Jipp in The StartupNo Webcam, No Problem!Philip Joubert in The InnovationLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Best 5 Latest Information Technology Trends In 2020,https://medium.com/@nivipant1997/best-5-latest-information-technology-trends-in-2020-a2558ec1c862?source=tag_archive---------1-----------------------,"Artificial Intelligence,IoT,Blockchain,VR,Information Technology","Artificial IntelligenceArtificial intelligence is a branch of computer science that act like a human.AI is a study field of Robotics engineering.AI is the seeking to copy human as a machine that called “robot” who make a decision like a human. Artificial Intelligence basically a huge revolution in information technology.It is the top trending technology in today’s world.AI is intelligence technology sometimes called machine intelligence who works similarly to a human.AI study of “intelligent agent” like a sensor.An intelligent agent is a program that makes a decision perceives from the environment. It is an autonomous entity that acts through the environment like a sensor, the actuator performs some specific task. It is a self-learning program to use knowledge according to action in the environment for achieving goals.Internet of ThingsThe Internet of things contains devices that connect through the network. IoT things we used in our daily life like multiple apps in mobile phones, smartwatch, etc. It is a giant network of multiple devices which can share data with each other using sensor. It works with a sensor that emits the data of devices such as a smartwatch, traffic light, electrical appliance which you crossing your daily life.It is a big challenge to emits a huge amount of data so IoT provides a platform for all devices and provides a language for communication between devices.For more details about trending Information technology check out this linkhttps://technzzblog.blogspot.com/2020/09/best-5-latest-information-technology.htmlWritten byPantechFollowArtificial IntelligenceIoTBlockchainVRInformation TechnologyMore from PantechFollowMore From MediumThese advanced AI retail techniques are making retailers jobs a breezeStephanie Organ in Nightingale HQTips for Dealing with Inappropriate Language using Watson AssistantBurak Akbulut in IBM WatsonHedging with Machine LearningTodd Moses in Fintech with ToddSimon’s Chess FactorJP Fosterson in The StartupWhat Is Natural Language Processing And What Is It Used For?Terence Mills in AI.ioCould Automation and AI break the BI adoption barrier? (Part 1)Daniel Shaw-DennisShall We Play a Game?Christopher Hoskin in Taking StockAmazon Tried to Sell ICE Its Faulty Facial Recognition TechExtremeTech in ExtremeTech AccessAboutHelpLegalGet the Medium app"
N/A,https://medium.com/@kayxxx/fbvirtualreality-1894f3242737?source=tag_archive---------2-----------------------,",Black Mirror,VR,Facebook,","9月15日下班回到家，打開臉書看到動態墻（News Feed）滿滿都是臉書好友分享自己建立設定的虛擬替身，一時好奇之下（也很難得臉書有新東西）我也點進去編輯，突然，靈光一閃，等等，不對…圖來自網路作為《黑镜》（Black Mirror）的鐵粉，在15/9在FB看到大家瘋狂編輯、建立虛擬替身，其實我也有按進去嘗試編輯，可是弄到一半想想不對！今天我在做一個「我」的替身，那麽改天會不會要求我給我的替身輸入我的思想、我的字跡、我的聲音等等，然後她就慢慢擁有意識，可以代替我在網絡的世界里遨遊發聲？這個熟悉的感覺，怎麽有點像《Black Mirror》第一季的第二集啊？那些虛擬的人像竟然代替真實的我看演唱會！！！一想到這個，我立馬退出編輯框。《Black Mirror》 Season 1 Episode 2 《一千五百萬點》說的正是被物化的世界，人類失去靈魂只能踩著腳踏車賺點數，換取不是自由的自由。每天困在一個四面都是熒幕的房間，看著虛擬的自己在虛擬的畫面里玩得很開心，呵呵！播了那麼久，我對這集依然印象深刻，因為這故事的結尾並沒有讓我失望，沒有反轉（不想劇透）。縱然FB的虛擬替身這個新功能可能沒有以上的想法，而且經過查證後，FB創建這所謂的新功能其實是為了以後的VR應用做準備，好像是Facebook Spaces一種社交VR體驗，詳情請點這裡。圖來自網路Anyway，雖說「虛擬」這個Idea已經在Snapchat、Nintendo等應用出現過，這些我都可以接受，但是臉書作為最大的社群媒體，竟然也抵擋不住虛擬這個洪流，要用戶創立自己的臉書虛擬空間，用虛擬的自己交虛擬朋友，完完全全就是《一千五百萬點》啊！雖然這集的主要Focus不是科技這一塊（非主要），但說真的啦，FB有本事建立虛擬空間的話，VR裝置也變得像手機那樣普通的話，我倒是還蠻想玩玩看的啦，畢竟身為人類還是很容易被新穎、方便和看起來好厲害的東西給吸引，就像劇集裡面的主角一樣，仍然逃不過被強行同化的命運。我真的深深感到一切科技的走向都往《BM》里面的情節邁進！這很可怕！如果照此發展下去，以後的世界可能會出現虛擬議員、人體記憶芯片、打分系統、意識芯片、金屬頭等等可怕的發明！其中消滅掉大部分人類的金屬頭，超恐怖的，要嘛人類你就是乖乖成為科技的寵物；要嘛…被它殺死。好啦，看到這里一定有人認為我在誇大，或是科技在誇大，你仔細想想自己接觸過的電子產品，改變都是潛移默化的，沒有百分百，也有十足十，未來是冷漠的。Written byKayxxx馬來西亞人，思維跳躍的文字工作者Follow7 7 7 臉書Black MirrorVRFacebook中文More from KayxxxFollow馬來西亞人，思維跳躍的文字工作者More From MediumMessages I’ve Sent On Tinder Or Facebook Marketplace?Phil Gillen in SlackjawOn Election Day, Facebook and Twitter Did Better by Making Their Products WorseThe New York Times in The New York TimesDonald Trump Won, No Matter What Happens NextJessica Wildfire in The Apeiron Blog(Why) There Was no Biden Landslideumair haque in Eudaimonia and Co20 Things Most People Learn Too Late In LifeNicolas Cole in Better AdviceThe Election Should Never Have Been This Closeumair haque in Eudaimonia and CoThis Is ‘I Wish a Motherf*cker Would’ Week for Black PeopleMarley K. in ZORA“Anyone but Bernie”, They Said.Lauren Martinchek in Dialogue & DiscourseAboutHelpLegalGet the Medium app"
3 ways virtual reality could change the world,https://medium.com/@alieskandari2001/3-ways-virtual-reality-could-change-the-world-ca182e9cb930?source=tag_archive---------3-----------------------,"VR,Virtual Reality,Virtual Worlds,Future,Future Technology","When someone talking about virtual reality, the first thing that comes in their mind is gaming.People think virtual reality is all about gaming. But it’s not.Wait for a second…Virtual reality or VR is all about gaming.I believe our lifestyle will be based on VR, very sooner than we think.How and Why?Let’s get started.Virtual reality is the new real world!It’s doesn't matter what you doing now.Maybe you are in the wine business or you a digital marketing manager.It’s most likely virtual reality technology affects your lifestyle. The era of monitors and displays will be over, finally!They will become things from the past.There is no need to work with hardware like keyboards and mouses. They become old stuff, like radio.We will go into the content, literally.We will engage with it, as we engage with the real world.Virtual reality in our jobs and businessThanks to COVID million people don’t have to work in the offices.They can be anywhere — with their family — and also making money.Maybe in the future we back to offices. But not quite the same.Meet with virtual reality officesVirtual reality become a crucial part of how we working.You will be fully engaged with tasks. Your whole environment will be engaged in the task you are doing.Whatever you are designing or developing, the world around you will be transformed into another universe.Imagine you are a digital product designer and working on an app.You put the virtual reality goggles and BOOM!Welcome!Now you are IN THE APP.You can move 3D graphic elements like when you move a thing in the real world.VR makes people more focused and productive.In the other perspective (the dark side), your company will force you to work in a fully controlled place that will become your nightmare.Virtual reality isn’t good or bad, people determine how to use it.Virtual reality in educationToday’s educational system is sucks. Who’s with me?Maybe — again thanks to COVID — the broken system force to do some improvement, but still it’s lack one important thing:People not learning anything important in this system.So why on the earth you should spend at least 10 years of your life learning things that not matters — things that robots can do far better than us.Why?Unleash your creativity with virtual realityStay tights, because virtual reality gonna change the world.Imagine you want to learn about the solar system and the universe.You don’t need 2D books and non-engaging monitors, only we need a pair of VR goggles.Let’s tell you a story:Tara has a class with the topic of the solar system. She goes on the treadmill and put those VR goggles.BOOM!She now observing Helix Nebula! She can see stars, black holes, planets, and so on.She can with a gesture, zoom on each planet and with one tap see their history.The educational system based on virtual reality allows you to discover, explore, and go further.You will fully engage with the topic you are learning about.The educational system become a virtual reality game.Virtual reality in our communicationLet’s assume you want to find a friend.It’s simple, you check Facebook, add a person to your friends, and maybe a few moments later, Congrat! You have a new friend now.But the friend you can talk with her/him and in person is a unique and different experience.Now maybe we are limited to Facebook on a 2D monitor, but the future wouldn't look like this.Virtual reality friendsWhen we live in a virtual world, all of us can have virtual friends that are like our friends in the real world.We can talk with them face to face and meet them in person — In their detailed 3D avatar.Communication will be virtual, totally.A confession, NOBODY can’t predict the future. I just here dreaming about it.Maybe the future will be totally different from the future I dream about in this article.But maybe this future becomes reality.A virtual world.Written byAli EskandariA storyteller 💙FollowVRVirtual RealityVirtual WorldsFutureFuture TechnologyMore from Ali EskandariFollowA storyteller 💙More From Medium2019 Cloud services predictionsVíctor Escudero Rubio4 Reasons “The Maker Movement” Will Redefine Traditional Manufacturing in the U.S.JoeSupplyChainApple & Google: It’s Up to You to Save the Dying Smart Phone User ExperiencepdorfmanQuestions We Still Need Answered After Apple’s Media EventMichelle Castillo in CheddarMIT’s Artificial Brain-On-A-Chip Could Bring Supercomputing to Mobile DevicesPCMag in PC MagazineThe Battle to Replace the SmartphoneJosh QuittnerAn Advocacy Group for Startups Is Funded by Google and Run by Ex-GooglersThe Intercept in The InterceptFacebook: Where Friendships Go to Never Quite DieThe Atlantic in The AtlanticAboutHelpLegalGet the Medium app"
Zoom Host/VR Host,https://arvrjourney.com/zoom-host-vr-host-50513a2f5e68?source=tag_archive---------0-----------------------,"Zoom,Virtual Reality,Hosting,Reunion,VR","Zoom is a Super Word that can be a noun, verb, adjective, maybe even an adverb, to express a new way of relating to each other.Zoom was more or less jammed down our throats. There are things people love about it and things people get very stressed up about and don’t like at all.Video services like Zoom have been around for years. Zoom was the one peaking when face to face became video face to face. I love this way of being with people who aren’t anywhere near me and I’ve been doing it for decades.When our Reunion got busted by the virus, I said let’s do Zoom and there was understandable skepticism at first, but people gave it a shot. And doing it virtually actually worked out.We heard from everyone. It was different and unexpected. There was a big ‘Holy Shit’ factor.Trending AR VR Articles:1. How to use subtle AR filters to survive your Zoom meetings?2. The First No-Headset Virtual Monitor3. Augmented reality (AR) is the future of Restaurant Menu?4. Creating remote MR productionsNow we were trying it again. Anyone can get lucky once. Have a bunch of people in video tiles reintroducing themselves for 90 seconds. That concept doesn’t work twice.We kicked it up one notch. A panel from four different professions to talk personally about how they got where they are, and how they see the Covid world as a result of it. The idea was to kickstart the whole Zoom conversation that way.It worked.But I had a problem.Our Zoom event had been scheduled for over a month. Hour and a half, with a soft deadline. Then I got scheduled into another event two hours after the Zoom. In VR.I wasn’t too worried. We wrapped the first Zoom reunion in less than two hours.This time it was different. People had already shared the quick and easy intros and besides, we were talking about Covid World. People had personal things to say. I didn’t want to use my Host power and give the hook to anyone.Respect was the easily the Theme of the Zoom. We heard stories of billion dollar negotiations coming apart over personal slights. Questions about Essential Workers being celebrated and respected until they ask not even for a raise but just for safer working conditions. There was a foreign relations expert who pinned it all on respect. Declining respect around the world for the U.S. Other country’s insistence on respect from the U.S.I called on the last person at the one hour and fifty five minute mark. I need about two minutes to get into the virtual world with people who were depending on my presence. He made a wonderful last comment. I thanked him.As I asked someone else to put the formal punctuation mark on the event, I reached for my Oculus Quest and pushed the power button.I thanked everyone for being so engaged, together, for two hours, slipping the headset down over my face, on-screen. I left the meeting and my view resolved into an iconic Zen garden, with rocks and a pond and a little arched bridge. Evening time. Insects chirping.I was completely there. I know the world and every detail of it. I am in it for a several hours every week talking with people about things they don’t usually talk about. Like death and sadness and feeling awkward in the world.The others spawned in right then. It was the second meeting of our EvolVR Circle group. Six of us. We would be meeting like this for eight weeks altogether. Same time, same people, same virtual Zen garden.We had a tropic but it’s just an excuse to get to know each other. Do it every week for a few months and we all end up feeling connected to more people, people we can just approach and say hi and talk easily because we shared this Circle. That’s money in the bank.I was the Host, again. I think I might have finally found something I’m good at here in my eighth decade. I called on people’s avatar and everyone checked in. I just asked them to say what they’re bringing right now and they felt safe enough to do it.Since this is early in the group’s process, there was a lot of discovery going on. Oh, you know about that, too, I thought no one did? That’s fun. We bonded over these little things, and not so little things. Like Kidneys, really. Kidney disease, kidney fundraising, kidney research, and a dialysis center all came out. It was funny.You had to be there, which is exactly how you feel in VR.The Zoom call was an intense and stimulating experience I had been at the center of minutes ago. It was like it happened to someone else. It wasn’t part of my world any more except as a memory, which is how I described it when I checked-in.We will have more Zoom Reunions because the whole idea has become a verb, not something we travel to and do once and it’s over.When this Circle comes to an end we will start another one.I don’t feel like there is any point to anything except each other, so I will just keep connecting any way I can do it.Don’t forget to give us your 👏 !AR/VR Journey: Augmented & Virtual Reality MagazineBest place to learn about AR& VR.Follow53 ZoomVirtual RealityHostingReunionVR53 claps53 clapsWritten byTom NickelFollowLearning Technologist focusing on VR, Video, and Mortality … producer of Less Than One Minute and 360 degree videosFollowAR/VR Journey: Augmented & Virtual Reality MagazineFollowBest place to learn about AR& VR. We share the latest AR/VR News, Info, Tools, Tutorials, ARkit, ARcore, & More.FollowWritten byTom NickelFollowLearning Technologist focusing on VR, Video, and Mortality … producer of Less Than One Minute and 360 degree videosAR/VR Journey: Augmented & Virtual Reality MagazineFollowBest place to learn about AR& VR. We share the latest AR/VR News, Info, Tools, Tutorials, ARkit, ARcore, & More.More From MediumInfographic: The Future of Virtual RealityAlice Bonasio in AR/VR Journey: Augmented & Virtual Reality MagazineReality Check: The marvel of computer vision technology in today’s camera-based AR systemsAlex Chuang in AR/VR Journey: Augmented & Virtual Reality MagazineDead or Alive: What is going on with the Virtual Reality Industry?Andrew Julian in AR/VR Journey: Augmented & Virtual Reality MagazineHow can augmented reality be used in education?Arcitux in AR/VR Journey: Augmented & Virtual Reality MagazineNiantic’s strategy in augmented reality — Pikachus are just the beginningSteph Rhee in AR/VR Journey: Augmented & Virtual Reality MagazineExpert View: 3 ways VR is transforming Learning & DevelopmentAlice Bonasio in AR/VR Journey: Augmented & Virtual Reality MagazineXR and the Self-Inflicted Trough of DisillusionmentJason Pace in AR/VR Journey: Augmented & Virtual Reality MagazineVR and AR in the Mobile WebNiño Ross Rodriguez in AR/VR Journey: Augmented & Virtual Reality MagazineLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
A Virtual Reality Classroom Adventure,https://medium.com/living-out-loud/a-virtual-reality-classroom-adventure-c2a1e8ff5ce3?source=tag_archive---------1-----------------------,"VR,Virtual Reality,Edtech,Education Technology,Teachers","“Miss, there is sick everywhere!”Created with crello.comYou hear a lot of strange things as a teacher. Some of it you often wish you hadn’t heard.As I get older, a lot of what I hear in the classroom I no longer understand. Teachers make excellent dinner companions because we have such great stories to tell from the trenches of teaching. My first venture into virtual reality (VR) was no different.We were lucky enough to have some Google reps come into the school that I was working at. They were to introduce some of the students and teachers to Google Expeditions and discuss using VR in the classroom.Google Expeditions, (for those that don’t know), is an immersive learning and teaching tool that lets you go on VR trips or explore artificial reality (AR) objects.On this particular day, I had my year 8 science class which had been selected to participate in the VR experience. As my class and I headed down the corridor to the classroom where we would have the VR session, we were all filled with intrigue. The kids were clearly excited and they could barely contain their excitement as they filed into the classroom. They took their seats and in front of each of them sat a set of Google Cardboard VR glasses.Well, you can imagine how long it was before they started picking them up. This was like sticking a cake in front of a two-year-old and saying “don’t eat”. The children explored the glasses with gusto, putting them over their eyes and talking animatedly to their friends and peers about what might happen next.I spoke briefly to the Google rep, who’s name I don’t remember but we will call him Ben, and within a few minutes, our adventure had begun.The session was simple; we were going on a tour of the digestive system.The students would start in the mouth and move as a piece of food would through the body. Ben would be the technician making sure the expedition went as planned, and I was the guide, walking the students through the digestive system and filling in all the relevant knowledge to match our curriculum as we went.A perfect plan!Photo by Giu Vicente on UnsplashStraight away, AS SOON AS I PUT ON THE GLASSES, I was as engrossed as the kids.I was transported into a 360-degree, 3D world. I spun around taking it all in and quickly becoming fully immersed.Eventually, I remembered my role and started to narrate the journey. I decided to hold my glasses in my hand, allowing me to pop in and out of the experience and watch the students — it was amazing to see them so engaged. They were spinning on their chairs, looking up and down, talking animatedly and pointing into thin air.They took to it straight away; they were naturals.We watched the food pass from the mouth and down the esophagus.Amazing!As we move down into the stomach, I continued my narration; talking about stomach acid and digestion until suddenly I heard a voice from the back shout.“Miss, there is sick everywhere!”In a panic, I rushed to the back of the classroom where, Jack, the boy who had shouted the comment was seated. I was expecting to find a puddle of vomit on the floor as motion sickness is sometimes a problem with VR. However, there was nothing.I looked up at Jack. He, and the rest of the class, were none-the-wiser as to my panic. They were all happily engaged and exploring. At this point, I was pretty confused as to what was going on. The comment from Jack, a lovable rogue, and the class clown was not uncharacteristic but he looked anything other than distracted or wanting to cause trouble.“Jack?” I asked. “Where is the sick?”Jack lifted his hand and pointed into the air in front of his face.“There Miss,” he replied, “it’s everywhere. It’s like I am walking in it.”Then it clicked in. He was talking about the contents of the virtual reality stomach. As I placed my own glasses over my eyes, his interpretation of the scene became clear. I turned back toward the front of the classroom to see Ben smiling broadly and my trainee teacher with her hand over her mouth trying not to laugh. I retreated slowing back to my spot in the classroom to re-group, smiling to myself. Only in this job, I thought.Does Virtual Reality Have A Place In eLearning?The importance of enriching educational experiences.medium.comThe rest of the expedition ended up going to plan. Within 25 minutes we were done and back off to our own classroom. The students were noisier as we headed down the corridor.They were all chatting about the experience while my trainee and I laughed about Jack’s comment and my Usain Bolt-like speed across the classroom.Photo by kyo azuma on UnsplashWhen we returned to our science lab, the students were still chatting away.We had a worksheet to do but I knew it was a fool’s errand getting them to do it. So, instead we discussed the experience in detail. Their hands were flying up at all my questions. The kids were bursting to share and have their say. If only teaching was always that easy.By the end of the lesson, they were still just as excited as when we had started. They left with the worksheet as homework while chatting about their hour, ready to boast to their friends over lunch.They wanted to know when they would get to do it again.They wanted more.The Sad Side of the StoryPhoto by Ivan Aleksic on UnsplashI have been teaching for 12 years and this is the only time I have seen VR in the classroom and I think this is massively disappointing.The students are keen to have this kind of experience, and they gain so much from it.Teachers are ready to learn new technology and skills and do whatever they need to do to help their students.With money being one of the major barriers, where is the help?Where are the investors, decision-makers and purse-string holders? Where are they? Don’t these people have children in school who could benefit from this type of experience?We need to spread the word about the importance of technology like VR in our classrooms to the people with money to spend so they can help make it happen.VR and AR are coming into our lives.It is already on our phones, in our homes and on the big screen, and it needs to be in our schools, too. Our children need to use and understand this technology.We only have one future, and that is our children.ReferencesExpeditions - Apps on Google PlayGoogle Expeditions is an immersive learning and teaching tool that lets you go on VR trips or explore AR objects.…play.google.comLiving Out LoudReal Life NowFollow486 2 Sign up for Real Life Now By Living Out LoudLife, Love and Creativity Take a lookGet this newsletterBy signing up, you will create a Medium account if you don’t already have one. Review our Privacy Policy for more information about our privacy practices.Check your inboxMedium sent you an email at  to complete your subscription.VRVirtual RealityEdtechEducation TechnologyTeachers486 claps486 claps2 responsesWritten byKate MackayFollowTech enthusiast, EdTech advocate, science teacher, 360 amature photographer, part-time writer and full-time learner.FollowLiving Out LoudFollowReal Life. Real People. Real Stories.  Exploring what it means to live with passion and purpose.FollowWritten byKate MackayFollowTech enthusiast, EdTech advocate, science teacher, 360 amature photographer, part-time writer and full-time learner.Living Out LoudFollowReal Life. Real People. Real Stories.  Exploring what it means to live with passion and purpose.More From MediumBiomimicry Innovation LabUlu Mills in LXD: Julia, Karen &UluWhy Colleges Should Pay Less Attention to GradesIsland Girl 808 in Age of AwarenessHalf of All School Employees Aren’t Teachers. This Recession Will Endanger Their JobsThe 74Can Science Be Taught Online?Rebecca LeBard in Age of AwarenessTo profit or not to profit, that is the question…Dr Denry MachinMoving Beyond Macro-talentLaurie Livingston Nave in The Partnered PenI Was Bullied for Getting My PeriodMollie Gray in Age of AwarenessLearning How To LearnAndrei Lyskov in Age of AwarenessLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Product Design Summer Internship at Facebook,https://medium.com/@yuehanw17/product-design-summer-internship-at-facebook-c14bef856abe?source=tag_archive---------2-----------------------,"Product Design,Facebook,Intern,UX,VR","A quick look into our experiences as AR/VR Product Design interns at Facebook in summer 2020 while working remotely during the global pandemic.Authors: Gabby Hoefer, Hannah Wang, Sabrina Zhai📝 1. Key Learnings from Interning at FacebookWorking as product design interns taught us several key lessons this summer. Even working remotely, we’ve grown so much as designers and are excited to share our learnings.Product design in VRFeedbackOne of the most important lessons I learned this summer was balancing feedback. I found myself constantly asking for feedback on my designs, but differing opinions often arose and contradicted each other. I first made the mistake of trying to make everyone happy and incorporate all aspects of feedback in my designs, but that became messy very quickly. Through the internship, I had to learn to trust myself and my design choices as well as the insights from others. This level of independence and self-awareness was crucial in creating strong designs.CommunicationOver-communicating is a necessity to overcome the hurdle of working remotely. There were days when I felt as if I was being “annoying” or “needy” by scheduling time on my manager’s calendar. I learned very quickly that a simple 15 minute progress report could save hours of time. Regularly syncing with your coworkers can make remote collaboration easier. Give your coworkers a heads up about your plan so they can have sensable expectations and manage their time and work accordingly. The heads up not only includes your project progress, but it also could be other projects you are working on and how much time you plan to devote to them, or the time you are planning to take a time-off.Being concise about which aspect of your design you’re looking forAs a product designer, you’ll also have the opportunity to have weekly critiques with your team (and even other teams!). The best part about critiques is that you can receive feedback from other designers who may not know as much about the project as you do. As a result, it’s really important to start your critique giving a brief context into the problem and be extremely clear in the feedback you are looking for. Asking specific questions and showing only the most relevant aspects of the design can be helpful in narrowing the scope of the insights.It’s especially important to bring your early designs to critique, rather than waiting until you have a more developed solution. However, at these stages, it’s possible there is little to show, as ideas may be conceptual, but grounding your ideas in any sort of illustration is helpful, as it allows for your audience to see exactly what you’re seeing rather than imagining it.Working with a managerPart of being an intern was also learning how to be managed, rather than simply leaning on your intern manager to tell you what to do. Especially with the remote model, it was key for me to learn what was the most effective way of working with my manager, given his own working styles and how to make it work with my own. I took the initiative to schedule daily 1:1s (generally around 30 minutes) with my manager and outlined an agenda of what I planned to go over and get a review on. This helped sync us, and made sure I was following expectations; my manager later mentioned that this was very helpful for him. As a manager, he has many meetings he needs to schedule and arrange himself, so having me take care of it for him allowed him to never wonder what I was doing, or feel like he hasn’t checked up on me in a while. Keeping this line of communication clear is key in developing an effective work model.🎈 2. Numerous resources for designersFacebook is unique in that it offers numerous opportunities and resources for designers. As an intern, you have the opportunity to be a part of small groups who come together for more personal discussions.Polish your skills: free coursesInterns have access to free courses on product design tools (such as Origami, Unity), techniques, etc. hosted by employees at Facebook. I enrolled in a few Origami classes, which I found to be much easier than learning on my own since you’re able to ask the instructor questions anytime.Networking: Intern Circles.There are many events especially for interns to connect with each other, discuss and learn. For instance, as part of the Women’s Intern Circle, four of us would come together biweekly for open discussion about our goals, current events, and being a woman in the industry. This ended up being a highlight of the internship since it provided space to establish close relationships while being remote!Talk with leadershipThere were also endless opportunities to sit in on speakers (e.g., Mark Zuckerberg!), where interns could engage and ask questions. Many interns reached out to leadership and were able to schedule coffee chats. We had the opportunity to speak with Jon Lax together and ask questions about his experience leading the ARVR org at Facebook.The best learning opportunity: 1:1s with your coworkersAt Facebook, it’s encouraged to schedule coffee chats with other employees, to take the chance to learn about them and of how they go to where they are. I’ve found that I learned so much in simply chatting with other full-time designers and asking about their opinions on design and user research. During an internship at Facebook, I encourage you to schedule weekly coffee chats with designers adjacent to your team, managers of managers, in order to get a wider perspective of design at Facebook and their journey as a product designer.💻 3. Working VirtuallyDue to the impact of the pandemic, this summer we all interned remotely. Things at work changed a lot, and we found some tips really useful when working at home.CommunicationWorking virtually changes the way you communicate with your team. When we communicate remotely using text, it’s harder to tell people’s emotions and easier to feel worried because of misinterpretation. One thing I learned from other designers and our recruiters is that people love to see emojis and stickers because through these tiny things they can understand that you are being friendly and open, so they feel more comfortable to discuss things and share their thoughts in the chat.ToolsIn the remote working environment, we use posts to update our design work, solicit feedback and recruit participants. This is a lightweight but useful way for designers at Facebook to promote visibility of our work and involve broader audiences in the conversation in addition to our team. In addition to real-time communication with your cross-functional team, posts allow more flexibility because anyone that is interested in your topics can respond friendly and asynchronously, and sometimes views from outside of your team could be an inspiration. It also allows for the opportunity for you to grow your network by meeting more people and talking about your project with other peers.Be creative at homeWorking remotely can make separating work-life and home-life particularly challenging. I found setting a distinct workspace aside (e.g., an office separate from the bedroom or living room) to be extremely helpful in maintaining a work-life balance. This also allowed for a more creative space for my design work specifically.ConclusionThank you for taking the time to read about our experience. We each really enjoyed interning at Facebook this summer and are happy to chat in more detail directly over virtual coffee! Feel free to see more details about our specific projects in our portfolio websites: Gabby’s Oculus Store Project, Sabrina’s Guardian Project, and Hannah’s Design Tool Project.Written byHannah WangFollowProduct DesignFacebookInternUXVRMore from Hannah WangFollowMore From MediumBuilding your Design IQGinmann in Full of TruthThe Icon KaleidoscopeJon Friedman in Microsoft DesignA New Development ProcessJoe Fensler in The InnovationAdding Timed Comments and Waveforms to SpotifyLee Martin in The StartupField Guide to Eavesdropping, People Watching, + Paying AttentionSam WestThe Anatomy of a Large Experience Design Organization — 2.0Jesse Kaddy in Wayfair Experience DesignTime Capsule: You’re Nothing But a Pack of Cards (Week 2)Lauren Busser in Digital Detritus: An Open SketchbookHow to design for the customers of tomorrow.Wilson Fletcher in Wilson Fletcher — The Human LayerAboutHelpLegalGet the Medium app"
"AVRA, Community Wallets Used Around the World",https://medium.com/@avrafoundation/avra-community-wallets-used-around-the-world-e140cb99c249?source=tag_archive---------3-----------------------,"Avra,Avrawallet,VR,Entertainment,Game","AVRA wallet is about to be releasedThe platform business is growing very fastAVRA wallet includes movies, games, shopping, and community channels.It will grow into a wallet that communicates with many users around the world.[AVRA official community]Homepage : https://www.avra.network/Telegram : https://t.me/AvraprojectTwitter : https://twitter.com/avracoinYoutube : https://url.kr/N92QCdInstagram : https://www.instagram.com/avrafoundation/Facebook : https://www.facebook.com/AVRACOINWritten byAVRA FoundationFollowAvraAvrawalletVREntertainmentGameMore from AVRA FoundationFollowMore From MediumThe fate of Privacy-focused digital coins amid the FATF’s “travel rule”Faisal Khan in TechnicityAltcoin News: Is JPMorgan's Coin Serious Competition for Ripple?Marko Vidrih in The CapitalIs My Cryptocurrency a Security?Patrick Tan in The CapitalCryptocurrency Mining — channeling your inner Tolkien dwarfThomas J. Mallick in The StartupWas Monero’s PoW Change A Success?ecurrencyhodlerChasing the Bitcoin Boys in the Crypto Capital of the WorldDrew MillardShould We Celebrate Facebooks Libra Cryptocurrency Or Cringe?Javanx3d in The CapitalDigital Wallets Are The Modern Brokerage AccountsAnthony PomplianoAboutHelpLegalGet the Medium app"
