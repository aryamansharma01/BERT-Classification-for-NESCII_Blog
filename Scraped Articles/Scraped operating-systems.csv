title,articleUrls,keywords,text
Difference between relative path and absolute path in Kotlin.,https://medium.com/@swapnil.saxena/the-difference-between-relative-path-and-absolute-path-cb1e24994682?source=tag_archive---------0-----------------------,"Relative Path,Absolute Path,Operating Systems,Development,Computer Science","What is the difference between relative path and absolute path? I wondered while working on my android application in native(Kotlin). In this post I would be explaining the fundamental difference between Relative Path and Absolute Path in a file system.A path is a string of characters that help locate a file directory in a file system. The absolute path is the full path of a file or folder right from the root directory. It is that path which you see in the details of a file or directory.The concept of absolute path isn’t that straightforward. One needs to know the concept of current working directory(CWD) to understand this. Basically when using classic Linux terminal or programs such as a python script there is current working directory associated with these and all the absolute paths are with respect to these i.e. relative to the current working directory.Python exampleNotice that python and many other languages open a file even if the full path is not given provided the file resides in the same directory as the script. This is because it uses the current working directory to locate the file. In other words it sees the given file name with respect to the current working directory. This phenomenon happens with paths also.In the above code the same thing happens with directories i.e. my_dir and the code reside in same directory so the program automatically uses current working directory to determine the full path also-known-as (drums roll) the absolute path.Why relative path?Well why not. If you have ever used django or made some project than you may notice that you keep all your files within some directory.Now what if you change this directory. If you absolute paths in your code than all your paths would become bad-paths when you move the directory. So what we do is use relative paths.Basically we say “Hey program, once you have reached here i.e. where you, the code file live, all the paths that I have given start from here!”.So this gives us relocatable paths. This happens automatically i.e. implicitly but can be done explicitly as well.These are ideal for machine-learning and other development projects where all the information related to the project resided within a directory.When absolute paths?Sometimes when requesting a path, a relative path may be returned. Hence be careful. For all files and directories not in your folder you need to use absolute path. Also note that somewhere inside the program, the relative paths also get converted to absolute path.As for my application, I went for the method .getAbsolutePath() as I was crawling the whole file-system.Written bySwapnil SaxenaEngineer, Foodie, SingingFollowRelative PathAbsolute PathOperating SystemsDevelopmentComputer ScienceMore from Swapnil SaxenaFollowEngineer, Foodie, SingingMore From MediumHow to Create a Reusable Web ScraperDavid Tippett in Better ProgrammingAn Explanation of What the Heck is Going On: Ruby Classes and the Has-Many-Through RelationshipRebecca Rosenberg in The StartupTest Your Kafka Cluster With PythonGeoffrey Mariette in Better ProgrammingApplying a function to just one previous term in a Scala lazy collectionAlonso Del Arte in The StartupLearning Dynamic Programming with a popular coding interview questionAlexander Mok in DataSeriesPDF resumé using github actionsKartik MauryaImplementing Queue In GoJane KozhevnikovaTutorial: Drools Decision Tables in Excel for a Product ProposalFelix KuestahlerAboutHelpLegalGet the Medium app"
N/A,https://medium.com/@punkyoon/chromium-%EB%B9%8C%EB%93%9C-%ED%9B%84%EA%B8%B0-a48e98c09726?source=tag_archive---------0-----------------------,"Software Engineering,Software Development,Chromium,Build,Operating Systems","집에 iMac과 Windows PC 두 대가 모두 있어서, 여러 환경에서 Chromium build를 시도해볼 수 있었다. 모든 환경에서 build에 성공을 한 것은 아니지만, 비교해볼만 한 것 같아서 적어두기로 했다. 그냥 후기글이기 때문에, 실질적으로 도움되는 내용은 없을 수 있다.Windows이전에 게임이나 다소 무거운(?) 작업들을 진행할 경우에 대비해서 Windows PC를 나름 좋은 사양으로 맞춰두었다. 실제로는 게임할 시간이 별로 없거나, 다소 무거운 작업을 할 경우가 없어서(이전에 졸업작품한다고 했던 커널 빌드 정도) 실제 사용횟수는 얼마되지 않았다. 집에 있는 컴퓨터 중에서는 가장 사양이 좋았기 때문에 제일 먼저 Chromium build를 시도해보았다.평소에는 Windows 환경에서 개발을 하거나, Visual Studio를 만질 일이 없어서, 이 환경에서 Chromium을 build한다는 것은 나에게 꽤나 까다로운 과정이었다.Windows Build Instruction문서에 나와있다고는 하지만, Visual Studio 설정을 건드는 것부터 어떻게 해야할지 당황스러웠고, Mac이나 Linux처럼 간단하게 명령어로 무언가를 설정하거나 설치하는 것이 아닌 경우가 많았어서 헤맸다. 결국에는 gn get out/Default 명령을 실행할 때 부터 알지 못할 에러가 발생하는 바람에 포기했다.이 과정에서 각종 Windows 관련 빌드 도구들을 설치했었는데, 설치 속도도 느리고 용량도 굉장히 커서 애를 먹었던 기억이 있다. 참고로 설치 속도는 DNS 설정을 1.1.1.1로 할 때보다 8.8.8.8로 했을때 더 빨라졌었다.MacMacbook이 아니라 iMac 환경에서 build를 진행했다. 참고로 집에서 무언가를 개발할 때, Macbook의 조그마한 화면을 들여다보는 것이 피로해서 단순한 웹 개발 용도로 iMac을 구입했었다. iMac을 사용하다보면 확실히 쾌적하다는 느낌이 든다.Mac Build InstructionWindows와는 비교도 할 수 없을 정도로 수월하게 build를 진행할 수 있었다. 특히 CPU와 RAM 등 하드웨어 사양 자체는 Windows PC가 훨씬(?) 좋았는데, Mac은 최적화가 잘 되어있는 것인지는 몰라도, 전반적인 과정 자체가 빠르게 진행되는 느낌이였다.하지만.. iMac을 구입할 당시에 가벼운 목적으로 구입한 것이기 때문에 SSD 용량이 256GB 밖에 되지 않는 것이 문제였다. 결국에는 build 중간에 디스크 용량 부족으로 아무것도 할 수 없는 상황이 되었다.어떻하지?iMac의 SSD를 업그레이드 하기에는 어려움이 많았고, Windows는 이미 build 하기를 포기했기 때문에 결국에는 Linux(Ubuntu) 환경에서 시도해보는 수 밖에 없었다. 기존 Windows PC에 설치된 것들을 밀어버리기에는 나름대로 쓰일 때가 있어서, SSD 512GB를 추가로 구매하고, RAM을 32GB로 업그레이드 하기로 결정했다. 추가로 구매한 SSD에 Ubuntu를 설치하고, 해당 환경에서 Chromium을 build!참고로, 기존에 사용하던 Windows PC의 대략적인 사양은 다음과 같다.RAM 8GBSSD 128GBHDD 1TBCPU i7–7700Ubuntu확실히 사양이 좋아진 탓인지, 운영체제 설치도 빠르게 끝나고, 다른 작업들을 바로 시작해볼 수 있었다.Linux Build Instruction운영체제를 새로 설치하는 과정도 포함되서 그런 것일 수도 있지만, Mac에서 만큼의 수월함을 느끼지는 못했다. 예상치 못하게, python 실행 관련 명령에서 에러가 발생하기도 했고, 명령을 실행하니 터미널이 꺼져버리는(..) 이상한 문제도 겪었다. 하지만 Windows와 비교했을 때에는 굉장히 편하게 build를 할 수 있었기 때문에 나름 만족스러운 build 경험이기는 했다.후기Windows를 제외하면(..) Mac과 Linux 환경에서 문서에 나온대로만 따라하면 수월하게 빌드를 진행할 수 있었다. 물론 Mac에서 build를 수행하는 것이 가장 원활하고, 쾌적한 느낌이었다. 하지만 Mac은 하드웨어를 확장하기에 어려움이 있을 수도 있다는 단점 때문에, 일반 사용자가 chromium을 build할 때에는 Linux 환경에서 수행하는 것도 꽤 괜찮은 선택인 것 같다.Written bypunkyoongoodbyeFollowSoftware EngineeringSoftware DevelopmentChromiumBuildOperating SystemsMore from punkyoonFollowgoodbyeMore From MediumPackaging in Python: Tools and FormatsMartin Thoma in Towards Data ScienceThe Only Introduction to Golang You NeedLouis Petrik in Better ProgrammingMicroservices Security — Broken Object Level AuthorizationLal VermaThe Most Exciting Part of Microsoft Edge is WebView2Matthew MacDonald in Young CoderHow I Use Linux ProfessionallyShawn Grover in The StartupDonald Trump Won, No Matter What Happens NextJessica Wildfire in The Apeiron Blog(Why) There Was no Biden Landslideumair haque in Eudaimonia and CoThe Election Should Never Have Been This Closeumair haque in Eudaimonia and CoAboutHelpLegalGet the Medium app"
How Deadlock Occurs?,https://medium.com/@bhavanavasamsetty00/how-deadlock-occurs-2d9bc4003808?source=tag_archive---------1-----------------------,"Operating Systems,Deadlock,Bankers Algorithm","Deadlock is a usually occurred when different processes are waiting for the resources to perform a particular task. It is a never-ending process.Why we are facing this?This occurs when a particular process trying to access the same resources at a time. By eliminating one of the conditions we can avoid deadlock, those conditions are listed below…Mutual Exclusion- Only one process should be allocated to a particular resource, or else there will be a delay in releasing the requested resource to another process.Hold and Wait- All resources should be allocated to respective processes before the execution begins.No Preemption- A resource can’t be allocated forcefully from one particular process, it should be released by itself to another process.Circular Wait- A process should be requested in an order. For example, if Process P wants to use the resources R1 and R3, first it should request R1 then R3.Representation of DeadlockCredit: tutorialwing.comBy observing the above diagram, we can notice that Process P1 is waiting for Resource R2, which is allocated(R2) to Process P2, but unfortunately, Process P2 is waiting for Resource R1, but R1 is already allocated to Process P1.Deadlock avoidanceThe system firsts checks whether the process is in a safe state or not, if it is in a safe mode, then resources will be granted at a particular time, or else resources will not be assigned to the processes. In this way, we can avoid this never-ending process. Deadlock avoidance can be done with Banker’s Algorithm.Banker’s AlgorithmThis algorithmic approach is most widely used in the banking sector, so this algorithm is called Banker’s algorithm. This helps to check whether the loan can be sanctioned to a person or not.Credit: gateoverflow.inDeadlock DetectionDeadlock occurs if and only if the system doesn’t employ either Deadlock Prevention or Deadlock Avoidance. So in this case, the system must follow two algorithms…An algorithm which examines the state of the system to check whether the deadlock has occurred.Algorithm to recover from the deadlock.Recovery from DeadlockOnce deadlock is determined, make sure that it is aborted. This process can be done manually or automatically by the system. There are mainly two methods to be followed for breaking down the deadlocks, those are…Process Termination- This method is having again two different methods, they are… 1. Abort all deadlocked processes 2. Abort one process at a time until the deadlock cycle gets eliminated.Resource Preemption- They are again 3 issues to be followed in this approach they are… 1. Selecting a Victim 2. Rollback 3. Starvation.I hope you all like this article, stay tuned for my next article :)Written byBhavana VasamsettyBlogger | Btech | Computer Science |FollowOperating SystemsDeadlockBankers AlgorithmMore from Bhavana VasamsettyFollowBlogger | Btech | Computer Science |More From MediumHello World in GoSher ChowdhuryGetting started with .NET Core API, MongoDB, and TransactionsAlex AlvesHow I Programmatically Accessed My PowerSchool AccountChase in The StartupStartup Culture: a RetrospectiveMarc Fichtel in Better ProgrammingMy Experience of Tableau Desktop Specialist ExaminationVivek Parashar in The StartupThe 4 Best Online Learning Platforms in 2020Harry Khan in The StartupWeb Optimization: Increasing FPS by Disabling Hover EffectCharis Theodoulou in Better ProgrammingInline and Reified Type Parameters in KotlinJasmeet Kaur in The StartupAboutHelpLegalGet the Medium app"
Building Linux From Scratch on a Google Cloud Virtual Machine,https://medium.com/@michael.craig.fitzgerald/building-linux-from-scratch-on-a-google-cloud-virtual-machine-1a5e64683fb9?source=tag_archive---------0-----------------------,"Linux,Compilation,Linux From Scratch,Operating Systems,Tutorial","Links to Part 1, Part 3A barn raising in Canada. Source: WikipediaReferences are made to LFS Version 9.1-systemd using the format LFS x.x.x… for specific sections. Command blocks are largely copied verbatim with minor customizations for this setup.This part of the tutorial will comprise annotations for each build step for the temporary system in LFS 5.4–5.35 and some notes on system preparation for the final build.Increasing compute resources (Optional).Caution! Doing this could cost you money. Make yourself aware of the costs associated with using more compute resources. You can complete the LFS build without doing this.I am going to increase the compute power of my VM to 8 cpus and 32GB of memory so that we can take advantage of parallel compilation and speed up the overall build time. A list of machine types can be found here.LFS 4.5 warns that using parallel compilation could lead to failed builds and debug messages that are hard to interpret. We are going to try anyway and adjust as needed.#stop instancegcloud compute instances stop [INSTANCE-NAME] #change machine typegcloud compute instances set-machine-type [INSTANCE-NAME] --machine-type e2-standard-8#start instancegcloud compute instances start [INSTANCE-NAME]The output of nproc should be 8.Log in as the lfs user.#start login shellsu - lfs#if your prompt doesn't switch use the foreground commandfgBinutilsThis is the first pass build of binutils. We will time the compilation and installation to determine the SBU.cd $LFS/sourcestar -xf binutils-2.34.tar.xz && cd binutils-2.34mkdir -v build && cd build#wrap in time function to compute SBU#this will be the only time we doe this.time { ../configure --prefix=/tools     \             --with-sysroot=$LFS        \             --with-lib-path=/tools/lib \             --target=$LFS_TGT          \             --disable-nls              \             --disable-werror &&        \        make -j$(nproc) &&              \        case $(uname -m) in          x86_64) mkdir -v /tools/lib && ln -sv lib /tools/lib64 ;;        esac &&                         \        make install; }#end time blockcd $LFS/sources && rm -rf binutilsHere is the output of the time function:real 0m50.484suser 2m45.603ssys 0m28.736sThis suggests that our SBU is about 1 minute. We can use that to estimate build times for other packages. Again, this assumes you are using the same machine type with 8 processors.GCC (10 minute estimated build time)#step 1: tar -xf gcc && mv gcc-9.2.0 gcc & cd gcc#step 2: untar additional required packagestar -xf ../mpfr-4.0.2.tar.xz && \mv -v mpfr-4.0.2 mpfr && \tar -xf ../gmp-6.2.0.tar.xz && \mv -v gmp-6.2.0 gmp && \ tar -xf ../mpc-1.1.0.tar.gz && \mv -v mpc-1.1.0 mpc#step 2: change default dl location (verbatim LFS 5.5)for file in gcc/config/{linux,i386/linux{,64}}.hdo  cp -uv $file{,.orig}  sed -e 's@/lib\(64\)\?\(32\)\?/ld@/tools&@g' \      -e 's@/usr@/tools@g' $file.orig > $file  echo '#undef STANDARD_STARTFILE_PREFIX_1#undef STANDARD_STARTFILE_PREFIX_2#define STANDARD_STARTFILE_PREFIX_1 ""/tools/lib/""#define STANDARD_STARTFILE_PREFIX_2 """"' >> $file  touch $file.origdone#step 3: point to 64-bit libs (verbatim LFS 5.5)case $(uname -m) in  x86_64)    sed -e '/m64=/s/lib64/lib/' \        -i.orig gcc/config/i386/t-linux64 ;;esac#step 5: mkdir -v build && cd build#step 6:../configure                                       \    --target=$LFS_TGT                              \    --prefix=/tools                                \    --with-glibc-version=2.28                      \    --with-sysroot=$LFS                            \    --with-newlib                                  \    --without-headers                              \    --with-local-prefix=/tools                     \    --with-native-system-header-dir=/tools/include \    --disable-nls                                  \    --disable-shared                               \    --disable-multilib                             \    --disable-decimal-float                        \    --disable-threads                              \    --disable-libatomic                            \    --disable-libgomp                              \    --disable-libquadmath                          \    --disable-libssp                               \    --disable-libvtv                               \    --disable-libstdcxx                            \    --enable-languages=c,c++#step 7:make -j$(nproc)#step 8:make install#step 9: cleanupcd $LFS/sources && rm -rf gccActual build time: 5 minutesLinux API Headers (< 1 minute estimated build time)#step 1tar -xf linux-5.5.3.tar.xz && cd linux-5.5.3#step 2: clean the directorymake mrproper#step 3:make headers#step 4: copy headers to /tools/includecp -rv usr/include/* /tools/include#step 5: cleanupcd $LFS/sources && rm -rf linux-5.5.3Glibc (5 minute estimated build time)From here on I will omit the extraction step for conciseness.There is a specific warning that this build might fail with parallel make.mkdir -v build && cd build../configure                             \      --prefix=/tools                    \      --host=$LFS_TGT                    \      --build=$(../scripts/config.guess) \      --enable-kernel=3.2                \      --with-headers=/tools/includemake -j$(nproc)make installActual build time: 3 minutes.Parallel make did not seem to fail. LFS 5.7.1 recommends a sanity check at this point that tries to compile a dummy C program. Our build passed.Libstdc++ (< 1 minute estimated build time)This is included in the gcc source code, which needs to be extracted again.I will omit build directory creation, make, and install steps here forward.../libstdc++-v3/configure           \    --host=$LFS_TGT                 \    --prefix=/tools                 \    --disable-multilib              \    --disable-nls                   \    --disable-libstdcxx-threads     \    --disable-libstdcxx-pch         \    --with-gxx-include-dir=/tools/$LFS_TGT/include/c++/9.2.0Binutils Pass 2 (1 minute estimated build time)CC=$LFS_TGT-gcc                \AR=$LFS_TGT-ar                 \RANLIB=$LFS_TGT-ranlib         \../configure                   \    --prefix=/tools            \    --disable-nls              \    --disable-werror           \    --with-lib-path=/tools/lib \    --with-sysroot#after make and install, prepare the linkermake -C ld cleanmake -C ld LIB_PATH=/usr/lib:/libcp -v ld/ld-new /tools/binGCC Pass 2 (13 minute estimated build time)Caveat: make sure you are in the extracted gcc-9.20 source folder#create full version of internal headercat gcc/limitx.h gcc/glimits.h gcc/limity.h > \  `dirname $($LFS_TGT-gcc -print-libgcc-file-name)`/include-fixed/limits.h# point to appropriate linkerfor file in gcc/config/{linux,i386/linux{,64}}.hdo  cp -uv $file{,.orig}  sed -e 's@/lib\(64\)\?\(32\)\?/ld@/tools&@g' \      -e 's@/usr@/tools@g' $file.orig > $file  echo '#undef STANDARD_STARTFILE_PREFIX_1#undef STANDARD_STARTFILE_PREFIX_2#define STANDARD_STARTFILE_PREFIX_1 ""/tools/lib/""#define STANDARD_STARTFILE_PREFIX_2 """"' >> $file  touch $file.origdone#adjust for 64 bit systemcase $(uname -m) in  x86_64)    sed -e '/m64=/s/lib64/lib/' \        -i.orig gcc/config/i386/t-linux64  ;;esac#pull in required filestar -xf ../mpfr-4.0.2.tar.xz && \mv -v mpfr-4.0.2 mpfr && \tar -xf ../gmp-6.2.0.tar.xz && \mv -v gmp-6.2.0 gmp && \ tar -xf ../mpc-1.1.0.tar.gz && \mv -v mpc-1.1.0 mpc#fix known issuesed -e '1161 s|^|//|' \    -i libsanitizer/sanitizer_common/sanitizer_platform_limits_posix.cc#configure buildCC=$LFS_TGT-gcc                                    \CXX=$LFS_TGT-g++                                   \AR=$LFS_TGT-ar                                     \RANLIB=$LFS_TGT-ranlib                             \../configure                                       \    --prefix=/tools                                \    --with-local-prefix=/tools                     \    --with-native-system-header-dir=/tools/include \    --enable-languages=c,c++                       \    --disable-libstdcxx-pch                        \    --disable-multilib                             \    --disable-bootstrap                            \    --disable-libgomp#after make and install, symlink gcc to ccln -sv gcc /tools/bin/ccThe actual build and install time was approximately 5 minutes. The build passed the recommended sanity check described in LFS 5.10.Tcl (< 1 minute)cd unix./configure --prefix=/tools#after make and installchmod -v u+w /tools/lib/libtcl8.6.somake install-private-headersln -sv tclsh8.6 /tools/bin/tclshExpect (< 1 minute)cp -v configure{,.orig}sed 's:/usr/local/bin:/bin:' configure.orig > configure./configure --prefix=/tools       \            --with-tcl=/tools/lib \            --with-tclinclude=/tools/include# different installmake SCRIPTS="""" installDejaGNU (< 1 minute)./configure --prefix=/toolsM4 (< 1 minute)sed -i 's/IO_ftrylockfile/IO_EOF_SEEN/' lib/*.cecho ""#define _IO_IN_BACKUP 0x100"" >> lib/stdio-impl.h./configure --prefix=/toolsNcurses (< 1 minute)sed -i s/mawk// configure./configure --prefix=/tools \            --with-shared   \            --without-debug \            --without-ada   \            --enable-widec  \            --enable-overwrite#after make and install ln -s libncursesw.so /tools/lib/libncurses.soBash (< 1 minute)./configure --prefix=/tools --without-bash-malloc#after make and installln -sv bash /tools/bin/shBison (< 1 minute)./configure --prefix=/toolsBzip (< 1 minute)make -f Makefile-libbz2_somake clean#to installmake PREFIX=/tools installcp -v bzip2-shared /tools/bin/bzip2cp -av libbz2.so* /tools/libln -sv libbz2.so.1.0 /tools/lib/libbz2.soCoreutils (< 1 minute)./configure --prefix=/tools --enable-install-program=hostnameDiffutils (< 1 minute)./configure --prefix=/toolsFile (< 1 minute)./configure --prefix=/toolsFindutils (< 1 minute)./configure --prefix=/toolsGawk (< 1 minute)./configure --prefix=/toolsGettext (~ 2 minutes)./configure --disable-shared#to installcp -v gettext-tools/src/{msgfmt,msgmerge,xgettext} /tools/binGrep (< 1 minute)./configure --prefix=/toolsGzip (< 1 minute)./configure --prefix=/toolsMake (< 1 minute)./configure --prefix=/tools --without-guilePatch (< 1 minute)./configure --prefix=/toolsPerl (~ 2 minutes)sh Configure -des -Dprefix=/tools -Dlibs=-lm -Uloclibpth -Ulocincpth#to installcp -v perl cpan/podlators/scripts/pod2man /tools/binmkdir -pv /tools/lib/perl5/5.30.1cp -Rv lib/* /tools/lib/perl5/5.30.1Python (~ 2 minutes)Note: extract the (capital P) Python source archive.sed -i '/def add_multiarch_paths/a \        return' setup.py./configure --prefix=/tools --without-ensurepipSed (< 1 minute)./configure --prefix=/toolsTar (< 1 minute)./configure --prefix=/toolsTexinfo (< 1 minute)./configure --prefix=/toolsUtil-linux (~ 1 minute)./configure --prefix=/tools                \            --without-python               \            --disable-makeinstall-chown    \            --without-systemdsystemunitdir \            --without-ncurses              \            PKG_CONFIG=""""Xz (< 1 minute)./configure --prefix=/toolsFinal PreparationsWe will skip the optional stripping step since we have tons of space.Change the ownership of $LFS/tools to root.chown -R root:root $LFS/toolsThis concludes Part 2.Up next in Part 3: Building the LFS System (LFS 6.1–6.80).Written byMichael FitzgeraldFollowLinuxCompilationLinux From ScratchOperating SystemsTutorialMore from Michael FitzgeraldFollowMore From MediumEnhancing Gray-Scale Images Using Numpy, Open CVKavya Musty in The StartupBash History EnhancePaolo CozziWriting Code as A TeamBrian Jenney in The InnovationBlazing fast CI with GitHub Actions, Poetry, Black and PytestDaniel van FlymenHow To Use Python String-Literal ModifiersJonathan Hsu in Better ProgrammingPHP 7.x — P5: Truthy BoolsDino Cajic in Dev GeniusMy Journey as a Scholar in Google Africa Challenge Scholarship with Udacity and Andela tagged…Imo OkonInspecting HTTP requests in FlutterJakub Homlala in Flutter CommunityAboutHelpLegalGet the Medium app"
Writing A Simple Bootloader,https://medium.com/vit-linux-user-group/writing-a-simple-bootloader-5931ef084b54?source=tag_archive---------0-----------------------,"Operating Systems,Bootloader,Programming,Assembly Language","“Low-level programming is good for the programmer’s soul.” — John CarmackHello to everyone reading this. As the technology around us advances daily, we sometimes forget to appreciate the beauty of the very core basics on which our computers are built. So, today in this article I will try to explain what is a bootloader and how to build a basic one in as simple way as possible. Before moving forward I would like to appreciate this site for its amazing content and concisely delivered information. This article is also heavily inspired from this site. I would highly recommend reading the articles here for more details on the topic. To understand the code in this article a basic level of knowledge about assembly language is required. It is better if you have required knowledge in assembly language, however, i’ll try to cover most of the required concepts. So, let’s begin..How does my computer start?Well, most of us might have thought that what actually happens when we press that power button. There is something known as PSU(Power Supply Unit) in your system hardware. When your press your power button, it sends signal to PSU which converts original AC current to DC current and supplies it to other components of the system. If it is able to provide proper power supply it sends a ‘power-good’ signal to the BIOS indicating that you may take charge now.The BIOS on receiving this signal starts another process knows as POST(Power On Self Test).It sort of checks that we are ready to go or not. It tests that whether proper power supply is there or not, memory is not corrupted, what devices are connected etc. If anything is wrong it reports error either by showing a number to I/O port or by a sequence of beeps etc.Now, after this last check if POST finds that everything is OK, it shows green flag to BIOS(just an analogy :) ). Hence, control is now transferred to BIOS.Finally, we have reached BIOS. The BIOS now creates an Interrupt Vector Table(IVT). This table stores the addresses of various Interrupt Service Routines. Interrupt is the mechanism used by hardware to signal to the processor the occurrence of an event.Now, the main job of BIOS is to load the bootloader. But how do we know where is it located in our storage device?The answer to above question is that we have a sector on our storage device that is called boot sector.(Note: For more info on what are sectors read this). The boot sector is generally the first sector of the disk or sector 0 on track 0 on head 0. Now, BIOS moves the data in boot sector into main memory at address 0x7c00 and we will use interrupt 0x19 to jump to it.If the above paragraph was not clear to you then don’t worry. When we discuss more on bootloaders you might understand it better.2. Gathering necessary stuff..Now, before we move forward and discuss more on bootloaders, we need to install a few things. First up, as we are going to write some code in assembly language we need an assembler to convert it to machine language. NASM is one such assembler for Intel x86 architecture. Second, we will install qemu, an emulator to test our bootloader as we don’t want to test this directly on our hardware.To install NASM and qemu(on debian based OSs):sudo apt-get install nasm qemuFor other OSs you may refer to internet.3. Writing our Bootloader..org 0x7c00bits 16Start:     cli    hlt times 510 — ($-$$) db 0dw 0xAA55The code might look a bit awkward to you or might look familiar. Whatever the case, let’s discuss what it means line by line.First, we have ‘org 0x7c00’. As we have discussed earlier, our bootloader is loaded into memory at 0x7c00, so this line tells NASM to set all addresses according to the fact that first instruction is at 0x7c00.Next line tells us that we are in 16 bit real mode. As x86 architecture has 16 bit registers, by default we boot into 16 bit real mode only. We can however switch to 32 bit protected mode, but I will not be discussing this here. You may however refer ‘this’ for more info on switching modes.Now, cli and hlt. cli is used to clear all interrupts and hlt is used to halt the system. This ensures that CPU doesn’t run random instructions beyond our code.Now, ‘times 510 — ($-$$) db 0’ . This needs some discussion. As we know that one sector contains only 512 bytes, we can’t write a bootloader that is bigger in size as we copy only one sector from disk(i.e. the boot sector). Also, we cannot have size less than 512 bytes as it may lead to random instructions or faults. So, to ensure that our code is 512 bytes in size we replace any of the remaining bytes with 0. $ represents the address of the current line while $$ represents address of the first line. Hence, ($-$$) represents size of the program. But why do we use only 510 and not 512?We ensure that our code is of size 510 bytes because last bytes are reserved for some specific use. The last 2 bytes store the boot signature. The last line ensures 0xAA is stored at 511th byte and 0x55 is stored at 512th byte. These 2 bytes tell the BIOS that this sector is bootable.Now, how to test our bootloader? Very Simple.First, we need to assemble our code to machine code. Just enter this command.(considering name of your file in which write your program is myboot.asm, you may however use any name).nasm -f bin -o myboot.bin myboot.asmAfter this, run below command. It copies our bootloader to first sector of virtual floppy disk image using ‘dd’ utilitydd status=noxfer conv=notrunc if=myboot.bin of=myboot.flpFinally, boot up your first bootloader :).qemu-system-i386 -fda myboot.flpOutput:THANKS FOR READINGVIT Linux User GroupTaking forward the legacy of Linus Torvalds.Follow155 Operating SystemsBootloaderProgrammingAssembly Language155 claps155 clapsWritten byTej Prakash AgarwalFollowFollowVIT Linux User GroupFollowOpen Source / Linux / DevelopmentFollowWritten byTej Prakash AgarwalFollowVIT Linux User GroupFollowOpen Source / Linux / DevelopmentMore From MediumPrint() in PythonKeno Leon4 Linux Monitoring Tools You Should UseTate Galbraith in Better ProgrammingAsk the Unity expert: what is the ECS?Oliver Balaam in Improbable EngineeringOpenID/Form Authentication in 300 lines of codeВ.КореховServing a torch model using FastAPIKelvin Jose in The StartupMinecraft RL: Part 1.3Ryan RudesWhy GPT-3 feels like ProgrammingCarlos E. Perez in Intuition MachineParent and Child joins with ElasticSearch 7Sohan Ganapathy in The StartupLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Parrot Security has released the parrot OS 4.10 |download parrot latest OS — mrscriptkiddie,https://medium.com/@harshitdodia653/parrot-security-has-released-the-parrot-os-4-10-download-parrot-latest-os-mrscriptkiddie-36227830edb2?source=tag_archive---------1-----------------------,"Parrot Security Os,Ethical Hacking,Operating Systems,Cybersecurity","Parrot OS, the flagship product of Parrot Security is a GNU/Linux distribution based on Debian and designed with Security and Privacy in mind ,has announced the release of Parrot Security OS 4.10, which makes the distribution more reliable and more secure.Parrot Security OS is a security-oriented operating system, which is designed for infiltration testing, computer forensics, reverse engineering, attack, cloud penetration testing, privacy / anonymous, password, and other occasions.The Latest Parrot 4.10 consist of some new features they are as follows:AnonSurf 3.0As we know Anonsurf is a tool which helps to anonymize the entire system under TOR using IPTables.Anonsurf 3.0 is now subdivided into 3 modules: GUI, Daemon and Utilities.The GUI is written in NIM, a blazing fast programming language very easy to write and read that compiles in native C code. It uses Gintro GTK for the interface and it has several features to let the user control the anonsurf behavior.You can start, stop and reload anonsurf, you can easily configure anonsurf to automatically start at boot, and it is easy to monitor the status of tor and see the traffic, the logs and some usage statistics thanks to its integration with NYX.The new AnonSurf Daemon takes care of shutting down the service automatically at shutdown in case the user powered off the computer with anonsurf enabled, which was a known cause of later connectivity issues in previous versions, and of corurse allows the user to tell the init system to automatically start anonsurf at boot for those who need it.AnonSurf is overall more reliable and more stable, and it is an important step forward for the whole project since we deeply believe in privacy and the role it covers in the fight for freedom.Linux 5.7Parrot OS 4.10 now comes with Linux 5.7.Few important changes of this new kernel version:Improved scheduler.new ExFAT filesystem module.Spli Lock detection.userfaultfd() write protection support.A BPF-based Linux Security Module called bpf-lsm.Allow clone3() to spawn processes into cgroups.Improved perf cgroup profiling.Improved btrfs filesystem support.Metasploit 6.0The development of Metasploit 6 has finally started, and it ships a lot of awesome features that were missing from the previous versions.It is important to know that this version will break retro-compatibility with previous versions, so it is important for our users to understand what has changed in this version.One of the most wanted features is finally here: end-to-end encryption in meterpreter backdoors, which of course breaks retro-compatibility with older meterpreter payloads.These are the updates in parrot 4.10 ,if you are running older version of parrot you can update to the latest version by downloading it from here.or you can type the following command i n your parrot terminal .sudo parrot-upgradeORsudo apt update && sudo apt full-upgradeKeep Coming for more!!Thank youOriginally published at https://mrscriptkiddie.com on August 22, 2020.Written byfreaky DODOHey guys i am Harshit Dodia aka freaky DODO , i am a student of Information Technology and certified Ethical hackerFollowParrot Security OsEthical HackingOperating SystemsCybersecurityMore from freaky DODOFollowHey guys i am Harshit Dodia aka freaky DODO , i am a student of Information Technology and certified Ethical hackerMore From MediumHTTP APIs in AWS API GatewayRoss Rhodes in AVM Consulting BlogUnder the Hood of C# Alias Types and NamespacesMorgan Kenyon10 Steps to Building Web Applications With Accessibility (a11y)Jennifer Fu in Better ProgrammingSemantic HTML: Why Use It?Michael KornblumYou Should Write Bad Code More OftenYgor Rebouças Serpa in Better ProgrammingDepth-First Search vs. Breadth-First Search in PythonXuanKhanh Nguyen in NothingaholicWhy Do Incompetent Managers Get Promoted?Lance Ng in Better ProgrammingMonitor COVID cases using Python in less than 50 lines of codeAndrey in Seamless CloudAboutHelpLegalGet the Medium app"
Custom Memory Manager in C++,https://medium.com/@amitpriyankar22/custom-memory-manager-in-c-6bb2c33f25fc?source=tag_archive---------2-----------------------,"Memory Management,Cpp,Operating Systems,Dynamic Memory Allocation,Malloc","Dynamic Memory allocation has been a fundamental part of most of the computer systems for decades. It is required when there is a need for memory blocks at the runtime. In C and C++, you might have used standard library functions like malloc and free to allocate memory from the heap for your program dynamically. The program then uses this memory for some defined purpose. Usually, the objective is to add a node to a data structure. In object-oriented languages, dynamic memory allocation is used to get the memory for a new object.It is a general tendency to think that heap will always fulfil our needs of memory. But heap is limited. Most of us may be aware of the physical limit, but there is also a subtle “virtual” limit. This limit becomes much more apparent if we’re using a lot of allocation and deallocation in a long-running program. Even though we’re always free to return the memory to the heap if it is no more needed, this comes with a cost. The heap may develop “holes” where previously allocated memory has been returned between blocks of memory still in use. For a new request, our memory allocator would have to search for the appropriate “hole”(i.e. large enough to fulfil our need) among the free holes. Think about a situation where we may not be able to find a hole large enough, but there is a good amount of free space available. Confused?Since what we want is a contiguous block of memory, none of the holes may be large enough; instead, there are too many small holes. This is memory fragmentation, one of the major problems with dynamic memory allocation. There are many different techniques used to minimise fragmentation like using a good memory allocation scheme or coalescing holes into big ones. It gives a motivation of having a custom memory manager in which we have complete freedom to choose the allocation scheme and different other techniques to deal with such problems.But wait. Why can’t default memory allocators in C and C++ save us? To answer this question, let’s dive into details.Functions such as malloc and new are general-purpose memory allocators. Our code may be single-threaded, but the malloc function it is linked to can handle multithreaded paradigms just as well. It is this extra functionality that degrades the performance of these routines.In their turn, malloc and new make calls to the operating system kernel requesting memory, while free and delete make requests to release memory. This means that the operating system has to switch between the user-space code and kernel code every time a memory request is made. Programs making repeated calls to malloc or new eventually run slowly because of the repeated context switching.The memory that is allocated in a program and subsequently not needed is often unintentionally left undeleted, and C/C++ doesn’t provide for automatic garbage collection. This causes the memory footprint of the program to increase. In the case of really big programs, the performance takes a severe hit because available memory becomes increasingly scarce and hard-disk accesses are time intensive.Written byAmit PriyankarFollowMemory ManagementCppOperating SystemsDynamic Memory AllocationMallocMore from Amit PriyankarFollowMore From MediumStarting With Your First PyQT GUI Python ApplicationAdivardhan Maheshwari in The StartupRecursion With Sierpinski’s TriangleJake ShamsUse the fork, Luke!Maxim VolginScalable Real-time Communication With PusherVelotio TechnologiesR Docker fasterJacqueline NolisHow to Build an API With Ruby on RailsCaleb in The StartupGo memory ballast: How I learnt to stop worrying and love the heapRoss Engers in Twitch BlogPython Tricks 101Gautham Santhosh in HackerNoon.comAboutHelpLegalGet the Medium app"
Challenge: CS162 in 1 Week,https://medium.com/@james_fricker/challenge-cs162-in-1-week-bdc8802a6cc5?source=tag_archive---------3-----------------------,"Ultralearning,Online Course Ideas,Operating Systems,Cs162,Learning","Ever since I wrote my first program, I’ve been interested in computer systems and computer programming. One thing that I felt was missing from my computer knowledge was that deeper understanding of computers. At university, I had only taken subjects relating to Algorithms, Data Structures and Problem Solving, but never things like Computer Architecture, Networking or Operating Systems.Recently, I embarked on a mission to solve this problem.OutlineWhat Was the Challenge?In order to learn these missing pieces of my computer knowledge, I decided to go through the entirety of CS162 in a single week. CS162 is an ~18 week course on Operating Systems offered at the University of Berkeley. Completing this course would give me a great understanding of how Operating Systems work and give me a deeper insight into what happens when I run various programs.Fortunately for me, the course materials and lectures are all available for free online ( course material, lectures).I was aiming to complete this course during the last week of my university holidays. That is, an 18 week course in only 1 week. This was going to happen with a few constraintsI don’t need to complete the projectsI will sit the final exam on the last Sunday of the weekMotivationIn order to really motivate myself, I created a contract with my brother. The contract stated that I was to sit the final exam on Sunday the 26th of July and if I didn’t achieve a passing mark (50%), then I would donate a sum of money to charity. If I didn’t sit the exam at all then I would need to pay an even bigger sum.I don’t suggest this motivation technique for everything but it definitely has it’s place. For me, I knew that having this social pressure to learn would help me to learn much more over the week than I would have if I just tried to learn on my own. There are some sites that will do this for you automatically like BeeminderWhy did I decide to do this?The first and most obvious reason of why I did this is that I have a high level of interest in learning, and I thought that learning about Operating Systems would be both useful and interesting. Interesting in the sense that I would have a better understanding of computers and useful in that when I begin my first job at ANZ next year, I’d love to get involved with some programming there. My idea is that having a background like this will make it easier to learn new tools and to have a much more well-rounded view of computer systems.Another reason why I wanted to try this was to see how much I could learn in a week. I recently read the book “ Ultralearning “ by Scott Young. A few years ago, Scott undertook what he calls the MIT Challenge. He did an entire MIT 4 year degree both in one year, and using material available for free online.This inspired me to also undertake something similar. I’ve got a massive stack of online courses that I want to do some day, but this presented a great opportunity to try one out and see how I’d go.What did I learn?So now on to the actual fun stuff, what did I actually learn. Well to put it simply, the course and learning didn’t pan out as I had expected.I began the first few days by reading the relevant textbooks for the course and taking notes. This strategy was working really well in terms of learning, but not so well in terms of speed. In order to get through the course, I’d have to go through much quicker.At this point I changed tack and began watching the lectures on 2x speed. This was a fairly decent strategy, however as I got closer to the end, I realised I was still going to fall short of watching all the lectures. 26 lectures at 1:30 each takes quite a while! (Surprisingly 3x speed didn’t really help me that much).So in the end I realistically made my way about 50% of the way through the course.I successfully learnt about things like:Kernel AbstractionDual Mode OperationOS Scheduling techniquesThe fork() methodLocksProcess and ThreadsVirtualisation of memoryThese things are super interesting and I am very happy I spent the time learning them.What would I do differently?In hindsight, there are a few things that I would change.Obviously the main problem that I encountered was that I wanted to get through the entire course in the week and I didn’t manage to do that. I don’t think that came down to the amount of work specifically, I think the mistakes were mostly down to a lack of awareness and planning.My initial stages of reading the textbooks rather than watching lectures was a good initial strategy, but I also think the lectures provided adequate explanations and were more time-efficient. If I had this challenge again, I’d stick to the lectures where possible and only use the textbook for further clarification when needed.I also think I didn’t plan for this as well as I could have. I underestimated the amount of work I would have to do and perhaps started a bit too confident in my learning abilities. One thing I would do next time would be to plan ahead more. Me spending 4–6 hours a days trying to learn meant I could only get through so much material in a day, when in reality, I had a lot to get through and need to spend more time if I was going to get through everything.Should you do this?Overall I think this experience was worthwhile. While I didn’t complete the course like I had imagined, I still focussed more than I would have had it not been for the challenge. Sometimes when you have a week to do nothing, the week can quickly fade into a slump week. I am very happy that my week had a purpose and I was able to gain something from it.It’s unrealistic to expect a full-time employee to commit a week of solid work to a course like this. I am really lucky to be in university and to have this free time. It’s much more likely that someone would undertake these courses in their spare time after work or on weekends. I think that while learning is good, it’s also important to have something to show for it. One thing I would recommend is to make sure you use the course to create something, be that a blog post like this or a project that you can create that will showcase your understanding of the topic. Without this, your new knowledge isn’t as useful.Online learning is something that will become much more common in the future, and it’s amazing that we have such resources like MITOCW and these courses from Berkeley available for free. I’d highly recommend finding something that interests you and diving in. Also be careful though about window shopping for courses. Sometimes you can feel like you are learning when you are just finding lists of courses to try one day. It’s important to remember that the actual work comes in doing the course, not just looking at the outside or watching the intro videos.Even if it’s not this specific course that I took, I think using your free time to learn new things is a great idea. I am really happy about what I learnt during this week and no doubt will be sitting through some more online courses in the future.Originally published at https://www.jfricker.com on August 22, 2020.Written byJames FrickerFollowUltralearningOnline Course IdeasOperating SystemsCs162LearningMore from James FrickerFollowMore From MediumSwift Bit, Byte and NibbleSteven Curtis in The StartupStartups and the Production Readiness ProcessAl-Waleed Shihadeh in Better ProgrammingWhy Your Software Solutions Will Fail If Your Developers Aren’t Aligned to the BusinessTrent Miskin in The Entrepreneur LifeLet’s graph: Explore your Steam Library in Neo4jAlexander Erdl in Neo4j Developer BlogHow I Scaled a Software System’s Performance By 35,000%Joseph Gefroh in The StartupHow to Develop and Deploy a Webhook Alert Action App with Custom Payload and Headers for SplunkAnkit Tyagi in Adobe Tech BlogThe incredible power of Python’s replace regexJOSHUA WEINSTEIN in Python In Plain EnglishHow To Update Project Versioning With npm toolBhargav Bachina in Bachina LabsAboutHelpLegalGet the Medium app"
Windows 95: The Most Important Operating System in History,https://medium.com/@ricomariani/windows-95-the-most-important-operating-system-in-history-485ad08b717b?source=tag_archive---------0-----------------------,"Operating Systems,Windows 95,Windows","This is obviously an opinion piece and a bit of nostalgia but, despite that, Win95 being the most important OS ever is not a claim that I make lightly. I’m a student of this space and there are many great contenders but, in my opinion, none had as dramatic an effect on the entire industry, and certainly none as quickly as Win95.So, what am I talking about? Let’s set some context:In 1995, PCs outnumbered all other computers at roughly 80M units, growing to roughly 90M by 1998. I think a case can be made that this out numbers all other general purpose computing devices combined (but I have no reference for that). For instance, by comparison, Mac sales in 2002 (the oldest number I could readily find), were only 3.1M. So by volume anything that happened on the PC was going to be important.These computers were largely running something like Windows 3.1, with various DOS 5.0 combos and the like. The state of the software development in that environment was, to be generous, terrible. Much of the most important software was running in this horrible 16 bit segmented architecture universe thrust upon us by the 8086. Much of the most important software ran with no memory protection, in shared address spaces. Even important software like critical printer drivers and disk drivers ran in that mode, “real mode” 8086. The most important GUI applications were running in that same 16-bit mode, in a shared memory space, with cooperative scheduling. Any application could readily bring down the whole system and often did. Debugging in this universe was a horrid thing requiring miracles (see the section on debugging in My History of Visual Studio)The hardware extensibility situation was horrible with many if not most things coming in the form of ISA cards, noted for being configurable only by dip switches and requiring an exact combination of driver, dip-switch, and config.sys setup. Even the simplest things like installing a Sound Blaster audio card (frequently not included by default) was an arcane process. The number of “free interrupts” and DMA channels was a sales feature of PCs. Like a thing you put on the damn sticker beside processor speed and memory. Many video cards were still based on that 8Mhz ISA bus and graphics acceleration could require very tricky driver setup which again was prone to bizarre crashes…And that’s where the industry was… the most important computing platform was a hot mess.Now let’s talk a moment about Windows 95 and how it is built; I won’t go into this in great detail because you can read a lot more about this sort of thing at the Wikipedia article on the subject. Suffice to say Win95 is not a jewel of algorithmic perfection by any means. It is nothing like the best operating system Microsoft knew how to build at the time, or was capable of building at the time. We have existential proof of that: look at Windows NT if you like, or consider other contemporaneous operating systems and consider “could Microsoft have built that had it put its best on such an endeavor” I think it’s easy to conclude that cleaner solutions than Win95 could have been found. But none of those were in the offing. And why?In order to be successful Win95 had to be wildly backwards compatible with the current ecosystem including:support for critical real mode drivers and DOS applications generally, including, importantly, tons of games which were generally DOS+graphics/memory extensionssupport for every important “Win16"" (i.e. Windows 3.1 or less) application in existenceTo this add:enable the creation of new Win32 applications compatible with Windows NT, including full address isolation and threading, and an entirely different debugging and i/o modelenable a 32-bit driver path you could reasonably migrate toenable new plug and play devices despite the existence of O(10⁴) ISA devices that would hork things up if not properly detected “some other way” and then skillfully “dodged” by Plug and PlayWindows 95 succeeded wildly at this. The number of compromises and special cases and shims was staggering, but it worked; selling over a million units in the first day towards about 40 million units in the first year.And what were the consequences?Well you might like the look and feel or not like it, but importantly in just a few years we see consequences like:ISA cards went from the main-thing to a side-thing to a non-thingvirtually everything went Plug and Play, enabling more complex cards and configurations; interrupt shortages were soon a thing of the pastevery important application migrated from Win16 to Win32 with the old “real mode” applications dying the fastest, real mode didn’t even have to ship by Win98 (which had USB in it by default)DOS drivers went the way of the dodo, the new 32 bit driver model was easier, and more stable, rendering the drivers much cleaner; more complex drivers became possiblebizarre mandatory user configurations were largely gone, you didn’t edit autoexec.bat or config.sys on a weekly basis anymoretons of new exciting cards became available, including sound and video, high speed video became a thing, it could self configure!These effects had further amazing consequences in the next few years; the most important thing was that the PC platform had gone from being a weird kludge to being much more reasonable and uniform. Further operating systems benefited from this tremendously; Windows 2000 and then Windows XP of course but not just the MS operating systems. The quality of Linux on PC was never better, the platform changes were tremendous for PC based servers and you could reasonably make PCs for HPC and other applications. Today’s mega computers look roughly like giant PC arrays with fabulous networking. The PC platform became so viable that Apple could reasonably build their Macs on top of a PC foundation. An unthinkable situation just a few years prior.And why? Because above all else the industry needed a way to get to their future: the promised land of reasonable hardware and software architecture. The industry didn’t need a prefect gem of architecture beauty; what it needed was a raft that could last a few years and carry them safely to the other side. This was an incredibly difficult challenge on highly constrained systems with so many band-aids but that’s exactly what happened. The Miracle that was Windows 95 enabled an entire era of desktop computing. We are still living in that era.It’s true that things might have happened some other kind of way, but, in our reality, they didn’t. It was Windows 95 that delivered us to the future. And so, despite its many, many, warts, I believe Windows 95 can credibly be called the most important OS ever to be released. Worthy of mention beside the Titans we know and study.Written byRico MarianiI’m a software engineer at Facebook; I specialize in software performance engineering and programming tools generally. I survived Microsoft from 1988 to 2017.Follow51 2 51 51 2 Operating SystemsWindows 95WindowsMore from Rico MarianiFollowI’m a software engineer at Facebook; I specialize in software performance engineering and programming tools generally. I survived Microsoft from 1988 to 2017.More From MediumYAGNI: You Ain’t Gonna Need ItAlberto Salas in Better ProgrammingDon’t Fear the // TODOCasey McQuillan in The StartupStackOverFlowError: Causes & SolutionsRam Lakshmanan in Tier1app.comUnderstanding k8s AutoScaleYros Aguiar in DevOps for Zombies12 VSCode Shortcuts and Tactics to Ease Developmentjsmanifest in Better ProgrammingFunctional Programming With Java: StreamsBen Weidig in Better ProgrammingWhen Indexes & Performance Tuning don’t fix Slow queries in PostgresAitzaz M. Khan50 Python Interview Questions and AnswersThe Educative Team in Better ProgrammingAboutHelpLegalGet the Medium app"
Top 60 Shell Scripting Interview Questions & Answers,https://medium.com/edureka/shell-scripting-interview-questions-c60c94f21c23?source=tag_archive---------1-----------------------,"Operating Systems,Shell,Shellscripting,Shell Script,Interview Questions","Linux has started to expand its market rapidly since the past few years and Shell Scripting in Linux is one of the Top 10 occurring IT job-requirements. So, we thought of making your job easier by making an ensemble of the most commonly asked Shell Scripting Interview Questions which will get you ready for any job interview that you wish to appear.The questions have been segregated into 3 parts;Interview Questions for BeginnersInterview Questions for the IntermediateInterview Questions for the ExperiencedInterview Questions for BeginnersQ1. What is Shell?The Shell is a Command Line Interpreter. It translates commands entered by the user and converts them into a language that is understood by the Kernel. The shell interprets a command typed in at the terminal, and calls the program that you want.Q2. What is a Shell Script? Can you name some of its advantages?A shell script is a command-containing text-file that contains commands in order of their execution. Typical operations performed by shell scripts include printing text, file manipulation, and program execution.Following are the two main advantages of shell scripting:It facilitates developing your own custom OS with relevant features that best suit your needs.It facilitates designing software applications according to their respective platforms.Q3. What are the different types of variables used in Shell Script?A shell script has two types of variables :System-defined variables are created/defined by the Operating System(Linux) itself. These variables are generally defined in Capital Letters and can be viewed by “set” command.User-defined variables are created or defined by system users and the values of variables can be viewed by using the command “echo”.Q4. What are the different types of commonly used shells on a typical Linux system?There are primarily two kinds of shells in Linux OS, namely, Bourne Shell and C-Shell. Examples of derivative from each are as follows;Bourne Shell: Bourne Shell, Bourne-Again Shell, Korn Shell, POSIX Shell.C-Shell: C-Shell, TENEX C-Shell, Z-ShellQ5. How do you create a shortcut in Linux?This can be done with the help of links present in Linux OS.Hard Link: Hard links are linked to the inode of the file and have to be on the same file system as of the file. Deleting the original file does not affect the hard link.Soft Link: Soft links are linked to the file name and can reside on a different file system as well. Deleting the original file makes the soft link inactive.Q6. Tell something about the Super Block in Shell scripting?A SuperBlock is essentially a program that contains a record of specific file systems.Characteristics such as the block size, the empty and the filled blocks and their respective counts, the size and location of the inode tables, the disk block map, and usage information, and the size of the block groups are available in a superblock.Q7. What is GUI scripting?GUI is used for controlling a computer and its applications. GUI scripting supports different applications. It mostly depends on the operating system.Q8. What are the various stages of a Linux process it passes through?A Linux process generally passes through four stages:Waiting: The Linux process waits for the resource.Running: The Linux process is currently being executed.Stopped: The Linux process is stopped after successful execution.Zombie: The process has stopped but is still active in the process table.Q9. What is the difference between break and continue commands?Break: It is a simple way to escape out of a loop in progress. We can use the break command to exit out from any loop, including while and until loops.Continue: It causes the present iteration of the loop to exit, instead of the entire loop.Q10. What is the significance of the Shebang line in Shell Scripting?The Shebang line is present at the top of the script,e.g. #!/bin/sh. It simply provides information regarding the location where the engine is placed. The engine is the one that executes the script.Q11. How to pass an argument to a script?#!/bin/shct $1question 11 — Shell Scripting Interview Questions — EdurekaQ12. How to use arguments in a Script?#!/bin/shcp $1 $2question 12 — Shell Scripting Interview Questions — EdurekaQ13. How to calculate the number of passed arguments?#!/bin/shecho ""Number of Parameters passed:$#""question 13 — Shell Scripting Interview Questions — EdurekaQ14. How to get script name inside a script?!/bin/shecho ""Script Name:$0""question 14 — Shell Scripting Interview Questions — EdurekaQ15. How to check if the previous command was run successfully?#!/bin/shvar=$?if var=0thenecho ""Script was Run successfully""elseecho ""Script was unsuccessful""fiquestion 15 — Shell Scripting Interview Questions — EdurekaQ16. How to get the last line from a file using just the terminal?tail -1 <filename>Q17. How to get the first line from a file using just the terminal?head -1 <filename>Q18. How to get the 3rd element/column from each line from a file?#!/bin/shawk '{print $3}' $1question 18 — Shell Scripting Interview Questions — EdurekaQ19. How to write a function?#!/bin/shfunction example {echo ""Hello Learner""}Q20. Write down the Syntax for all the loops in Shell Scripting.For Loop:for var in word1 word2 ... wordNdo   Statement(s) to be executed for every word.doneWhile Loop:while commanddo   Statement(s) to be executed if command is truedoneUntil Loop:until commanddo   Statement(s) to be executed until command is truedoneInterview Questions for IntermediateQ21. What makes C shell a more preferable option than the Bourne Shell?C is a more preferable option in the following cases:All the commands can be aliased simply with the C shell whereas the same is not possible in the case of Bourne Shell.Lengthy commands can be used again and again in C shell whereas Bourne doesn’t allow the same in all the cases.The command history can be accessed through the C shell but it cannot be accessed through Bourne.Q22. How would you compare the strings in a Shell Script?The test command is used to compare the text strings. The test command compares text strings by comparing each character in each string.Q23. How to redirect both standard output and standard error to the same location?The two methods to redirect standard output and standard error to the same location are the following;2>&1(# ls /usr/share/doc > out.txt 2>&1 )&>(# ls /usr/share/doc &> out.txt )Q24. Differentiate between ‘ and “ quotes.Single Quotes: Used in case evaluation of variables to values is undesired.Double Quotes: Used in case evaluation of variables to values is required.Q25. When should shell programming/scripting not be used?It is not advisable to use Shell scripting in the following cases;When the task is very much complex, e.g. writing the entire payroll processing system.Where there is a high degree of productivity required.When it needs or involves different software tools.Q26. What is the lifespan of a variable inside a shell script?The lifespan of a variable inside shell script is only until the end of execution.Q27. What is a file system?The file system is a collection of files that contain information related to the files.Q28. What are the default permissions of a file when it is created?On Linux and other Unix-like operating systems, new files are created with a default set of permissions. The umask or user mask command is used to determine the default permissions for newly created files. It is a 4-digit Octal number which is set and expressed using symbolic values. The default permission of a file when it is created is 664 i.e. rw-rw-r-. The table for file permissions is given below;Q29. What does it mean by #!/bin/sh or #!/bin/bash at the beginning of every script?A script may specify #!/bin/ bash on the first line, meaning that the script should always be run with bash, rather than another shell. / bin/ sh is an executable representing the system shell. Actually, it is usually implemented as a symbolic link pointing to the executable for whichever shell is the system shell.Q30. What is the difference between $* and $@?$@ treats each quoted argument as separate arguments but $* will consider the entire set of positional parameters as a single string.Q31. Determine the output of the following command: name=Shubham && echo ‘My name is $name’.question 31 — Shell Scripting Interview Questions — EdurekaQ32. Determine the output of the following command: [ -z “” ] && echo 0 || echo 1question 32 — Shell Scripting Interview Questions — EdurekaQ33. Determine the output of the following command: echo ${new:-variable}q33 — Shell Scripting Interview Questions — EdurekaQ34. How to get part of the string variable with echo command only?#!/bin/shecho ${variable:x:y}#x - start position#y - lengthvariable=""My name is Upasana, and I work at Edureka.""echo ${variable:11:7} # will display Upasanaq34 — Shell Scripting Interview Questions — EdurekaQ35. Rewrite the command to print the sentence and convert the variable to plural: echo “I like $variable”.q35 — Shell Scripting Interview Questions — EdurekaQ36. How to print all the arguments provided to the script?#!/bin/bash  for i; do     echo $i  doneq36 — Shell Scripting Interview Questions — EdurekaQ37. How to print PID of the current shell?#!/bin/shfor PID in $$doecho $PIDdoneq37 — Shell Scripting Interview Questions — EdurekaQ38. How to print all array elements and their respective indexes?#!/bin/shfor PID in $$doecho $PIDdoneq38 — Shell Scripting Interview Questions — EdurekaQ39. How to print the first array element?#!/bin/sharray=(""This"" ""is"" ""Shell"" ""Scripting"" )echo ${array[0]}q39 — Shell Scripting Interview Questions — EdurekaQ40. What is the Crontab?Crontab stands for cron table because it uses the job scheduler cron to execute tasks. The crontab is a list of commands that you want to run on a regular schedule, and also the name of the command used to manage that list.The schedule is called the crontab, which is also the name of the program used to edit that schedule.Interview Questions for the ExperiencedQ41. How many fields are present in a crontab file and what does each field specify?The crontab file has six fields.The first five fields contain information on when to execute the command and they are as follows;minute(0–59)hour(0–23)day(1–31)month(1–12)day of the week(0–6, Sunday = 0).The sixth field contains the command to be executed.Q42. What are the two files of the crontab command?The two files of crontab command are:cron.allowwhich decides the users need to be permitted for using the crontab command.cron.denywhich decides the users need to be prevented from using the crontab command.Q43. What command needs to be used to take the backup?The tar command is used to take the backup. It stands for tape archive. The command is mainly used to save and restore files to and from an archive medium like tape.Q44. What are the different commands available to check the disk usage?There are three different commands available to check the disk usage.df: It is used to check the free disk space.du: It is used to check the directory wise disk usage.dfspace: It is used to check the free disk space in terms of MB.Q45. What are the different communication commands available in the Shell?There are four different communication commands available in Shell.mailnewswallmotdThe total disk space used by Edureka can be found out as shown below.du –s/home/EdurekaQ46. Explain the basic architecture of ShellThe fundamental architecture on which the hypothetical Shell is based isn’t complex. The basic architecture is pretty similar to a pipeline, where input is analyzed and parsed, symbols are expanded. It uses a variety of methods such as brace, tilde, variable and parameter expansion and substitution, and filename generation. Then, commands are executed using shell built-in commands, or external commands.Q47. How to debug the problems encountered in the shell script/program?Given below are some common methods used to debug the problems in the script.Debug statements can be inserted in the shell script to output/display the information which helps to identify the problem.Using set -x we can enable debugging in the script.Q48. What is the difference between = and ==?= This is used for assigning value to the variable.== This is used for string comparison.Q49. How to open a read-only file in the Shell?A read-only file can be opened using the below command:vi –R <File Name>Q50. How can the contents of a file inside jar be read without extracting in a shell script?The contents of the file inside a jar can be read without extracting as shown below.tar –tvf <File Name>.tarQ51. Write a shell script to get current date, time, user name and current working directory.#!/bin/shecho ""Hello, $LOGNAME""echo ""Today's date is `date`""echo ""Username is `who i am`""echo ""Current directory is `pwd`""q51 — Shell Scripting Interview Questions — EdurekaQ52. How to find all the files modified in less than 3 days and save the record in a text file?find . -type f -mtime -3 -exec ls -l {} ; > last3days.txtQ53. Write a Shell Script that adds two numbers if provided as the command Line Argument and if the two numbers are not entered throws an Error Message.#!/bin/sh# The Shebangif [ $# -ne 2 ]# If two Inputs are not received from Standard Inputthen# then execute the below statementsecho ""Usage - $0 x y""# print on standard output, how-to use the script (Usage - ./1.sh x y )echo "" Where x and y are two nos for which I will print sum""# print on standard output, “Where x and y are two nos for which I will pri$exit 1# Leave shell in Error Stage and before the task was successfully carried o$fi# print on standard output, how-to use the script (Usage - ./1.sh x y )echo "" Where x and y are two nos for which I will print sum""# print on standard output, “Where x and y are two nos for which I will pri$exit 1# Leave shell in Error Stage and before the task was successfully carried o$fi# End of the if Statement.echo ""Sum of $1 and $2 is `expr $1 + $2`""# If the above condition was false and user Entered two numbers as a command$Case 1: When parameters are not passedq52.1 — Shell Scripting Interview Questions — EdurekaCase 2: When parameters are correctly passedq52.2 — Shell Scripting Interview Questions — EdurekaQ54. Print a given number, in reverse order using a Shell script such that the input is provided using the command Line Argument only.#!/bin/shif [ $# -ne 1 ]thenecho ""Usage: $0 number""echo "" Reverse of the given number will be printed""echo "" For eg. $0 0123, 3210 will be printed""exit 1fin=$1rev=0sd=0while [ $n -gt 0 ]dosd=`expr $n % 10`rev=`expr $rev * 10 + $sd`n=`expr $n / 10`doneCase 1: When parameters are not passedq54.1 — Shell Scripting Interview Questions — EdurekaCase 2: When the parameter is correctly passedq54.2 — Shell Scripting Interview Questions — EdurekaQ55. Calculate a real number calculation directly from the terminal and not any shell script.q55 — Shell Scripting Interview Questions — EdurekaQ56. How can you get the value of pi till 100 decimal places?q56 — Shell Scripting Interview Questions — EdurekaQ57. How will you find the total disk space used by a specific user?du -sh ~q57 — Shell Scripting Interview Questions — EdurekaQ58. How to check if a directory exists?#!/bin/shif [ -d $mydir ]thenecho ""Directory exists""fiq58 — Shell Scripting Interview Questions — EdurekaQ59. Can you write a script to portray how set –x works?#!/bin/sh#set -xi=1while [ $i -lt 6 ]doprint ""in loop iteration: $i""((i+=1))doneexitq59.1 — Shell Scripting Interview Questions — Edureka#!/bin/shset -xi=1while [ $i -lt 6 ]doprint ""in loop iteration: $i""((i+=1))doneexitq59.2 — Shell Scripting Interview Questions — EdurekaQ60. Suppose you execute a command using exec, what will be the status of your current process in the shell?All the forked processes which are new get overlays when the exec is executed. The command simply gets executed without making any impact on the current process. Also, no new process will be created in this scenario.If you wish to check out more articles on the market’s most trending technologies like Artificial Intelligence, DevOps, Ethical Hacking, then you can refer to Edureka’s official site.Do look out for other articles in this series which will explain the various other aspects of the Operating System.1. Linux Commands2. Top 75+ Unix Interview Questions And Answers3. Linux MintOriginally published at https://www.edureka.co.EdurekaRidiculousy Committed E-Learning PlatformFollow12 Operating SystemsShellShellscriptingShell ScriptInterview Questions12 claps12 clapsWritten byMohammad waseemFollowFollowEdurekaFollowThere are many e-learning platforms on the internet & then there’s us. We are not the biggest, but we are the fastest growing. We have the highest course completion rate in the industry. We provide live, instructor-led online programs in trending tech with 24x7 lifetime support.FollowWritten byMohammad waseemFollowEdurekaFollowThere are many e-learning platforms on the internet & then there’s us. We are not the biggest, but we are the fastest growing. We have the highest course completion rate in the industry. We provide live, instructor-led online programs in trending tech with 24x7 lifetime support.More From MediumAdding Composer into your Dockerfile with one lineJack LeiSQL query practics with examples -1Xue WangMonads Are Just Fancy SemicolonsMarcel Moosbrugger in Better ProgrammingBenchmarking Different Methods to Cool the Raspberry PiGaven MacDonald in Young CoderCentralized handling of errors in GraphQL and React NativeSrijan RanaDiameter of a Binary TreeShuo Wang in Python In Plain EnglishSuper-Slim Docker ContainersNassos Michas in Better ProgrammingStuart’s Apple pie recipeVictor Vargas in Stuart EngineeringLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
How to solve the serious crash of iOS 14 software?,https://medium.com/@sajjadhussain-11869/how-to-solve-the-serious-crash-of-ios-14-software-7dabac795ac7?source=tag_archive---------2-----------------------,"iOS,Apple,Operating Systems,Technology,Technical","Although iOS 14 has been updated to the third beta system, there are still many bugs. Recently, many users have reported that iOS 14 has caused very serious software crashes, especially when the weather is very hot, and APP crashes more frequently.In fact, application crashes are generally caused by two situations , one is that the application itself is unstable, and the other is that the iOS system is unstable. The latter is common after flashing, because flashing is prone to accidents, resulting in incomplete system, but there is another situation, that is, the system itself is unstable. This situation is common when the beta system is installed and the system is jailbroken.The current iOS 14 system is still a beta version, and many apps have not yet been adapted, so crashing is also a normal problem. The best solution at present is to install a stable version of the system or wait for the app manufacturer to adapt to iOS14.iOS 14 Programming Fundamentals with Swift: Swift, Xcode, and Cocoa BasicsiOS 14 Programming Fundamentals with Swift: Swift, Xcode, and Cocoa Basics [Neuburg, Matt] on Amazon.com. *FREE*…amzn.toIn addition, the issue of APP crash is not only a unique feature of iOS 14, but also other versions of iOS. If there is a crash, how should I alleviate it?1. Crash caused by application incompatibilityIf you are installing a stable version of the system, general APP crashes are caused by application bugs or application incompatibility. If there is a crash problem, you can try the following methods:Method 1: Clean the phone and restart the applicationStep 1: Swipe up on your home screen or double-tap the home button.Step 2: Swipe up to close all applications.Step 3: Go back to the main screen and click again to access the app.Method 2: Upgrade the crash applicationIt is very important to keep the application in the latest version, because developers will not only add new features to the updated version, but also fix software failures.Step 1: Open the App Store on your phone and select “Update”.Step 2: Click on the flashback application to install available updates.Step 3: Restart the application and check if the problem is resolved.Method 3: Reinstall the applicationOpen “Settings”-”General”, find “iPhone Storage”, click “Uninstall App”, wait for the uninstall to complete, and then click “Reinstall App”. (“Uninstall App” is not the same as “Delete App”. The uninstall button just deletes the App, but the documents and data in it are still retained, and the contents will not disappear.)Method 4: Uninstall the application completelyCrash caused by the systemIf the crash is caused by the system, it can usually be solved by flashing or system repair.Crazy Master Apple Repair Master Repair SystemStep 1: Open Crazy Master Apple Repair Master on your computer, then connect your device, select “Standard Mode” (retaining data repair system), and click “Next”.Step 2: Set your iPhone to enter DFU mode or recovery mode.Step 3 : Wait for the software to recognize your device, and then download the firmware package that matches your iPhone system.Step 4: Start the repair. Do not disconnect the device from the computer during the repair process to avoid bricking the device.iTunes restore iPhoneiTunes is a common method to repair Apple phone failures. Restoring iPhone through iTunes can repair most of the system problems of your Apple device. However, this method will erase all data on your device.Step 1: Open iTunes on your computer, and then connect your iPhone. If your iPhone pops up a window asking whether to trust, select “Trust” and then go to the next step.Step 2: Select the iPhone icon, then click “Summary”, select “Restore iPhone” and confirm.Step 3: Keep the device connected and wait for the restoration to complete.The above methods can alleviate the application crash problem. If the crash phenomenon is still not fixed after the Apple device is flashed, you can contact the Apple Service Center and ask for the help of a technician to check whether there is a problem with the hardware of the Apple device.Written bySajjad HussainDigital NomadFollowiOSAppleOperating SystemsTechnologyTechnicalMore from Sajjad HussainFollowDigital NomadMore From MediumBringing the Cosmos SDK to SwiftAlex Tran Qui in KatalysisAn Introduction to Property Wrappers in SwiftSergii Spivakov in Better ProgrammingHow To Build a Memory Card Game Using Classes and Protocols in SwiftXiomara Figueroa in Better ProgrammingProtocol in swiftKishore Premkumar in IVYMobility TechBytesNeumorphic Design in SwiftUIMohammad Azam in The StartupTurn Your Code Into PoetryFernando Moya de Rivas in Better ProgrammingApple unveils iOS 14, featuring widgets and several app upgradesCody DeBos in The StartupA guide to avoid CocoaPods installation failure while building Unity project for iOS.Shobhit SamariaAboutHelpLegalGet the Medium app"
Building Linux From Scratch on a Google Cloud Virtual Machine,https://medium.com/@michael.craig.fitzgerald/building-linux-from-scratch-on-a-google-cloud-virtual-machine-1a5e64683fb9?source=tag_archive---------3-----------------------,"Linux,Compilation,Linux From Scratch,Operating Systems,Tutorial","Links to Part 1, Part 3A barn raising in Canada. Source: WikipediaReferences are made to LFS Version 9.1-systemd using the format LFS x.x.x… for specific sections. Command blocks are largely copied verbatim with minor customizations for this setup.This part of the tutorial will comprise annotations for each build step for the temporary system in LFS 5.4–5.35 and some notes on system preparation for the final build.Increasing compute resources (Optional).Caution! Doing this could cost you money. Make yourself aware of the costs associated with using more compute resources. You can complete the LFS build without doing this.I am going to increase the compute power of my VM to 8 cpus and 32GB of memory so that we can take advantage of parallel compilation and speed up the overall build time. A list of machine types can be found here.LFS 4.5 warns that using parallel compilation could lead to failed builds and debug messages that are hard to interpret. We are going to try anyway and adjust as needed.#stop instancegcloud compute instances stop [INSTANCE-NAME] #change machine typegcloud compute instances set-machine-type [INSTANCE-NAME] --machine-type e2-standard-8#start instancegcloud compute instances start [INSTANCE-NAME]The output of nproc should be 8.Log in as the lfs user.#start login shellsu - lfs#if your prompt doesn't switch use the foreground commandfgBinutilsThis is the first pass build of binutils. We will time the compilation and installation to determine the SBU.cd $LFS/sourcestar -xf binutils-2.34.tar.xz && cd binutils-2.34mkdir -v build && cd build#wrap in time function to compute SBU#this will be the only time we doe this.time { ../configure --prefix=/tools     \             --with-sysroot=$LFS        \             --with-lib-path=/tools/lib \             --target=$LFS_TGT          \             --disable-nls              \             --disable-werror &&        \        make -j$(nproc) &&              \        case $(uname -m) in          x86_64) mkdir -v /tools/lib && ln -sv lib /tools/lib64 ;;        esac &&                         \        make install; }#end time blockcd $LFS/sources && rm -rf binutilsHere is the output of the time function:real 0m50.484suser 2m45.603ssys 0m28.736sThis suggests that our SBU is about 1 minute. We can use that to estimate build times for other packages. Again, this assumes you are using the same machine type with 8 processors.GCC (10 minute estimated build time)#step 1: tar -xf gcc && mv gcc-9.2.0 gcc & cd gcc#step 2: untar additional required packagestar -xf ../mpfr-4.0.2.tar.xz && \mv -v mpfr-4.0.2 mpfr && \tar -xf ../gmp-6.2.0.tar.xz && \mv -v gmp-6.2.0 gmp && \ tar -xf ../mpc-1.1.0.tar.gz && \mv -v mpc-1.1.0 mpc#step 2: change default dl location (verbatim LFS 5.5)for file in gcc/config/{linux,i386/linux{,64}}.hdo  cp -uv $file{,.orig}  sed -e 's@/lib\(64\)\?\(32\)\?/ld@/tools&@g' \      -e 's@/usr@/tools@g' $file.orig > $file  echo '#undef STANDARD_STARTFILE_PREFIX_1#undef STANDARD_STARTFILE_PREFIX_2#define STANDARD_STARTFILE_PREFIX_1 ""/tools/lib/""#define STANDARD_STARTFILE_PREFIX_2 """"' >> $file  touch $file.origdone#step 3: point to 64-bit libs (verbatim LFS 5.5)case $(uname -m) in  x86_64)    sed -e '/m64=/s/lib64/lib/' \        -i.orig gcc/config/i386/t-linux64 ;;esac#step 5: mkdir -v build && cd build#step 6:../configure                                       \    --target=$LFS_TGT                              \    --prefix=/tools                                \    --with-glibc-version=2.28                      \    --with-sysroot=$LFS                            \    --with-newlib                                  \    --without-headers                              \    --with-local-prefix=/tools                     \    --with-native-system-header-dir=/tools/include \    --disable-nls                                  \    --disable-shared                               \    --disable-multilib                             \    --disable-decimal-float                        \    --disable-threads                              \    --disable-libatomic                            \    --disable-libgomp                              \    --disable-libquadmath                          \    --disable-libssp                               \    --disable-libvtv                               \    --disable-libstdcxx                            \    --enable-languages=c,c++#step 7:make -j$(nproc)#step 8:make install#step 9: cleanupcd $LFS/sources && rm -rf gccActual build time: 5 minutesLinux API Headers (< 1 minute estimated build time)#step 1tar -xf linux-5.5.3.tar.xz && cd linux-5.5.3#step 2: clean the directorymake mrproper#step 3:make headers#step 4: copy headers to /tools/includecp -rv usr/include/* /tools/include#step 5: cleanupcd $LFS/sources && rm -rf linux-5.5.3Glibc (5 minute estimated build time)From here on I will omit the extraction step for conciseness.There is a specific warning that this build might fail with parallel make.mkdir -v build && cd build../configure                             \      --prefix=/tools                    \      --host=$LFS_TGT                    \      --build=$(../scripts/config.guess) \      --enable-kernel=3.2                \      --with-headers=/tools/includemake -j$(nproc)make installActual build time: 3 minutes.Parallel make did not seem to fail. LFS 5.7.1 recommends a sanity check at this point that tries to compile a dummy C program. Our build passed.Libstdc++ (< 1 minute estimated build time)This is included in the gcc source code, which needs to be extracted again.I will omit build directory creation, make, and install steps here forward.../libstdc++-v3/configure           \    --host=$LFS_TGT                 \    --prefix=/tools                 \    --disable-multilib              \    --disable-nls                   \    --disable-libstdcxx-threads     \    --disable-libstdcxx-pch         \    --with-gxx-include-dir=/tools/$LFS_TGT/include/c++/9.2.0Binutils Pass 2 (1 minute estimated build time)CC=$LFS_TGT-gcc                \AR=$LFS_TGT-ar                 \RANLIB=$LFS_TGT-ranlib         \../configure                   \    --prefix=/tools            \    --disable-nls              \    --disable-werror           \    --with-lib-path=/tools/lib \    --with-sysroot#after make and install, prepare the linkermake -C ld cleanmake -C ld LIB_PATH=/usr/lib:/libcp -v ld/ld-new /tools/binGCC Pass 2 (13 minute estimated build time)Caveat: make sure you are in the extracted gcc-9.20 source folder#create full version of internal headercat gcc/limitx.h gcc/glimits.h gcc/limity.h > \  `dirname $($LFS_TGT-gcc -print-libgcc-file-name)`/include-fixed/limits.h# point to appropriate linkerfor file in gcc/config/{linux,i386/linux{,64}}.hdo  cp -uv $file{,.orig}  sed -e 's@/lib\(64\)\?\(32\)\?/ld@/tools&@g' \      -e 's@/usr@/tools@g' $file.orig > $file  echo '#undef STANDARD_STARTFILE_PREFIX_1#undef STANDARD_STARTFILE_PREFIX_2#define STANDARD_STARTFILE_PREFIX_1 ""/tools/lib/""#define STANDARD_STARTFILE_PREFIX_2 """"' >> $file  touch $file.origdone#adjust for 64 bit systemcase $(uname -m) in  x86_64)    sed -e '/m64=/s/lib64/lib/' \        -i.orig gcc/config/i386/t-linux64  ;;esac#pull in required filestar -xf ../mpfr-4.0.2.tar.xz && \mv -v mpfr-4.0.2 mpfr && \tar -xf ../gmp-6.2.0.tar.xz && \mv -v gmp-6.2.0 gmp && \ tar -xf ../mpc-1.1.0.tar.gz && \mv -v mpc-1.1.0 mpc#fix known issuesed -e '1161 s|^|//|' \    -i libsanitizer/sanitizer_common/sanitizer_platform_limits_posix.cc#configure buildCC=$LFS_TGT-gcc                                    \CXX=$LFS_TGT-g++                                   \AR=$LFS_TGT-ar                                     \RANLIB=$LFS_TGT-ranlib                             \../configure                                       \    --prefix=/tools                                \    --with-local-prefix=/tools                     \    --with-native-system-header-dir=/tools/include \    --enable-languages=c,c++                       \    --disable-libstdcxx-pch                        \    --disable-multilib                             \    --disable-bootstrap                            \    --disable-libgomp#after make and install, symlink gcc to ccln -sv gcc /tools/bin/ccThe actual build and install time was approximately 5 minutes. The build passed the recommended sanity check described in LFS 5.10.Tcl (< 1 minute)cd unix./configure --prefix=/tools#after make and installchmod -v u+w /tools/lib/libtcl8.6.somake install-private-headersln -sv tclsh8.6 /tools/bin/tclshExpect (< 1 minute)cp -v configure{,.orig}sed 's:/usr/local/bin:/bin:' configure.orig > configure./configure --prefix=/tools       \            --with-tcl=/tools/lib \            --with-tclinclude=/tools/include# different installmake SCRIPTS="""" installDejaGNU (< 1 minute)./configure --prefix=/toolsM4 (< 1 minute)sed -i 's/IO_ftrylockfile/IO_EOF_SEEN/' lib/*.cecho ""#define _IO_IN_BACKUP 0x100"" >> lib/stdio-impl.h./configure --prefix=/toolsNcurses (< 1 minute)sed -i s/mawk// configure./configure --prefix=/tools \            --with-shared   \            --without-debug \            --without-ada   \            --enable-widec  \            --enable-overwrite#after make and install ln -s libncursesw.so /tools/lib/libncurses.soBash (< 1 minute)./configure --prefix=/tools --without-bash-malloc#after make and installln -sv bash /tools/bin/shBison (< 1 minute)./configure --prefix=/toolsBzip (< 1 minute)make -f Makefile-libbz2_somake clean#to installmake PREFIX=/tools installcp -v bzip2-shared /tools/bin/bzip2cp -av libbz2.so* /tools/libln -sv libbz2.so.1.0 /tools/lib/libbz2.soCoreutils (< 1 minute)./configure --prefix=/tools --enable-install-program=hostnameDiffutils (< 1 minute)./configure --prefix=/toolsFile (< 1 minute)./configure --prefix=/toolsFindutils (< 1 minute)./configure --prefix=/toolsGawk (< 1 minute)./configure --prefix=/toolsGettext (~ 2 minutes)./configure --disable-shared#to installcp -v gettext-tools/src/{msgfmt,msgmerge,xgettext} /tools/binGrep (< 1 minute)./configure --prefix=/toolsGzip (< 1 minute)./configure --prefix=/toolsMake (< 1 minute)./configure --prefix=/tools --without-guilePatch (< 1 minute)./configure --prefix=/toolsPerl (~ 2 minutes)sh Configure -des -Dprefix=/tools -Dlibs=-lm -Uloclibpth -Ulocincpth#to installcp -v perl cpan/podlators/scripts/pod2man /tools/binmkdir -pv /tools/lib/perl5/5.30.1cp -Rv lib/* /tools/lib/perl5/5.30.1Python (~ 2 minutes)Note: extract the (capital P) Python source archive.sed -i '/def add_multiarch_paths/a \        return' setup.py./configure --prefix=/tools --without-ensurepipSed (< 1 minute)./configure --prefix=/toolsTar (< 1 minute)./configure --prefix=/toolsTexinfo (< 1 minute)./configure --prefix=/toolsUtil-linux (~ 1 minute)./configure --prefix=/tools                \            --without-python               \            --disable-makeinstall-chown    \            --without-systemdsystemunitdir \            --without-ncurses              \            PKG_CONFIG=""""Xz (< 1 minute)./configure --prefix=/toolsFinal PreparationsWe will skip the optional stripping step since we have tons of space.Change the ownership of $LFS/tools to root.chown -R root:root $LFS/toolsThis concludes Part 2.Up next in Part 3: Building the LFS System (LFS 6.1–6.80).Written byMichael FitzgeraldFollowLinuxCompilationLinux From ScratchOperating SystemsTutorialMore from Michael FitzgeraldFollowMore From MediumEnhancing Gray-Scale Images Using Numpy, Open CVKavya Musty in The StartupBash History EnhancePaolo CozziWriting Code as A TeamBrian Jenney in The InnovationBlazing fast CI with GitHub Actions, Poetry, Black and PytestDaniel van FlymenHow To Use Python String-Literal ModifiersJonathan Hsu in Better ProgrammingPHP 7.x — P5: Truthy BoolsDino Cajic in Dev GeniusMy Journey as a Scholar in Google Africa Challenge Scholarship with Udacity and Andela tagged…Imo OkonInspecting HTTP requests in FlutterJakub Homlala in Flutter CommunityAboutHelpLegalGet the Medium app"
Memory mapping files and mmap module in python(with a lot of examples),https://medium.com/analytics-vidhya/memory-mapping-files-and-mmap-module-in-python-with-lot-of-examples-d1a9a45fe9a3?source=tag_archive---------4-----------------------,"Operating Systems,Python,Memory Management,Filesystem,Python3","Photo by Kote Puerto on UnsplashDefinition: A memory-mapped file object maps a normal file object into a memory. This allows us to modify a file object’s content directly in memory.memory mapped file objects behave both like bytearray and file objects . Hence all the operations which can be performed on a bytearray like indexing,slicing assigning a slice, or using re module to search through the file.And all the operations which can be performed on a file object like reading and writing data starting at current position. or using seek() to position the current pointer to different position.Memory-mapped file objectThe memory mapped file object is different for Unix and Windows based system. I will discuss about the Windows version.class mmap.mmap(fileno, length, tagname=None, access=ACCESS_DEFAULT[, offset])fileno: maps length bytes from the file specified by the file handle(file descriptor in Unix)fileno . And creates a mmap object.file.fileno(): returns file descriptor of the stream as numberA file handle(file descriptor in Unix) is a number that uniquely identifies an open file in a computer’s operating system. It describes a data resource, and how that resource may be accessed.If the length is larger than the current size of the file, the file is extended to contain the length of the bytes. And if the length is zero the maxlength of the map is current size of the file.To map anonymous memory, -1 should be passed as the fileno along with the length.tagname: If specified and not None , is a string giving a tagname for the mapping. If the parameter is omitted or None the mapping is created without any name.Understanding ACCESS_READ, ACCESS_WRITE, ACCESS_COPYACCESS_READ : read-only.ACCESS_WRITE : write-through, affects memory and both underlying fileACCESS_COPY : copy-on write memory, affects only memory and not underlying file.Examples:ACCESS_READ and ACCESS_WRITE and ACCESS_COPY.Now we know how mmap module functions now let's compare it with normal files.Assume that there is a binary file(in this case 20MB pdf file) larger than 15MB and we are processing the contents of this files like.From current position seeking 64 bytes and processing the data at this position.(in simple words we are moving 64 bytes from the start and placing the pointer at that position)From the current position seeking -32 bytes and processing the data at this position.(in simple words we are moving back 32 bytes and placing the pointer at that point)This process keeps on processing until a point is reached where the processed data is larger than 10MB.using memory maps is 13 times fast than normal files.Utility function to create a memory mapimport osimport mmapdef memory_map(filename,access = mmap.ACCESS_WRITE):    size = os.path.getsize(filename)    # the os.open() method returns a file descriptor for the newly opened file    file_descriptor = os.open(filename,os.O_RDWR)     return mmap.mmap(file_descriptor,size,access = access)Conclusion:Using the mmap to map files into memory can be an efficient and elegant means for randomly accessing the contents of a file.Instead of opening a file and performing various combinations of seek(), read() and write() calls we can simply map the file and access the file using the slicing operations.It should be noted that memory mapping a file does not cause the entire file to be read into the memory buffer. Instead, the operating system reserves a section of virtual memory for the contents of the file.(if the parts of the files are never accessed they stay on the disk).If more than one python interpreter memory maps the same file, the resulting mmap object can be used to exchange data between the interpreters.References:mmap - Memory-mapped file support - Python 3.8.5 documentationMemory-mapped file objects behave like both and like file objects . You can use mmap objects in most places where are…docs.python.orgmmap - Memory-map Files - PyMOTW 3Purpose: Memory-map files instead of reading the contents directly. Memory-mapping a file uses the operating system…pymotw.comMemory-Mapped (mmap) File Support in Python | Python CentralFrom Python's official documentation, be sure to checkout Python's mmap module: A memory-mapped file object behaves…www.pythoncentral.ioPython Cookbook, 3rd EditionIf you need help writing programs in Python 3, or want to update older Python 2 code, this book is just the ticket.www.oreilly.comAnalytics VidhyaAnalytics Vidhya is a community of Analytics and Data…FollowSign up for Data Science Blogathon: Win Lucrative Prizes!By Analytics VidhyaLaunching the Second Data Science Blogathon – An Unmissable Chance to Write and Win Prizesprizes worth INR 30,000+! Take a lookGet this newsletterBy signing up, you will create a Medium account if you don’t already have one. Review our Privacy Policy for more information about our privacy practices.Check your inboxMedium sent you an email at  to complete your subscription.Operating SystemsPythonMemory ManagementFilesystemPython3Written bySiddharth KshirsagarFollowData Scientist, Pythonista, Algorithms loverFollowAnalytics VidhyaFollowAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.comFollowWritten bySiddharth KshirsagarFollowData Scientist, Pythonista, Algorithms loverAnalytics VidhyaFollowAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.comMore From MediumEinstein Analytics Dataset Internal Storage Architecture and DesignGayatri SharmaR.I.P. data governance: Data enablement is the clear path forwardDan SutherlandMastering the mystical art of model deploymentJulien Simon in FAUNMining Consumer Sentiment the Right wayLoyalty Science Lab in The StartupWilly Wonka and the Data Driven Chocolate FactoryLisa Chen in The StartupLinear RegressionHamilton Chang in The StartupMay Be You Are Already a Data ScientistAbhishek AroraApache Airflow in 5 minutesAshish Kumar in The StartupLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
OS13k — An Unofficial Trophy And Music System for JS13k,https://medium.com/js13kgames/os13k-an-unofficial-trophy-and-music-system-for-js13k-d799bf0ba126?source=tag_archive---------5-----------------------,"Js13k,Music,JavaScript,Trophy,Operating Systems","Hello everyone, I am here to share a surprise we’ve cooked up for this years JS13k. As most of you know, all JS13k games share the same local storage, which can be problematic because every game needs a unique prefix to avoid name collisions. We’ve turned that bug into a feature: a shared trophy and music system that any JS13k game can opt into! If that isn’t enough, we’ve created an entire pseudo operating system to tie it all together.Welcome to OS13kHave you’ve heard of fantasy consoles like the Pico-8? Well, the best way to explain the vision behind OS13k is a fantasy OS and tiny game engine for creative coders. The OS is simple enough for anyone to use and has some powerful features for advanced users.ZzFX sound effects with support for sound seedsZzFXM music system, player, and visualizerTrophy system with popups and viewerCustom HTML, Dwitter, and Shadertoy programs with live editingGUI with window manger, taskbar, tray and settingsMobile/touch supportWe have been hard at work getting this ready for the past few months, and the full source code is now available on GitHub!One of the coolest features of OS13k is the ability to track trophies and music across all JS13k games and that’s what this post is about, so let’s get to it!TrophiesThere’s something really fun about building a collection of trophies across many games. It gives players a sense of progress and a reason to return later with only minimal overhead.The trophy system for OS13k mimics what you would expect to see on a modern game console though simplified. Each trophy has only 4 parts…Icon — One or more characters or emojisGame Name — Name of your JS13k gameTrophy Name — Name of the trophyMessage — Optional message for the trophyTo unlock a trophy in your JS13k game, simply add the following code, replaced with your trophy’s info…localStorage[‘OS13kTrophy,Icon,Game Name,Trophy Name’] = MessageWhen other JS13k games unlock trophies, OS13k will automatically detect new trophies, show a popup, reads the trophy name aloud, and add it to the user’s trophy case! It will also show a popup whenever the message for a trophy changes.This works by looking for local storage for keys that begin with OS13kTrophy. The rest key is then split at commas to get the trophy parameters. OS13k will even listen for local storage events to detect new trophies while running in the background.A few more things to be aware of…HTML tags and commas can’t be used in trophy stringsYou can track data with trophies for unlocks or high scoresDon’t abuse the system, lets limit it to 10 trophies per gameZzFXM MusicThe music system was developed by Keith Clark and myself. It is designed specifically for size limited productions like JS13k games. You can learn more and hear a demo on GitHub.Musical instruments are played using ZzFX sounds. I had originally developed ZzFX as a tiny sound effects tool, and used it for my 2nd place JS13k game last year. Since then I’ve added even more features, doubled the parameters, and improved the sound designer.Combining sound effects and music into the same system with songs that zip efficiently, makes it extremely useful for JS13k games. We are working on a native sequencer that should be ready soon, so look out for that.If you use ZzFXM for music in your game, there is a small optional step needed to register it with the user’s OS13k music library. Simply use the following code, replacing the parameters with your song…localStorage[‘OS13kMusic,Song Name’] = JSON.stringify(song)When the OS13k music player next loads, it will check local storage for any new music, verify if it is valid, and add it to the user’s library! Users can also manually add music by clicking the load button and pasting in the code.User ProgramsAdvanced users can extend OS13k by adding custom programs. The system automatically detects if it is HTML, Dweet, or Shadertoy code. Everything is saved in local storage for when the user returns and accessible via the menu.You can live edit user programs to experiment with creative coding, it’s a great sandbox to play around in for beginners or experts! All of OS13k’s features are available to user programs with some extra tools to help with live editing, debugging, and file management.JS13k and BeyondThe focus right now is on JS13k and this is all very experimental so it will be interesting to see how things turn out. After JS13k we will continue developing OS13k and adding more apps. I already snagged www.os13k.com, it just redirects to the GitHub for now though.Join UsI could not have done this alone! There were many people involved, listed on the GitHub page. Right now we are focused on making tiny games to fill out the JS13k build. If you are interested in helping out and joining our group JS13k entry, join the Discord server or send me a pull request. Either way we’re looking forward to earning some fun trophies and hearing your music.Thank you for reading, and good luck on all of your JS13k games! You can follow me on twitter for more tiny coding adventures.js13kGamesJs13kGames is a JavaScript coding competition for HTML5…Follow15 1 Js13kMusicJavaScriptTrophyOperating Systems15 claps15 claps1 responseWritten byFrankforceFollowFollowjs13kGamesFollowJs13kGames is a JavaScript coding competition for HTML5 Game Developers. The fun part of the compo is the file size limit set to 13 kilobytes. It runs between August 13th and September 13th, online since 2012.FollowWritten byFrankforceFollowjs13kGamesFollowJs13kGames is a JavaScript coding competition for HTML5 Game Developers. The fun part of the compo is the file size limit set to 13 kilobytes. It runs between August 13th and September 13th, online since 2012.More From MediumBuilding a Realtime Drawing App Using Socket.IO and p5.jsGabriel Tanner in Better ProgrammingGitHub Actions Markdown lint SetupChristina HastenrathHandling Asynchronous Actions with Redux ThunkRobin Kim in The StartupThis Is How Much JavaScript You Should Know before Learning a FrameworkPiero Borrelli in JavaScript In Plain EnglishThat Awesome Time Javascript Rescued UsMike Wolfe in The StartupMaze Generation With Depth-First Search and Recursive BacktrackingJake Mills in The StartupStatic Properties, Abstract Classes, and Constructor Functions in TypeScriptJohn Au-Yeung in Better ProgrammingNode.JS Under the HoodOussema Miled in The StartupLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Samsung And Microsoft Are Bridging Their Ecosystems For Better Interoperability,https://medium.com/0xmachina/samsung-and-microsoft-are-bridging-their-ecosystems-for-better-interoperability-b8e0835b293a?source=tag_archive---------6-----------------------,"Smartphones,Computers,Android,Operating Systems,Technology","In Big Tech, strategic partnerships can lead to new opportunities to open up markets and increase revenue. It can also bring together the best minds in the industry to develop cutting edge products. Two giants in tech, Samsung and Microsoft, have expanded their partnership in 2020. For consumers this can greatly improve integration of Samsung smartphones with Microsoft’s Windows operating system and associated devices.For Microsoft, this is another opportunity into the smartphone and mobile market. This was something they had missed with the Windows Phone’s market failure. This time around, Microsoft is providing integration for Samsung’s smartphone line up from the flagship Galaxy Note and their budget models. This partnership started in 2019 as a way to bridge the Android smartphone world closer to the Windows desktop. This brings more interconnectivity and interoperability between a smartphone and computer running the Windows operating system.In Big Tech when you marry productivity (Microsoft) with mobility (Samsung) you get greater flexibility in products. (Source Microsoft)What is strategic about this partnership is that they both have a product ecosystem used by millions of users on billions of devices around the world. Bridging them together allows even better support for consumers to use products that they are already familiar with rather than purchase another brand. If you have a Samsung Galaxy Note 20 and Windows 10 running on your laptop, interoperability allows consumers to do more things with their devices. Apple already has an existing ecosystem that allows the iPhone to connect with the Mac computer line. However, the iOS and macOS do not seamlessly interconnect. You cannot run a native iOS app on a Mac running macOS (as of summer 2020). They require the correct version of the app. This is an issue that Apple is addressing with the new Apple Silicon architecture.The Android operating system on Samsung’s smartphones was actually developed by Google. This integration can also benefit Android phone users regardless of brand (e.g. LG, Huawei). A greater reach to most Android phone users with the ability to connect to a Windows computer can bring more demand for Microsoft products like the Surface as well as benefit computer vendors like Dell and HP who use the Windows operating system. Vendors who make ultrabooks and premium laptops that run Windows can also develop apps for this type of integration. Samsung may not see it that way though since this partnership could also be another way to move away from reliance on Google.Good News For GamersOne ecosystem Samsung integrates with is Microsoft’s Xbox gaming console.According to the Microsoft blog:“With Xbox Game Pass on your Samsung Galaxy, your Xbox games are always in your pocket.”Microsoft’s Game Pass for Samsung smartphone users.Not only that, there is the potential for Samsung users to access Microsoft’s xCloud gaming platform for playing games directly on their smartphone. This is anywhere and anytime access for gamers.Systems IntegrationMicrosoft allows Windows users to access their smartphone’s Android apps. This integration aims to make it easier with the Window’s Your Phone app and Link to Windows. This allows direct interaction with mobile apps on the Samsung smartphone to run in a Windows environment wirelessly using Wi-Fi. A type of mirroring of the smartphone opens up in Your Phone and launches in a separate window.The Link to Windows app on Samsung smartphones connect to a Windows PC. (Source Microsoft)These features bring convenience to users who have to work between different devices. Most people work on their desktop PC every day, so the convenience of having smartphone integration makes it easier to transfer information like photos, documents and notes from one device to another.Easier way to work between devices. (Source Microsoft)Productivity And MobilityMicrosoft is best known for their productivity products like Office 365. Bringing this to the mobile world on smartphones allows users to work with Microsoft products on the go. This is already possible with Android smartphones running a version of Microsoft’s apps. With more integration, users can also switch between their smartphone and desktop or other devices. The next version of these products will allow synching up with Samsung apps as well.Microsoft is extending the apps with support from Samsung devices like the Galaxy Watch. With support for Office 365 and other productivity products, Samsung users will have access to important information on their Outlook e-mail, OneDrive storage, Word documents and Excel spreadsheets.The Answer To Apple And GoogleThe Samsung and Microsoft partnership is the answer to counter the influence of Apple and Google. They now have their respective ecosystems, but integration appears to be the motivation driving product development. Samsung, although it uses Google’s Android operating system, is moving in a direction away from too much reliance on the tech giant. Samsung has developed its own operating system Tizen, which for now is not the main OS used on their smartphones but the plan can be to replace Android when the time comes.Samsung also has developed Bixby, their own virtual assistant app alongside Android’s Google Assistant. If Samsung were intent on staying with Android, why would they even bother to develop their own? Samsung bought the company of the original Siri developers to build Bixby. With their own OS and virtual assistant, Samsung can replace Android as the features improve. Samsung can then become more exclusive with Microsoft when developing products which don’t need to benefit Android.With different ecosystems, consumers will have more choices. For Samsung, that means an expansion into the business and home computing market. Businesses that use Windows in the office may want to lock in contracts with telecom providers to purchase Samsung’s smartphones for their enterprise. Home users will also consider Samsung smartphones with their existing Windows setup because of simpler integration. Perhaps this may not entice consumers who are already locked into Apple or Google’s ecosystem due to brand loyalty or because these users have been using those products for a long time. It is the market of users who are not currently locked into an ecosystem who the tech giants will compete for.0xMachinaEssays and articles about interacting with modern devices…Follow14 SmartphonesComputersAndroidOperating SystemsTechnology14 claps14 clapsWritten byVince TaboraFollowElectrical Engineering, Data Science, Photography, Blockchain, AI, Cybersecurity, Multimedia, EV and Autonomous VehiclesFollow0xMachinaFollowEssays and articles about interacting with modern devices and how they work.FollowWritten byVince TaboraFollowElectrical Engineering, Data Science, Photography, Blockchain, AI, Cybersecurity, Multimedia, EV and Autonomous Vehicles0xMachinaFollowEssays and articles about interacting with modern devices and how they work.More From MediumHoloLens 2 Hands-OnAlice Bonasio in Microsoft DesignHow the virus is even changing how we gain entry to the officeBojan Stojkovski in An Idea (by Ingenious Piece)Razer THX Spatial Audio Software ReviewAlex Rowe in The StartupGoogle Introduces AR Search and Here’s What You Should ExpectAugmania in The StartupExposing the Bias Embedded in TechThe New York Times in The New York Times50 Years Later, the Internet’s Inventors Are Horrified by What It’s BecomeFast Company in Fast CompanyCould the next winner of Fortnite be a pensioner?Enrique Dans in Enrique DansKFC to 3D Print Chicken Using Lab-Grown ‘Meat of the Future’PCMag in PC MagazineLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Operating System — Process Management,https://levelup.gitconnected.com/operating-system-process-management-26c73901166?source=tag_archive---------7-----------------------,"Operating Systems,Process,Process Management,Computer Science,Software Development","Photo by Michael Dziedzic on UnsplashProcess management in operating system is an important concept as we generate hundreds and thousands of processes when we execute different programs in a day. In order to make it easier for you to understand process management, I’m gonna break it down to three levels, from easiest to hardest:Basic (Process, PCB, Process Lifecycle)Intermediate (Process in user space)Advanced (Process in kernel space)Level 1 — Essential Concepts You Must KnowWhat’s a process?A process is a program in execution. It contains every information of that running program:Current program counterAccumulated running timeList of files that are currently opened by that programPage tableWhat’s Process Control Block(PCB)?Every process is represented by a data structure called Process Control Block(PCB). A PCB keeps all the important information of a process.Process Control BlockPointer: A pointer to the parent process.Process ID: Unique ID number representing a process.Process State: The state any process currently is in (Ready, Wait, Exit, etc).Process Priority: Numeric value which states how urgent a process is. Process with the highest priority will be allocated to the CPU first.Program Counter: Address of the next instruction in line of the processes.Accounting Information: The amount of CPU used, time limits, job or process numbers, etc.CPU Registers: Accumulators, index registers, general-purpose registers, etc.I/O Information: An array of open files and I/O devices allocated to the process.What’s Process Lifecycle?There is a lifecycle of every process. The states of a process are Start, Ready, Running, Waiting and Terminated.Process LifecycleStart: The birth of a process.Except the first process “init”, every process is created using fork().Ready: The process is ready.It means it’s ready to run but is not running. A process may become “ready”(runnable) after:It is just created by fork()It has been running on the CPU for some time and the OS chooses another process to run (scheduled context switch)Returning from blocked statesRunning: The process is running.The OS chooses this process to be running on the CPU and changes its state to “Running”.Waiting/Blocking: The process is blocked.While the process is running, it may wait for something (e.g. getc(), wait()). There are 2 types of wait, interruptible and un-interruptible.Interruptible wait: Sometimes, a process has to wait for the response from a device and, therefore, it is blocked. This blocking state is interruptible. It means pressing “Ctrl + C” can get the process out of the waiting state.Un-Interruptible wait: Sometimes, a process needs to wait for a resource until it really gets the response. It’s in an Un-interruptible status. It means it won’t be “Ctrl + C” interruptible.Terminated: The process is going to die.The process may choose to terminate itself or force to be terminated.Level 2 — Intermediate Knowledge (User Space)After having the basic concepts, we’re gonna go deeper to know more about the system calls of process but focusing on user space (from programmer view).How to identify processes?How to create a new process?How can we identify processes from one to another?Each process is given a unique ID number, and is called the process ID(PID). The system call, getpid(), prints the PID of the calling process.Example of getpid():#include <stdio.h> // printf()#include <unistd.h> // getpid()int main(void) {  printf(“My PID is %d\n”, getpid() );  return 0;}How can we create a new process?To create a process, we use the system call fork().Example of fork():int main(void) {  printf(“Parent (PID = %d)\n”, getpid());  fork();  printf(“My PID is %d\n”, getpid() );  return 0;}Output:Parent (PID = 1234) <- parent processMy PID is 1234 <- parent processMy PID is 1235 <- child processIn the above example, we can observe that:Both the parent process and the child process execute the same programChild process starts its execution at the location that fork() is returned, not from the beginning of the programThe system call fork() is like “cell division”. It creates the child process by cloning from the parent process, including all user-space data.If a process can only duplicate itself and always runs the same program, it’s not quite meaningful. So, here comes another question — how can we execute other programs?Let’s meet the exec*() system call family!How can we execute a program?exec*() is a system call family and the family has 6 members (execl, execv, execlp, execvp, execle, execve).Let’s take execl() as an example:execl(“/bin/ls”, “/bin/ls”, NULL);We would like to run the command “/bin/ls” in this case.1st argument “/bin/ls”: The file that we want to execute2nd argument “/bin/ls”: When the process switches to “/bin/ls”,this string is the program argument[0]3rd argument “NULL”: This states the end of the program argument listHere is another example of execl():execl(""/bin/ls"", ""/bin/ls"", ""-l"", NULL);In this case, we have 4 arguments:1st argument “/bin/ls”: The file that we want to execute2nd argument “/bin/ls”: When the process switches to “/bin/ls”,this string is the program argument[0]3rd argument “- l”: When the process switches to “/bin/ls”,this string is the program argument[1]4th argument “NULL”: This states the end of the program argument listSo, this is an example of how to use execl() in a C-program:int main(void) {  printf(“before execl\n”);  execl(“/bin/ls”, “/bin/ls”, NULL);  printf(“after execl\n”);  return 0;}However, “after execl” is not printed if you run this program. It means the lines of code “after execl()” is not reached. The parent process is terminated.Bear this in mind: The exec system call family is not simply a function that calls a command. The “return” or the “exit()” statement in “/bin/ls” will terminate the process. Therefore, it is certain that the process cannot go back to the original program!Question: How can we make a meaningful process creation? Answer: fork() + exec*() + wait() = system()Example of creating a meaningful process:int exec(const char *cmd) {  if(cmd == -1)    return -1;  // if fork() returns 0, this is a child process    if(fork() == 0) {     execl(""/bin/sh"", ""/bin/sh"", ""-c"", cmd_str, NULL);    fprintf(stderr, ""%s: command not found\n"", cmd_str);    exit(-1);  }  wait(NULL);  return 0;}// mainint main(void) {  printf(""before exec\n\n"");  exec(""/bin/ls"");  printf(""after exec\n"");  return 0;}The key to suspend the execution of the parent process and to wake the parent up after the child is terminated is using wait().How wait() can suspend the parent processwait() is used to suspend the calling process to waiting state and return (wakes up) when one of its child processes is terminated or receive a signal.Now, you know that:A new process is created by system()A process is a program being brought by exec*() to the memoryC library call, system(), is implemented by fork(), exec*(), andwait()Level 3 — Advanced Knowledge (Kernel Space)So far, we’ve only covered the process in user space. This is how the full picture looks like before moving on to the kernel space:What happened when we invoke system calls?As the code is in user-space memory, the program counter is pointing to the user-space memory.When the process called the system call(e.g. getpid()), the CPU switches from the user-space to the kernel-space, and reads the PID of the process from the kernel.When the CPU has finished executing the system call, it switches back to the user-space memory, and continues running that program code.Therefore, a CPU is always switching between user-space and kernel-space. We can check the time spent on user-space and kernel-space when executing a program.User time: CPU time spent on codes in user-space memorySys time: CPU time spent on codes in kernel-space memoryIn Linux, there’s a command called time to check the user time and sys time. To know more, check this out:time(1) - Linux manual pageThe time command runs the specified program command with the given arguments. When command finishes, time writes a…man7.orgHow fork() works?When a process calls fork(), there’s a processing time as the kernel needs to do something. Let’s find out what the kernel is doing exactly.Inside kernel space, processes are arranged as a doubly linked list, called the Task List.This is how fork() updates the memory in both user-space and kernel-space:Parent process 1234 calls fork()PCB is being copied in the kernel space and code in user-space memory is also being copiedIn kernel space, some details of copied PCB is updatedAfter calling fork(), both the parent process and the child process will be returned from fork(). At last, a return value will be added in the PCB. The return value of parent process will be the PID of its child process and the return value of child process will be 0.How exec*() works?When a process calls exec(), the memory in user-space will be changed:Local variables & dynamically allocated memory are clearedGlobal variables are reset based on new codeCode & constants are changed to the new codeOf course, the kernel will also reset the register values (e.g., program counter) in PCB.How wait() and exit() work?exit()I want to talk about exit() first as calling exit() without calling wait() will cause a serious problem, zombie process. You will understand it very soon.This is how exit() frees the memory in both user-space and kernel-space:Child process 1235 calls exit()All allocated memory in kernel space is freed. The list of opened files are all closed. (so it’s okay to skip fclose() but it’s not recommended)All allocated memory in user space is freed. (including program codeand allocated memory)The kernel notifies the parent of the child process about the terminationof its child. The kernel sends a SIGCHLD signal to the parent.As the parent process 1234 didn’t call wait(), it will ignore the SIGCHLD signal. Therefore, process ID 1235 is still in the kernel’s task list. The status of the child process is now called zombie process.wait()By default, every process does not respond to the SIGCHLD signal. The parent ignores his child unless it’s really waiting for the child process.If a process has called wait(), the kernel will register a signal handlingroutine for that process.When the kernel sends SIGCHLD to the parent process, the corresponding signal handling routine will be invoked.This is what the default handler is gonna do:Accept and remove the SIGCHLD signal;Destroy the child process(remove it from process table, task-list, etc.)After removing the child process, the kernel deregisters the signal handling routine for the parent process and returns the PID of the terminated child.Therefore, calling wait() is very important!!! The main reason is system resource management. A zombie process takes up a PID but the total number of PIDs are limited (32,768). So, always remember to invoke wait() in the parent process first.If you’re reading this line, congratulations!!! You made it. It’s not easy to read from level 1 to level 3. I believe you have a very concrete understanding on process management now.To know more about my backend learning path, check out my journey here:My Backend Developer Learning Journey 我的後端學習之旅It’s been over one year after graduation. With more than 2 years of work experience in both frontend and backend…medium.comLevel Up CodingCoding tutorials and news.Follow59 Operating SystemsProcessProcess ManagementComputer ScienceSoftware Development59 claps59 clapsWritten byMatthew WongFollowBackend Developer@HK | https://mattwong.info/FollowLevel Up CodingFollowCoding tutorials and news. The developer homepage gitconnected.comFollowWritten byMatthew WongFollowBackend Developer@HK | https://mattwong.info/Level Up CodingFollowCoding tutorials and news. The developer homepage gitconnected.comMore From Medium3 CQRS Architectures that Every Software Architect Should KnowDaniel Rusnok in Level Up CodingEverything I Automated In 2020 To Save Me Hours Of Timekeypressingmonkey in Level Up CodingTop lessons learned from working with a 10x developerJeffrey Bakker in Level Up CodingLayers in Software Architecture that Every Sofware Architect should KnowDaniel Rusnok in Level Up CodingHow I Used Python and Selenium To Get a Lifetime Supply of Garlic Pizza SticksSanjeet Chatterjee in Level Up Coding15 Hilarious Jokes by the Programmers for the ProgrammersLokajit Tikayatray in Level Up Coding3 Domain-Centric Architectures Every Software Developer Should KnowDaniel Rusnok in Level Up CodingCode Review — The Awakeningilan pinto in Level Up CodingLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Running a powerless file to perform a powerful task,https://medium.com/acmucsd/running-a-powerless-file-to-perform-a-powerful-task-a819cb95c8bf?source=tag_archive---------8-----------------------,"Cyber,Operating Systems,Privilege Escalation,Gitignore,Shellcode","How I defeated UIUCTF 2020’s brand new pwnyOS via an uninitialized memory bug, and by executing the most innocent file on the system.pwnyOS’s login screenThis year, UIUC’s SigPwny team released their CTF (UIUCTF) with a brand new series of challenges: Kernel Exploitation. A great deal of effort (thanks to Ravi) was put into developing a brand new operating system just for these challenges — pwnyOS! I was thrilled about such challenges when the CTF just started, when I can’t wait for them to deploy their virtual machines.I will not go over how to log into the system and get from a sandbox user (the user you can log into as) to a regular user, but instead focusing on how to elevate from a regular user to the superuser, or the administrator of the system.An example session containing rash and binexec running a piece of shellcode that elevates privilege from sandbox to userDespite pwnyOS’s fancy outlook, after logging in I realized that it is basically a command line interface wrapped in a translucent “Terminal” window. Everything can be done via a keyboard, and only a keyboard. Indeed, the system is not responsive to any mouse inputs at all. In addition, most exploitations are not even done by running commands in the shell (rash, which is a much more restricted shell compared to bash), they are instead done by typing shellcodes into binexec, a program that executes raw 32 bit Intel x86 instructions in a hexadecimal string.The ChallengeKernel::Run_it_as_Root (3 solves, 666 points)There’s a bug with uninitialized memory in the kernel page allocator. Can you find a way to exploit this bug with your new user-level permissions to execute rash as root (UID 0)?Prerequisite: this challenge requires a UID of 1 to complete, so you need to solve crazy_caches first.Author: raviThe first step to every Kernel Exploitation challenge is to read the pwnyOS documentation. Quoting from the Getting Started Guide:Our intention is that everything you need to complete these challenges is provided to you- no guessing is involved.This challenge is not an exception. Despite being worth 666 points, careful reading of the documentation and some basic understanding of x86 assembly is all we need to defeat the challenge. With that said, let’s see what we can do with our newly gained user privilege from Crazy_Caches (the previous challenge):System calls available to user but not for sandb0x (with syscall numbers):10 SWITCH_USER11 GET_USER12 REMOTE_SETUSER13 MMAPThe first 3 syscalls are related to user management, but they are not enough to elevate us to root. They either require the correct root password (SWITCH_USER or su command) or require existing root privileges (REMOTE_SETUSER) in some process on the system. Unlike the previous Crazy_Caches challenge, there are no existing processes running as root (UID=0).Discovering a memory allocation bugThis left us with MMAP, which requests a 4MB page from the kernel memory allocator, but careful reading of the documentation reveals another reference to this same page allocator in the EXEC system call:Start a new process- this call won’t exit until the called process calls SYSRET! This syscall returns the exit code the called process sent to SYSRET. Arguments are specified by a space-separated list after the filename. This uses the kernel 4MB page allocator to request a new page for the process.Since the challenge asks us to find a bug in the kernel memory allocator, MMAP and EXEC are going to be the key of our exploit. But before we move on, let's talk about how pwnyOS executable binaries are loaded into memory. Like other operating systems, executables are first loaded from disk into memory before it is executed. Since the kernel needs to make sure the memory of one program does not overlap with that of another program (otherwise privileged processes will leak sensitive data to or be controlled by other processes), it has to request a currently unused memory page for the new process. That is the job of the 4MB page allocator. However, the fact that the page is unused does not mean that it is always filled with zeros, the kernel does not clean up after its processes by zero-filling their page. Again, quoting from the EXEC system call documentation:This page may contain program data from previous programs, or from other places the kernel uses the allocator. The new program is read into memory, overwriting the old data. However, if an old program was larger than the new one, remnants of its memory may still be present in the page! (You can’t assume all memory is initialized to 0). Returns -1 on failure (cannot execute program).I bolded the part that documents the uninitialized memory bug we need to exploit, and I will illustrate it with an example using only ASCII characters and human readable instructions:Let’s say when program A just exited, its memory looks like this:IMPORT 8 TONS OF WHEAT, OUR SOLDIERS ARE STARVING.When program A exits via SYSRET, it returns its memory page back to the kernel so that it can reuse the page for other purposes. Immediately afterward, program B is launched using an EXEC syscall, and the content of program B is only 2 bytes long:EXWhen the kernel loads program B’s contents into memory, it reuses the freed page from program A and overwrites the first 2 bytes (IM) with EX. However, since the kernel doesn't initialize the rest of the 4MB memory space, leaving part of program A's memory in program B's:EXPORT 8 TONS OF WHEAT, OUR SOLDIERS ARE STARVING.Due to the nature of ELF format of pwnyOS, if program B is a correctly behaving program (Ex. /bin/rash or /bin/binexec), it would be executed just fine regardless of the contents of program A. But as evident in the line above, loading a seemingly innocent yet malicious program B completely changes the meaning of the sentence: it changes ""import"" to ""export"", which changed the meaning of the whole sentence. The same thing can happen with machine-readable programs, as I will demonstrate in the section below.Finding Program A and B on pwnyOSNow comes the difficult part: how can we find the pair of programs in pwnyOS that allows us to run a program as root? Looking at page 7 of the Getting Started Guide for pwnyOS titled “pwnyOS Executables”, I discovered that pwnyOS uses the same executable format as Linux and some other Unix systems (ELF), but it extends the ELF header to allow privileged binaries similar to the setuid bit for Linux executables. While standard ELF files (those found in Linux) starts with these 4 bytes in hex: 7F 45 4C 46, the first byte of a pwnyOS binary can be something other than 0x7F: it can be 0x80 + uid where uid specifies the user id of the user it should always be run at (regardless of the current permission of the user running the program, like setuid binaries). For example, a program starting with 82 45 4C 46 would be run as the sandb0x user, whose UID is 2. Therefore, a binary starting with 80 45 4C 46 would always be ran as root whose UID is 0.Now back to our first question about finding a pair of programs that allows us to escalate to the superuser. Ideally, we would want program A (The old program) to be rash, binexec, or any program we have control over and program B (The new program) to be a file that starts with a single byte: 0x80. Sadly, I will tell you that there is no such program B, and due to the read-only nature of its filesystem, we cannot even create it, but not all hope is lost. There is indeed an indirect way of achieving basically the same task!The modified program B: MMAP and an empty fileAgain, quoting from the EXEC syscall documentation:This page may contain program data from previous programs, or from other places the kernel uses the allocator.Since MMAP shares the same 4MB page allocator as EXEC, this means that a program can view and edit the previously freed page of some exited process by performing the MMAP syscall. This allows us to simulate the effect of loading program B by changing the first byte of a page obtained from MMAP (after running program A) to 0x80, exiting, and then instructing the kernel to execute the content of the MMAP'd page.While the first 2 steps are trivial to perform in binexec, the last step — instructing the kernel to launch a new process that executes the MMAP page — is more difficult: it requires executing an empty file. When the kernel executes an empty file, nothing is written into the uninitialized page so the kernel will execute whatever was left in the page before.Luckily, the solution lies in a file that is commonly overlooked. By running ls inside user's home directory /user/, I discovered a strangely useless file: .gitignore. By running cat .gitignore, I almost expect some secrets to be inside there that would help me get to root. But instead, I get an empty file.Indeed, the pwnyOS team tried hard to obfuscate the importance of its files. A non-suspecting user might think that .gitignore may just be a file the pwnyOS team unintentionally introduced into the system (Like .DS_Store in zip archives made in macOS). But looking into pwnyOS's documentation, it says:All files in pwnyOS have a purpose- if you see a file, it is there for a reason.And yes, /user/.gitignore is not an exception.Running the exploitTo start, we need a newly started instance of binexec prompt running as user (Regular User privilege).Then we need to write some shellcode:.arch x86 ; pwnyOS is a 32-bit OS running on Intel x86 architecture.bits 32mov eax, 13int 0x80 ; MMAPmov byte [eax], 0x80retLet’s dissect this shellcode line by line:mov eax, 13: this sets eax to 13, the syscall number for MMAP.int 0x80: As the self-explanatory comment ; MMAP suggests, it performs the actual system call MMAP by triggering interrupt number 0x80 in the CPU. This interrupt is handled by the pwnyOS kernel where the memory manager resides. Unlike user mode processes, the kernel and the memory manager can interact directly with hardware and write to any possible physical memory location, including the table that specifies the mapping between virtual address (the addresses user mode process sees) and the physical address (the actual location inside the hardware RAM module). MMAP maps some currently unused physical address to virtual address 0x0D048000 which is returned to the caller by setting eax to this value.mov byte [eax], 0x80: Sets the first byte of the page obtained from MMAP to 0x80. Before this line the page should contain a normal ELF header (7F 45 4C 46). After this line the header will be 80 45 4C 46, which will make the kernel run the code afterwards as root.ret: end the shellcode and return back to binexecI saved the file as exploit.rasm and assembled it with rasm2, an assembler from Radare2 that outputs hex.rasm2 -f exploit.rasmThis outputs the following shellcode in hex (space added for clarity):b8 0d 00 00 00 cd 80 c6 00 80 c3I typed the piece of hex shellcode into binexec and exited the program to return the MMAP'd page to the kernel.At this point, we have already planted the exploit and it is just waiting to be triggered when the kernel executes the page. However, the page we just returned may not be the only free page in the pwnyOS memory allocator. There are many programs that have exited before at this point, including the binexec loop in the sandbox and the binexec used to gain user privilege and solve Crazy_Caches. To reduce the number of such pages, I rebooted the system and performed only necessary exploits to get to user before doing all the previous steps so that I can more easily get to the exploit page.The next step involves repeatedly running /user/.gitignore until we reach the malicious page, where we will see user on the top left corner of the screen change to root indicating that the current process runs at root. In rash, I simply ran the command /user/.gitignore or run /user/.gitignore. But afterwards, I was dropped into a binexec session instead (since there are previously exited binexec processes). In this case, I ran this shellcode to execute /user/.gitignore:b801000000bbade00408cd80c32f757365722f2e67697469676e6f726500Source for the shellcode (with comments):.arch x86.bits 32.org 0x0804e0a0 ; The address binexec will run the code. This line sets the address for the first instruction so that labels work correctlymov eax, 1 ; syscall number for EXECmov ebx, gitignore ; the first argument to EXEC(char *filename_to_exec)int 0x80 ; EXEC(gitignore)retgitignore:.string ""/user/.gitignore""So after several rounds of running /user/.gitignore in rash and that shellcode in binexec, I finally reached root. After getting to root, my machine looks like this:In this case, I become root inside binexec rather than rash, so I have to run rash inside binexec, but this is trivial: just change the filename after .string in the previous shellcode to ""/bin/rash"" instead of ""/user/.gitignore"" and compile the shellcode again:b801000000bbade00408cd80c32f62696e2f7261736800And voilà! I get a root shell, which allows me to get the flag for this challenge: uiuctf{th1s_h4s_b33n_a_l0t_0f_fun_and_i_h0p3_y0u_enjoy3d_it!}Meddling around in the root shellThe pwnyOS’s author (ravi) decided to put a lot of interesting files inside /prot/ that is visible only by root:/prot/passwd: Contains the passwords (in plaintext!) for every user on this system (root, user, and sandb0x) I won't post them here so that it won't spoil the fun for people wanting to try this. Having the root password allows bypassing the steps above and go straight from user to root via su or SWITCH_USER syscall (though the initial login screen only allows logging into sandb0x and no other users)/prot/crazy_caches: Contains the binary for the Crazy_Caches challenge/prot/intros/: Contains the binaries for intro level challenges/prot/images/: Folder with the desktop background image in various resolutionsResourcesI wrote a script in Windows PowerShell to automate the task of typing long shellcodes into binexec using the keyboard. I also made a script to automatically gain root privileges from the login screen by performing exploits step-by-step. They are stored in scripts/.Final ThoughtsUninitialized memory is a seemingly innocent bug that can lead to dangerous security vulnerabilities. It is especially common in system programming languages such as C/C++ and assembly, all of which are commonly used in writing kernel code. Relying on uninitialized memory has led to the Debian/OpenSSL Fiasco which has silently generated several insecure OpenSSL keys that may still be present in critical systems today. The moral of this privilege escalation exploit? Initialize memory (Ex. zeroing it) immediately after allocating it. Don’t rely on untrusted users or programs to do it for you.ResourcesI wrote a script in Windows PowerShell to automate the task of typing long shellcodes into binexec using the keyboard. I also made a script to automatically gain root privileges from the login screen by performing exploits step-by-step. They are stored in scripts/.Final ThoughtsUninitialized memory is a seemingly innocent bug that can lead to dangerous security vulnerabilities. It is especially common in system programming languages such as C/C++ and assembly, all of which are commonly used in writing kernel code. Relying on uninitialized memory has led to the Debian/OpenSSL Fiasco which has silently generated several insecure OpenSSL keys that may still be present in critical systems today. The moral of this privilege escalation exploit? Initialize memory (Ex. zeroing it) immediately after allocating it. Don’t rely on untrusted users or programs to do it for you.ACM UCSDACM UCSDFollow67 CyberOperating SystemsPrivilege EscalationGitignoreShellcode67 claps67 clapsWritten byKevin HeFollowFollowACM UCSDFollowThoughts, shoutouts, and thinkshare from your fellow ACM membersFollowWritten byKevin HeFollowACM UCSDFollowThoughts, shoutouts, and thinkshare from your fellow ACM membersMore From MediumI Wrote a Script to WhatsApp My Parents Every Morning in Just 20 Lines of Python CodeKartik Nighania in Better ProgrammingWrite Your Own OS(3) — Bare Bone OSMeg's tech cornerA List of Useful Shell Commands for Linux BeginnerstheUnknown in The StartupCoding & Writing: They’re not so differentDanielle Jasper in The StartupDeploying a Python serverless function in minutes with GCPLaurent Picard in Google Cloud - CommunityResources I Used While Learning to CodeJenni MacklinPython Package for working on Huge Amounts of Numerical Data in PythonRavi in Python In Plain EnglishLearn Programming with Python — Introduction to FunctionsRichard Quinn in The StartupLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
Run a Virtual Machine on your Mac for free,https://medium.com/macoclock/how-to-setup-an-open-source-vm-f973d283d6ac?source=tag_archive---------9-----------------------,"Tutorial,Virtualization,Operating Systems,Microsoft,Macos","Photo by Kelli McClintock on UnsplashWhat actually is a VM?A VM is a virtual machine that runs inside a contained environment, using software to emulate a physical computer, letting you install an operating system and use it just like a regular computer.So you may be saying to yourself, why would I want to do this? Well the answer to that is that there is a number of reasons as to why you may want to use a VM.Software development and testingRunning applications that do not run on your native OSTrying out different operating systemsTesting settings to see the effects, without hurting your physical machineand moreI use a VM for all of the above, and to be honest I don’t know how I lived without one!So I thought I would show you how to setup a VM on your own computer for free using Virtual Box from Oracle.First we need to download Virtual Box from Oracle’s website, click the link below to grab the installer…Oracle VM VirtualBox - Downloadswww.oracle.comOnce you have installed Virtual Box we can get what we need to start a virtual machine. We first need a OS (Operating System), in this article I’m going to use Microsoft Windows 10.Obviously we do not have a physical disc drive or USBs to attached a USB stick with a VM (even though you can when installed) so we need a OS ISO file. An ISO file is a disc image of a physical install disc of a OS.Microsoft let you download a ISO of Windows 10 for free from their website at the below link…Download Windows 10 Disc Image (ISO File)Make sure you have: An internet connection (internet service provider fees may apply). Sufficient available data…www.microsoft.comSelect your edition and click confirm.Windows 10 ISO DownloadThen select your language and click confirm again.Select ISO LanguageYou will then need to select either 32bit or 64bit (if your machine is 64bit then select 64bit)32 or 64 BitThe ISO should now download, this can take a while depending on your internet speed, as this ISO is rather large (around 5GB)Once the ISO file has downloaded we can now prepare our Virtual Box to install Windows.Open Virtual Box and you should see the below window…Virtual BoxClick the New icon from the toolbar at the top of the window, you should now see the below window…Name your OS VMVirtual Box now whats you to name your VM, in the name textbox type in Windows 10. You will notice that Virtual Box automatically changes the version type for you.Version automatically changedClick Continue to move to the next window, you should now see the Memory Size window. This is where you can set the VM’s memory (RAM) by default Virtual Box will set the RAM to 2048mb this is more than enough for testing software etc, but if you are wanting to play a game or something else more RAM hungry then you may wish to increase this. For now we will just leave it at 2048 (2GB).VMs RAM OptionClick Continue, you should now see the Hard Disk window, by default Virtual Box will create a virtual HDD of 50GB, make sure you check the option ‘Create a virtual hard disk now’ and click Create.Create VM HDDYou should now have a window named Hard Disk File Type, keep the default setting of VDI (VirtualBox Disk Image) and click Continue.HDD File TypeThe next window should now ask you about how you want to store data to the physical hard disk, you have the option to have it Dynamically allocated which means if more storage is needed in the future the HDD size will grow to suit, or you can select fixed which will not grow automatically, Click Continue.Dynamic or FixedThe next window is the File Location and Size window, this is where you can choose where to store your VM on your HDD, I suggest leaving it as default in the VirtualBox VM’s directory. Here you can also adjust the HDD size (default is 50GB).VM storageThats it! We have now fully setup a VM thats ready to boot, you should now see the below window…VM all setHave a quick check over your settings, make sure they are as you want them (you can always change these later anyway) and click Start from the toolbar at the top of the window.If you are running this for the first time on a Mac then you will be asked by macOS to give permissions to Virtual Box, give all the permissions it needs to run then click start again!You should now see the below window…Fatal: No bootable medium found!Click the CD icon at the bottom of your VM window like the below…CD/DVDClick on Choose a Disc File, then select your Windows 10.iso file (should be in your downloads file).Now we need to restart the VM, we need to do this because the VM didn’t know how to boot as it had no OS installed. All we are doing here is inserting a CD/DVD into the drive for it to boot the install process virtually.You should now have the below window asking to input your Windows setting as you would expect.Windows 10 Install ProcessAdjust your settings accordingly and let Windows install to your VM.Note your window may be small, this is because the graphics drivers have not been installed yet, this will change when Windows has finished installing.After the install has finished you should now be presented with the windows 10 Desktop as you would expect.Windows 10 running in a VMThat’s it, you have now installed Windows on a VM, you can use this now how you would any other Windows computer.Now you know how to setup a VM you can download any OS ISO’s and try them out, such as Linux, the process is the same.I hope you find this useful and if you have any questions please feel free to ask me on Twitter @BIG_PESH or on here in the comments.Happy Virtual Machining!Mac O’ClockThe best stories for Apple owners and enthusiastsFollow129 1 TutorialVirtualizationOperating SystemsMicrosoftMacos129 claps129 claps1 responseWritten byGrant PeachFollowHobbyist computer programmer (Python, Java, SQL, Swift & Visual Basic), XB1X/Switch Gamer, love computer history, gadgets and the Internet.FollowMac O’ClockFollowThe best stories for Apple owners and enthusiastsFollowWritten byGrant PeachFollowHobbyist computer programmer (Python, Java, SQL, Swift & Visual Basic), XB1X/Switch Gamer, love computer history, gadgets and the Internet.Mac O’ClockFollowThe best stories for Apple owners and enthusiastsMore From MediumNot Sorry: If You’re a Coder, You’re the Bottom of the Food Chain and OverpaidAnonymousBusinessPhilosopherLolcat: Rainbow Animation in RubyDeka AmbiaDevOps_ProjectRitesh SinghHow Ad Blockers WorkConnor Finnegan in Better ProgrammingDisplaying JSON data from an APISerena LambertThe Purple People ParserMichel Belleville in Wat, the Elm-istHow to deploy a Blazor application on AzureAnkit Sharma in freeCodeCamp.orgHow to handle navigation in your Flutter appsSameeha Rahman in freeCodeCamp.orgLearn more.Medium is an open platform where 170 million readers come to find insightful and dynamic thinking."
[Pintos] 1–5. Synchronization,https://medium.com/@benny._.lee/pintos-1-5-synchronization-83dbe67265e?source=tag_archive---------0-----------------------,"Pintos,Operating Systems,Linux,Ubuntu,Synchronization","이번 포스팅에서는 동기화(Synchronization)에 대해서 알아보도록 하자.race condition (https://dev.to/rinsama77/process-synchronization-with-busy-waiting-4gho)다수의 작업을 동시에 실행시키는 멀티태스킹의 등장으로 병렬적으로 일을 처리함에 따라 응용프로그램의 실행 시간, 사용자에 대한 응답시간을 단축할 수 있게 되었다. 그러나 다수의 작업들이 공유 데이터에 동시에 접근하게 될 시에는 데이터가 훼손되는 문제가 발생할 수 있다. 즉, 여러 스레드가 공유 변수에 접근하려고 경쟁(race) 하는 상황에서 적절한 처리가 되지 않는다면 아래와 같이 의도치 않은, 잘못된 데이터가 저장될 가능성이 존재한다.🙄race condition example (http://opensourceforgeeks.blogspot.com/2014/01/race-condition-synchronization-atomic.html)이러한 문제를 해결하기 위한 방법인 동기화는 한 스레드가 공유 데이터에 대해 독점적으로 접근하도록 함으로써 다수의 스레드가 충돌 없이 공유 데이터에 접근하여 공유 데이터의 훼손을 방지한다.상호배제(Mutual Exclusion)상호배제는 임계 구역에 먼저 진입한 스레드가 독점적으로 해당 구역의 실행을 끝낼 때까지 다른 스레드가 진입하지 못하도록 관리하여 공유 데이터의 훼손을 방지하는 알고리즘이다.critical regioin (https://dev.to/rinsama77/process-synchronization-with-busy-waiting-4gho)여기서 임계 구역(critical region)은 공유 데이터에 접근하는 코드로, 하나의 스레드의 배타적인 사용이 보장되어야 한다. 진입 코드(entry code)와 출구 코드(exit code)를 두어 임계 구역에 대한 상호배제를 만든다.진입 코드 : 다른 스레드가 임계 구역에 있는지 체크하여 없으면 다른 스레드가 들어오지 못하도록 하고, 있으면 안에 있는 스레드가 임계 구역을 벗어나기를 기다림출구 코드 : 임계 구역의 실행을 마치면 대기 중인 스레드나 다른 스레드가 임계 구역에 들어올 수 있도록 들어오지 못하게 조치를 취한 것을 해제함상호배제는 Peterson의 알고리즘 등과 같은 소프트웨어적인 방법과 인터럽트 서비스 금지, 원자 명령 사용과 같은 하드웨어적인 방법으로 구현할 수 있다. 다만 소프트웨어적 방법은 실제 구현 시에 여러 문제가 있어 오늘날 하드웨어적 방법을 주로 사용하므로, 하드웨어적으로 상호배제를 구현하는 방법에 대해서 자세히 살펴보도록 한다.👀1. 인터럽트 서비스 금지임계 구역으로 진입할 때 진입 코드에서 인터럽트 서비스를 금지하는 명령어를 실행함으로써 스레드가 임계 구역을 실행하는 중에 선점되지 않도록 하는 방법이다.disabling interrupt (https://dev.to/rinsama77/process-synchronization-with-busy-waiting-4gho)그럴싸해 보이지만 CPU가 모든 인터럽트를 무시함으로써 언제 끝날지도 모르는 스레드가 완료될 때까지 무한정 기다려야 하므로 동기화의 목적에는 부합하지 않으며, 다중 CPU 시스템에서는 다른 코어에서 실행되는 스레드가 임계 구역 코드를 실행하는 것을 막지 못하므로 완벽한 해결책이라고 볼 수 없다.😕2. lock 변수 사용lock이라는 변수를 두어 임계 구역에 진입할 때는 값을 1로, 빠져나올 때는 0으로 설정하여 임계 구역을 실행하고 있는 스레드가 있는지 확인하는 방법이다. 인터럽트 서비스 금지와 달리 문도 있고 동시에 임계 구역에 진입하는 것을 막는 괜찮은 방법 같아 보이지만 lock이 생김으로 인해 임계 구역에 진입하기 위한 경쟁뿐만 아니라 lock을 위한 경쟁까지 하게 되었다.😞lock variable (https://dev.to/rinsama77/process-synchronization-with-busy-waiting-4gho)3. 원자 명령 사용아래 그림은 좌측 소스 코드를 실행하는 두 가지 시나리오를 나타낸 것이다. 한 번 살펴보도록 하자.Scenario 1에서는 한 스레드의 명령이 모두 수행된 후에 다른 스레드가 명령을 수행하기 때문에 공유 변수 val에 올바른 값이 저장되었음을 확인할 수 있다.atomic vs non-atomic operation (https://preshing.com/20130618/atomic-vs-non-atomic-operations/)그러나 Scenario 2에서는 Thread 0에서 val을 load 하고 1을 더한 다음 미처 결괏값을 val에 담기 전에 컨텍스트 스위칭이 발생하여 Thread 0의 TCB(Thread Control Block)에 CPU 레지스터 값들을 저장한다. 이제 Thread 1이 스케줄 되어 val을 load 하면 이전 스레드에서 아직 값을 담지 못했기 때문에 0인 상태로, 또다시 컨텍스트 스위칭이 발생해서 Thread 1의 TCB에 값을 저장한다. 그리고 Thread 0이 스케줄 되면 Thread 0의 TCB에 기록해 둔 레지스터 값들을 CPU에 복귀시켜 명령을 실행함으로써 비로소 val의 값은 1이 된다. 다시 컨텍스트 스위칭이 발생하여 Thread 1이 스케줄 되면 마찬가지로 TCB에 저장된 레지스터 값들을 복귀시킨다. 당시 val은 0인 상태였고 이 값에 1을 더하고 값을 변수에 담으면 다시 1이 된다. 이는 기대한 값 2가 아니다.이러한 문제가 발생한 원인은 이미 위의 그림에서 확인했듯이, 우리가 작성하는 한 줄의 코드는 사실 여러 줄의 기계어 명령으로 이루어져 있기 때문이다. 코드에 해당하는 모든 기계어 명령이 수행되고 나서 다른 코드의 명령을 수행할 경우에는 별로 문제가 되지 않겠지만, CPU가 기계어 명령을 순차적으로 실행하는 도중에 컨텍스트 스위칭이 발생하게 될 경우 문제가 발생할 수 있다.그래서 상호배제를 위해 특별히 설계된 CPU 명령인 원자 명령으로 여러 줄의 명령을 실행하는 도중에 컨텍스트 스위칭이 일어나지 않도록 명령들을 하나의 명령으로 만들어 위와 같은 문제가 발생하지 않도록 한다.멀티 스레드 동기화 기법뮤텍스(Mutex), 스핀락(Spinlock), 세마포어(Semaphore) 등 다양한 방법으로 멀티 스레드를 동기화 할 수 있다. 과제와 크게 관련성은 없지만 세마포어가 언급되므로 어떤 기법들인지만 살펴보자.1. 뮤텍스(Mutex)lock을 이용하여 오직 한 스레드만이 자원을 독점적으로 사용하도록 하는 동기화 기법으로, 대기 큐가 존재하며 임계 구역의 실행 시간이 짧은 경우에는 lock이 잠겨있는 시간보다 스레드가 sleep 상태에서 깨어나는데 더 긴 시간이 낭비되어 비효율적이다. 따라서 임계 구역의 실행 시간이 긴 경우와 단일 CPU 시스템, 사용자 프로그램에 적합하다.2. 스핀락(Spinlock)뮤텍스와 마찬가지로 lock을 기반으로 하는 동기화 기법이지만 대기 큐가 없고 lock이 풀릴 때까지 무한 루프를 돌면서 lock을 검사하는 코드를 실행(busy-waiting) 하기 때문에 단일 CPU를 가진 운영체제에서는 의미 없이 기다리며 CPU를 낭비하면서도 다른 스레드의 실행 기회도 빼앗아 비효율적이다. 따라서 임계 구역의 코드가 짧은 경우와 멀티 코어를 가진 시스템, 커널 코드나 인터럽트 서비스 루틴에 효과적이다.3. 세마포어(Semaphore)동시에 사용할 수 있는 하나의 자원에 대해 스레드들이 공유하도록 관리하는 동기화 프로그래밍 기법이자 공유 자원의 개수를 나타내는 변수로, 하나의 자원은 여러 인스턴스를 포함한다. 자원에 대한 다중 스레드의 원활한 공유를 목적으로 하며, P(Proberen: try in Dutch)/V(Verhogen: increment in Dutch) 연산을 통해 대기 큐나 무한 루프 방식으로 자원을 얻을 때까지 대기(busy-waiting) 하다가 자원 사용을 마치면 대기 스레드에 알려 스레드 동기화를 이룬다.다음 포스팅에서는 Priority Scheduling and Synchronization을 해결해보도록 할 예정이다.Written byJeong Hyeon LeeFollowPintosOperating SystemsLinuxUbuntuSynchronizationMore from Jeong Hyeon LeeFollowMore From MediumHow I Use Linux ProfessionallyShawn Grover in The StartupDonald Trump Won, No Matter What Happens NextJessica Wildfire in The Apeiron Blog(Why) There Was no Biden Landslideumair haque in Eudaimonia and Co20 Things Most People Learn Too Late In LifeNicolas Cole in Better Advice“Anyone but Bernie”, They Said.Lauren Martinchek in Dialogue & DiscourseWell… That Did Not Go as PlannedPatrick Tompkins in The Purple GiraffeThe Democrats Were Suckered Into Mail-In VotingDavid Leibowitz in Dialogue & DiscourseI Worked the Polls in Trump Country — and Left More Confused Than EverAaron Gell in GENAboutHelpLegalGet the Medium app"
Build and run a boot-loader,https://medium.com/@andersongusmao/build-and-run-a-boot-loader-561822fd4299?source=tag_archive---------0-----------------------,"Bootloader,Boot,Operating Systems","What to expect here.If you’re a curious guy like me, you’ve probably wondered how an operating system works. Here, I’ll share some research and practical experiments I’ve done to understand computing and operating systems better. After reading, you will create your bootable program that works in any virtual machine application like Virtual Box.Important noteThis article is not intended to explain everything about the boot loader with its complexities. This example is just a starting point based on the x86 architecture. It must be difficult reading for most people, which requires basic knowledge of microprocessors and computer programming.What is a bootloader?In simple words, a boot-loader is a piece of software loaded into a computer’s working memory after booting.In more detail, after pressing the start button on a computer, many things must be done. Then, a firmware called BIOS (Basic Input Output System) kicks in and does its job. After that, the BIOS gives control to the boot loader installed on any available media, that is, USB, hard drive, CD drive, etc. The BIOS goes through the data media found in sequence, checking for a unique signature — the so-called boot signature (or ‘boot record’). When the boot record is found and loaded into the computer’s memory, the processor starts to function from that point. To be more precise, at address 0x7C00, save this memory address; this is important in building the boot loader.Work inside of the first sector with only 512 bytes.Figure 01 — MBR (Master boot record) — The first sector is where boot-loader must beDuring the BIOS initialization process, the BIOS looks in the bootable devices’ first sector for a single signature, as mentioned before. This unique value is 0xAA55 and must be in the last two bytes of the first sector. Despite 512 bytes available in the master boot record, we cannot use all of them; we need to subtract the partition table schema and signature, and only 440 bytes remain. It doesn’t seem like good memory space, but you can write code to load more data from other sectors into memory and solve the problemThe initialization steps in a simplified wayThe BIOS boots computers and their peripherals;The BIOS searches for bootable devices;When the BIOS finds the signature 0xAA55 in the MBR (master boot record), it loads that sector into memory at position 0x7C00 and gives control to this entry point, that is, it starts executing instructions from this point 0x7C00 in memory ;Let’s start codingCode 01 — Bootloader assembly code.As you can imagine, this is assembly language and needs to be compiled into machine code with an assembly compiler to generate machine code, as you can see in the next block of code. Note that 512 in hexadecimal notation is 0x200 and the last two bytes are 0x55 and 0xAA; it is inverted compared to the assembly code above; this is related to the storage ordering system known as endianness. For example, in a big-endian system, the two bytes required for the hexadecimal number 0x55AA would be stored as 0x55AA in storage (if 55 is kept at storage address 0x1FE, AA will be at address 0x1FF). On a little endian system, it would be stored as 0xAA55 (AA at address 0x1FE, 55 at 0x1FF).Code 02 — Machine code after NASM compilation.How this code worksI will explain this code line by line in case you are not familiar with assembly language.1-) Specifying target processor mode, this BITS directive specifies whether NASM should generate code designed to run on a processor operating in 16-bit mode, 32-bit mode, or 64-bit mode. The syntax is BITS XX, where XX is 16, 32, or 64.2-) Specifying the binary file program origin, this ORG directive is to specify the origin address, which NASM will assume the program begins at when it is loaded into memory. When this code is translated to machine code, the compiler and linker will determine and organize all data structures needed by the program; this reference address will be used for this purpose.3-) This is just a label; when defined in code, it refers to a memory position you can point to; it is used together with jump instructions to control the application’s flow; This idea will make more sense in the next line.After explaining the fourth line, we need to describe the concept of registers:A processor register is a quickly accessible location available to a computer’s processor. Registers usually consist of a small amount of fast storage, although some registers have specific hardware functions and may be read-only or write-only. In computer architecture, registers are typically addressed by mechanisms other than main memory but may, in some cases, be assigned a memory address. This definition was extracted from Wikipedia.4-) Assigning data with MOV instruction, this instruction is used to move data; in this case, we are moving the value of the memory address of the label message to the SI register; Which will point to the text “Hey! This code is my boot loader operating.”. If you look in the image below, you will see that this text is stored at poison 0x7C10 when translated to machine code.Figure 02 - Binary file disasembled by IDA software.5-) We will use the BIOS video services to display the text on the screen, so we are settings how we want this work. It moves the byte 0x0E to the register AH.6-) Another label reference that allows controlling the execution flow, later we will use it to create a loop.7-) This instruction loads a byte from the source operand into the AL register. Remember the fourth line, in which the SI was set with a text address position; now, this instruction is getting the character stored at memory space 0x7C10. It is vital to notice this is behaving like an array, and we are point to the first position, which contains the character ‘H’; as we can see in figure 03 below. This text presentation will occur in a vertically iterative manner, and each character will be set each time. Besides, the second character was not presented extracted snapshot from the IDA program; 0x65 in ASCII represents the character ‘e’.Figure 03 — Array of characters between 0x7C10 until 0x7C3B.8-) Performing OR boolean operation between (AL | AL), at first glance, it does not seem to make any sense, but it does. We need to check if the result of this operation is zero, based on logic boolean, the result will be the same after this operation, for example, [1 | 1 = 1] or [0 | 0 = 0]. In the next line, you are going to understand why this is necessary.9-) Jump to halt label (Line 12) if the result of the last OR operation is zero, in the first moment, the value of AL is [0x48 = ‘H’] based in the last LODSB instruction, do you remember that on Line 7? So, it will not jump to halt label in the first moment. Why that? (0x48 OR 0x48) = 0x48, then it will go to the next instruction in the next line. It is important to say that JZ instruction is not related only to OR instruction. There is another register called FLAGS, which is observed during jump operations, i.e., the result of OR operation is stored in this FLAG register and observed by JZ instruction.10 -) Invoking BIOS interruption, the instruction INT 0x10 displays the value of AL on the screen; remember line 5, we set the value of AH with 0x0E; this is a combination to present the value of AL on the screen.11-) Jump to .loop label, that’s it without any condition, it is like GOTO instruction compared to a high-level language.12-) We are in line 7 more one time, LODSB will retake action. After the byte is transferred from the memory location into the AL register, the SI register is incremented. The second time, it is pointing to the address 0x7C11 = [0x65 ‘e’], then the character ‘e’ is presented on the screen. This loop will run until it reaches the address 0x7C3B = [0x00 0], and when the JZ is executed again on line 9, the flow will be driven to the halt label.13-) Here, we finish our journey. The CLI and HLT instructions halt the execution.14-) At the seventeenth line you see an instruction that pads the remaining 510 bytes with zeroes after that adds the boot record signature 0xAA55.Let’s build and runIn the first step, you must make sure you have installed the NASM compiler and QEMU on your computer, using your favorite dependency manager or downloading it from the internet; QEMU is a virtual machine emulator.If you have Linux, you can type on terminal:sudo apt-get install nasm qemuOn a mac you can use homebrew:brew install nasm qemuAfter accomplishing the first step, you must create a file with the assembly code presented in Code 01 block. Let’s name this file as boot.asm and then run NASM command:nasm -f bin boot.asm -o boot.binIt will produce the binary file you need to run your virtual machine, let’s run it on QEMU:qemu-system-x86_64 -fda boot.binYou should see the following screen:Figure 04 — Running the boot-loader with QEMU.Running it from Virtual boxFirstly you need to create a virtual an empty floppy diskdd if=/dev/zero bs=1024 count=0 > floppy.imgAnd then append the binary content inside of it:cat boot.bin >> floppy.imgNow you can create a Virtual Box machine and boot it using your image file.Figure 05 — Running the boot-loader with Virtual Box.I was not able to explain many things here for the sake of brevity; if this is your first time with this type of content, probably many questions have arisen in your head, ok, this is not an easy subject, and I hope it can serve as a starting point for many studies. A book that I recommend is Operating Systems Design and Implementation by Andrew S. Tanenbaum, a useful reference to better understand many principles of computing and operating systems.Written byAnderson Santos GusmãoIn my house I’m the boss, my wife is just the decision maker.Follow7 7 7 BootloaderBootOperating SystemsMore from Anderson Santos GusmãoFollowIn my house I’m the boss, my wife is just the decision maker.More From MediumPointers in GoMatheus Kielkowski in LinkApi SolutionsRefactoring — oops, I’ve been doing it backwards.Justin Fuller in freeCodeCamp.orgCreating a web and API authentication service in RustUk Chukundah in The StartupLet’s Keep a Record of Your ScoreQueenie Pamatian in The StartupHow to turn writing a code documentation  into a cool jobVivaldi Valentina in The StartupDemystifying ARM TrustZone for Microcontrollers (and a Note on Rust Support)Nihal Pasham in The StartupAPI Documentation Maturity — How Do Your Docs Stack up?Erikka Innes in The StartupGo: WorkspacesChris Kakos in The StartupAboutHelpLegalGet the Medium app"
Windows VS Macintosh VS Linux-The best operating system?,https://medium.com/@satvikvirmani/windows-vs-macintosh-vs-linux-the-best-operating-system-e7830fd364ef?source=tag_archive---------1-----------------------,"Mac,Linux,Windows 10,Operating Systems,Mac Vs Pc","Mac vs Linux vs WindowsHey guys. today we are going to compare the three operating systems available. So without any further ado let’s get started1.)Macintosh (macOS)Mac(Macintosh) is second most popular operating systems for Apple devices. It accounts for nearly 10% of user share.Pros:Easy to useBest UI / UX ExperienceIntegration with all devices / platformSecureCons:Very ExpensiveNo CustomizationConclusion:Mac is best for those people who rely on better user experience and want all of their devices (Phone. smartwatch, tablet ,tv ,etc.) interconnected to each other. Moreover, for people who are UI/UX designers (graphic designers and content creators) MAC is recommended as apps like Sketch, Final Cut Pro are only available for Mac. If you are are looking for a OS for some programming and everyday use and have a nice budget then Mac is the best option.2.)LinuxLinux is the most widely used operating system that powers 96.3% internet all around the globe. It is based on Unix-like operating system.Pros:Open-Source (free)Most Secure (practically no viruses)Best community supportTactical Advantage for programmersLarge variety of Distro (distributions)Large database of appsCons:Difficult to useMany popular apps like (Adobe apps) are not available.Conclusion:Linux is considered best for all round programmers especially Kernel programmers, internet developers. Although it is somewhat difficult to use but still many distro like Ubuntu and Linux Mint make use of a lot og GUI to make it work as an everyday use OS. Also it provides a small yet significant advantage to programmers in their job interviews. Linux is considered as a skill so provides an edge over others to its users.3.) WindowsWindows is the most popular operating system accounting for nearly 88% of user share.Pros:Not so expensiveCompatible with almost everythingEvery app is first designed for WindowCustomizableCons:Resource Extensive (Windows 10 require min. 2 GB ram for 64-bit)Not so secureConclusion:Windows is considered best for software developers (Machine Learning, Deep Learning, etc.) as it has the largest variety of apps for almost every purpose. It is very easy to use so is recommended for people who use PC for everyday use like web surfing, video streaming and have a average budget. For learning purposes Windows is considered BEST.Final ConclusionIf you want to use your PC for everyday use and you have a budget of 1200 USD (90,000 Ruppes) then Mac is your best option. Else, you have a somewhat low budget then a windows laptop comes at 800 USD (60000 Ruppes). While for linux, you can install it for free on almost every hardware except Apple devices. But if you’re a programmer and want to learn more and also want a advantage then I would prefer Linux.With this we end this post.if you like please follow and share.Follow Me:InstagramFacebookTwitterGithubWritten bySatvik VirmaniHey There, I am a PC enthusiast and amateur programmer who love to code and learn various concepts of Computing. Python Ninja. Occasional Full Stack Dev.FollowMacLinuxWindows 10Operating SystemsMac Vs PcMore from Satvik VirmaniFollowHey There, I am a PC enthusiast and amateur programmer who love to code and learn various concepts of Computing. Python Ninja. Occasional Full Stack Dev.More From MediumGetting Started with React-ReduxHailey Jane Bobella in HackerNoon.comHow to Crack the Google Cloud Professional Data Engineer Exam in 1 Month (October 2020)Revannth V in The StartupVariances in ScalaBartosz Gajda in The StartupAdd A Custom Info Window to your Google Map Pins in FlutterRoman Jaquez in Flutter CommunityWhy is “IN” query slow on indexed column in PostgreSQL?Dhruv Agarwal in Shuttl TechInstall Ghost on Your Raspberry PiPierre Averous in The StartupAWS Serverless Deployment — 101Naresh WaswaniContribute desired amount Of storage of DataNode to the Hadoop ClusterSachin KumarAboutHelpLegalGet the Medium app"
What’s the difference between MBR and GPT?,https://medium.com/@sohailsaifi65/whats-the-difference-between-mbr-and-gpt-3a3b83a20845?source=tag_archive---------0-----------------------,"Hard Disk,Operating Systems,Gpt,Mb,Mbr Vs Gpt","Ever came across the terms MBR or GPT partitioning? If not yet, you’ll surely need to know about them when you will install any operating system in your computer by yourself as they play a major role in the partitioning of the hard disk.MBR and GPT are mainly two different ways of creating the partitions in your hard disk. They both use their own strategies to create the partitions in the drive. We have to create these partitions because of the many reasons like storing the system files and other data in different partitions so that they do not disturb the functioning of the system files.The MBR or Master Boot Record partition style was used for many years in the past but it had many limitations that’s why new partition style came into use.For example, the major limitation of the MBR partition was that it can only have four primary partitions at most. If anyone wanted to use more than that then they have to use the “Extended partitions”. This partition style also had more risk of data loss.Another major problem was that MBR partitions can only be used on hard drives or storage devices up to 2 terabytes. It’s true that for many decades that was more than enough, but nowadays it is too small even for basic use by users.Because of these limitations, GPT or GUID partition table partition was developed having more storage capacity and reliability. It’s associated with UEFI, which is a replacement for the old BIOS. It’s called GUID Partition Table because every partition in the hard drive has a “globally unique identifier,” or GUID: a random string so long that every GPT partition on this planet likely has its own unique identifier.GPT doesn’t suffer from MBR’s limitations. GPT-based drives can be much larger, with size limits dependent on the operating system and its file systems. GPT also allows for a nearly unlimited number of partitions. Again, the limit here will be your operating system that how many it can support.On an MBR disk, the partitioning and boot data is stored in one place. If this data is overwritten or corrupted, you’re in trouble. In contrast, GPT stores multiple copies of this data across the disk, so it’s much more robust and can recover if the data is corrupted.This was the basic overview of these partition styles in an easy way. If you are interested in these more then you can go further reading about them across the internet because knowledge has no limits.Written bySohail SaifiFollowHard DiskOperating SystemsGptMbMbr Vs GptMore from Sohail SaifiFollowMore From MediumHow to test Jupyter notebook from Github via Google ColabSteve TanErasureJeff Pollard in strava-engineeringBeginner’s guide to create Python WheelVivek Atal in The StartupPartial Application in PythonMartin McBride in The StartupWeb Standards: the What, the Why & the How? 🕸 📋Amy Dickens in Samsung Internet DevelopersWordPress Continuous Deployment and Version Control with BitbucketAlexa Green in The StartupHandling Graphs With Adjacency ListsHybesis - H.urna in The StartupStart a K8s SolrCloud with Pre-Installed Custom Libraries — Customizing Solr Helm ChartJohn The Traveler in The StartupAboutHelpLegalGet the Medium app"
Operating System — CPU Scheduling II : 05,https://medium.com/@effectivereader/operating-system-cpu-scheduling-ii-05-3c03c29ca8c8?source=tag_archive---------0-----------------------,"Operating Systems,Computer Science,Information Technology,Cpu Scheduling,Computers","Operating System — CPU Scheduling II : 055.1 IntroductionCPU scheduling is used in operating systems to maximize CPU utilization and to provide multiple users with a feel that they are the sole users of the system. This module explains the working of the preemptive Shortest Job First (SJF), priority CPU scheduling and round robin scheduling algorithms.5.2 Preemptive Shortest Job First (SJF) scheduling algorithmThe SJF CPU scheduling algorithm associates with each process the length of its next CPU burst. These lengths are used to schedule the process with the shortest time. When the CPU becomes available, the process with the shortest next CPU burst is assigned the CPU. There are two schemes in SJF. One is non-preemptive in which once the CPU is given to a process, the process cannot be preempted until the process completes its CPU burst. The other is preemptive in which, if a new process arrives with a CPU burst length less than the remaining burst time of the currently executing process, the currently executing process is preempted. Thus, this scheme is also known as the Shortest-Remaining-Time-First (SRTF). In this module, we will learn how scheduling is done in preemptive SJF also known as SRTF.Consider four processes P1, P2, P3 and P4. The arrival times and the CPU-burst times in milliseconds of the four processes are given below:Process Arrival Time Burst TimeP1 0.0 7P2 2.0 4P3 4.0 1P4 5.0 4At time 0.0 ms, P1 is the only process that has arrived. Therefore, P1 is given the CPU first. P1 continues to use the CPU till the next process arrives..At time 2.0 ms, process P2 arrives. The burst time of P2 is 4 ms. At time 2.0 ms, P1 needs 5 more milliseconds to complete its CPU-burst as shown below:At time 2.0:Process Remaining Burst TimeP1 5P2 4Since the burst time of P2 is less than the remaining time needed for P1, P1 is preempted and P2 is assigned the CPU.At time 4.0 ms, another process P3 arrives. P3 has a CPU-burst time of 1 ms. Process P2, which is currently running, needs 2 ms more to complete its CPU-burst as shown below:At time 4.0:Process Remaining Burst TimeP1 5P2 2P3 1Since the new process that has arrived has a shorter CPU-burst than the remaining time needed for the currently running process, process P2 is preempted and P3 is assigned the CPU.At time 5.0 ms, process P4 also arrives and process P3 completes its CPU burst. Now, there are three processes in the ready queue P1, P2 and P4. P1 needs 5 ms more to complete its CPU burst, P2 needs 2 ms more to complete its CPU burst and P4 needs 4 ms as shown below:At time 5.0:Process Remaining Burst TimeP1 5P2 2P4 4Thus, of these three processes, P2 needs the shortest time and hence is given the CPU.Once P2 completes its CPU-burst, the remaining burst time for the processes is shown below:At time 7.0:Process Remaining Burst TimeP1 5P4 4The process that has the shortest remaining time, that is, process P4 is assigned the CPU as shown in Figure 8.5. After process P4 completes its CPU burst, the only remaining process is P1 and P1 is assigned the CPU.5.2.1 Calculation of waiting time and turnaround timeFrom the Gantt chart shown in Figure 8.6, the average waiting time and the average turnaround time can be calculated. Process P1 arrives at time 0 and gets the CPU at 0. Then from time 2.0 till time 11.0 P1 is waiting. Therefore, the waiting time for P1 is 0 + 9 = 9. Process P2 arrives at time 2.0 and gets the CPU at time 2.0. Then from time 4.0 till time 5.0, it is waiting. Therefore, the waiting time for process P2 is 0 + 1 = 1. Process P3 arrives at time 4.0 and gets the CPU at 4.0. P3 finishes its CPU burst without waiting. Hence, the waiting time for P3 is 0. Process P4 arrives at time 5.0, gets the CPU at time 7.0 and completes its CPU burst. Hence, the waiting time for process P4 is 2. Therefore, the average waiting time = ((0 + 9) + (0 + 1) + (0) + (2))/4 = 3Process P1 arrives at time 0 and completes execution at 16. Hence the turnaround time for P1 is 16. Process P2 arrives at time 2 and completes execution at 7. Therefore, the turnaround time for P2 is 5. Process P3 arrives at time 4 and completes execution at 5. Hence, the turnaround time for P3 is 2. Process P4 arrives at time 5 and completes execution at 11. Therefore, the turnaround time for P4 is 6. Hence, the average turnaround time = ((16–0) + (7–2) + (5–4) + (11–5))/4 = 7.5.2.2 Prediction of burst times for SJFIn SJF scheduling algorithm, the process with the shortest CPU-burst is selected by the CPU scheduler. But knowing the length of the CPU bursts is not possible. However, the value of the next CPU burst can be predicted based on the length of the previous CPU bursts. It is assumed that, for a particular process, the next CPU burst will be similar in length to the previous ones.5.2.2.1 Determining length of next CPU burstThe length of the CPU burst is predicted using exponential averaging. The next CPU burst is predicted as an exponential average of the measured lengths of the previous CPU bursts. Let tn be the actual length of nth CPU burst. Then  n+1, the predicted value for the next CPU burst is defined as n+1 = α tn + (1- α)  n where 0 ≤ α ≤ 1The parameter α controls the relative weight of recent and past history in the prediction. When  = 0,  n+1 =  n and the recent history does not count. When  = 1,  n+1 = tn and only the actual last CPU burst counts.If we expand the formula, we get: n+1 =  tn + (1 —  )  tn-1 + … + (1 —  )j  tn-j + … + (1 —  )n+1  0Since both  and (1 — ) are less than or equal to 1, each successive term has less weight than its predecessor.5.3 Priority SchedulingIn the priority scheduling algorithm, a priority number (integer) is associated with each process. The CPU is allocated to the process with the highest priority (smallest integer  highest priority). If two processes have the same priority, then the tie is broken using FCFS. SJF is also a priority scheduling algorithm where priority is the predicted next CPU burst time. The priorities for processes are defined based on internal or external factors. The internal factors for a process can be number of open files, time limits, memory requirements and so on. The external factors can be importance of the process, type and amount of funds being paid for computer use and so on.The priority scheduling algorithm can be either preemptive or non-preemptive. In non-preemptive scheduling algorithm, the process that has the highest priority is assigned the CPU. But, if another new, high priority process arrives while a process is using the CPU, the process that is currently using the CPU is not preempted. It continues to use the CPU till its CPU burst time is completed. In preemptive scheduling, if a new, high priority process arrives, the process that is currently using the CPU is preempted, even though it has not completed its CPU burst. The newly arrived, high priority process is assigned the CPU.The one problem with the priority scheduling algorithm is that low priority processes may never execute when high priority processes keep arriving. Hence, the low priority processes starve. The solution to this is to go for aging. That is, as time progresses, the priorities of the low priority processes are increased. And hence, in course of time, the low priority processes gain priority and get the CPU.5.3.1 Example of Priority SchedulingConsider five processes P1, P2, P3, P4 and P5 whose CPU-burst times in milliseconds and priorities are given below:Process Burst Time PriorityP1 10 3P2 1 1P3 2 3P4 1 4P5 5 2Let us see how the CPU is assigned to the processes when the scheduling algorithm is non-preemptive priority scheduling. The Gantt chart is shown in Figure 8.7. Here, all processes arrive at the same time, in the order P1, P2, P3, P4 and P5.Among all the five processes, process P2 has the highest priority (a low priority number indicates a high priority). Hence, the CPU is assigned to process P2 first. P2 has a CPU burst time of 1 ms. Once P2 completes its CPU burst, P2 relinquishes the CPU. The process with the next highest priority is P5. The CPU is assigned to process P5 next. P5 uses the CPU for a time equal to its CPU burst (5 ms) and then relinquishes the CPU. Of the remaining processes, P1 and P3 have the same priority. Now, the tie is broken using FCFS. Thus, the CPU is assigned to process P1, which arrived earlier than P3. P1 uses the CPU for a time equal to its CPU burst (10 ms) and then relinquishes the CPU. The CPU is assigned to process P3 next. P3 uses the CPU for a time equal to its CPU burst (2 ms) and then relinquishes the CPU. The only remaining process is P4. P4 gets the CPU, uses the CPU for a time equal to its burst time and then relinquishes the CPU.5.3.2 Calculation of waiting time and turnaround timeFrom the Gantt chart shown in Figure 8.7, the average waiting time and the average turnaround time can be calculated. Process P1 arrives at time 0 and gets the CPU at time 6 ms and completes the CPU burst. Therefore, the waiting time for P1 is 6 ms. Process P2 arrives at time 0 and gets the CPU immediately. Hence the waiting time for process P2 is 0. Process P3 arrives at time 0 and gets the CPU at 16 ms and completes its CPU burst. Therefore, the waiting time for P3 is 16 ms. Process P4 arrives at time 0, gets the CPU at time 18 ms and completed its CPU burst. Hence the waiting time for process P4 is 18 ms. Hence, the average waiting time = (6 + 0 + 16 + 18)/4 = 10 ms.Process P1 arrives at time 0 and completes execution at 16 ms. Hence, the turnaround time for P1 is 16 ms. Process P2 arrives at time 0 and completes execution at 1 ms. Hence, the turnaround time for P2 is 1 ms. Process P3 arrives at time 0 and completes execution at 18 ms. Hence, the turnaround time for P3 is 18 ms. Process P4 arrives at time 0 and completes execution at 19 ms. So, the turnaround time for P4 is 19 ms. Therefore, the average turnaround time = (16 + 1 + 18 + 19)/4 = 13.5 ms.5.3.3 Starvation and agingAs mentioned earlier, starvation is an issue in priority scheduling. Suppose, initially, there are five processes in the system P1, P2, P3, P4 and P5 with priorities 1, 2, 3, 4 and 5 respectively (1 being the highest priority). Suppose, even before P5 gets the CPU, many other new processes keep arriving with higher priority. Then, P5 never gets the CPU. Since P5 has a low priority, P5 is starved. To solve this starvation problem, aging is used. That is, the priority of the starving process is increased gradually, based on the time the starving process is waiting in the ready queue. Thus the starving process also will get the CPU in course of time.5.4 Round Robin (RR) schedulingIn round robin (RR) scheduling, each process gets a small unit of CPU time, called a time quantum, usually 10–100 milliseconds. After this time has elapsed, the process is preempted and added to the end of the ready queue. The ready queue is treated as a circular queue. Thus, this RR scheduling algorithm is similar to FCFS, but preemption is added to switch between processes. If a process that is currently using the CPU has a CPU burst less than 1 time quantum, the process releases the CPU voluntarily. If the CPU burst time is longer than 1 time quantum, the timer goes off, an interrupt is sent to the operating system and context switch happens. The currently running process is added to the tail of the ready queue and the next process is selected by the scheduler.5.4.1 Example of RR with Time Quantum = 20Consider four processes P1, P2, P3 and P4 whose CPU-burst times in milliseconds are given below:Process Burst TimeP1 53P2 17P3 68P4 24The Gantt chart for RR scheduling. The time quantum is 20.Processes have arrived in the order P1, P2, P3 and P4. Process P1 is in the head of the ready queue and hence, P1 gets the CPU first. P1 uses the CPU for 20 ms (time quantum). P1 has not yet completed its CPU burst at the end of the time quantum. Yet, at the end of the time quantum, P1 is preempted and is added to the tail of the queue. The next process in the queue, P2 gets the CPU next. P2 needs the CPU only for 17 ms. Hence, after using the CPU for 17ms, at time 37 ms, P2 relinquishes the CPU on its own. Now, the next process in the queue, P3 is assigned the CPU. After 20 ms of CPU time for P3, P3 is preempted and is added to the tail of the queue. The next process in the queue, P4, is assigned the CPU and P4 uses the CPU for 20 ms. P4 is preempted and is added to the tail of the queue. Now, the process in the head of the queue is P1. The CPU burst time of P1 is 53 ms. P1 has already used 20 ms. Now, it is given another 20 ms of CPU time and is then preempted and added to the tail of the queue. The next process in the queue, P3 needs 48 ms more. P3 is now given 20 ms and is then added to the tail of the queue. The next process in the queue, P4 needs only 4ms more of CPU time. After 4 ms, P4 relinquishes the CPU by itself. P1 is next in the head of the queue. P1 needs 13 ms more. After 13 ms, P1 relinquishes the CPU. The process currently in the head of the queue is P3. P3 is given the CPU in the next time slot. Since there is no other process in the queue at the end of the time quantum (20 ms), P3 continues to use the CPU till its CPU burst is completed.5.4.2 Calculation of waiting time and turnaround timeFrom the Gantt chart shown in Figure 8.8, the average waiting time and the average turnaround time can be calculated. Process P1 arrives at time 0 and gets the CPU immediately. Then from time 20 ms to 77 ms and then from 97 ms to 121 ms, P1 is waiting. Hence, the waiting time for P1 is 57 ms + 24 ms = 81 ms. Process P2 arrives at time 0 and gets the CPU at time 20 ms and completes its CPU burst. Therefore, the waiting time for process P2 is 20 ms. Process P3 arrives at time 0 and gets the CPU at 37 ms. Then from time 57 ms to 97 ms and later from 117 ms to 134 ms, P3 is waiting. Therefore, the waiting time for P3 is 37 + 40 + 17 = 94 ms. Process P4 arrives at time 0 and gets the CPU at time 57 ms. From time 77 ms to 117 ms, P4 is waiting. Hence, the waiting time for process P4 is 57 + 40 = 97ms. The average waiting time therefore is (81 + 20 + 94 + 97)/4 = 292/4 = 73 ms.Process P1 arrives at time 0 and completes execution at 134 ms. Hence, the turnaround time for P1 is 134 ms. Process P2 arrives at time 0 and completes execution at 37 ms. Hence, the turnaround time for P2 is 37 ms. Process P3 arrives at time 0 and completes execution at 162 ms. Hence, the turnaround time for P3 is 162 ms. Process P4 arrives at time 0 and completes execution at 121 ms. Hence, the turnaround time for P4 is 121 ms. Hence, the average turnaround time = (134 +37 + 162 + 121)/4 = 454/4 = 113.5 ms.5.4.3 Dependence of the performance of RR algorithm on the size of the time quantumRR scheduling algorithm has higher average turnaround than SJF but better response. In RR scheduling algorithm, if there are n processes in the ready queue and the time quantum is q, then each process gets 1/n of the CPU time in chunks of at most q time units at once. Thus, no process waits more than (n-1)q time units. Let us see how the size of the time quantum affects the performance of RR scheduling algorithm. If the time quantum q is large, the performance of RR is very similar to FCFS. All processes complete their CPU bursts within their time quantum and hence, the scheduling is similar to that of FCFS. If the time quantum q is small, the RR approach is called processor sharing. It appears to the users as if they get the entire processor time but with a speed equal to 1/n of the actual processor speed.Figure 8.9 shows how the number of context switches varies with the size of the time quantum. When the burst time of the process is 10 and the time quantum is 12, the process completes its CPU burst within the time quantum. Therefore, there is no context switch. When the time quantum is reduced to 6 for the same CPU burst time of 10, there is one context switch. When the time quantum is reduced to 1, the number of context switches gets increased to 9. Thus, it is seen that when the time quantum is very large, the number of context switches is less. When the size of the time quantum becomes small, the number of contexts increases. The time spent on context switches is a mere overhead. Hence, the time quantum q must be large with respect to the context switch. Otherwise, the overhead is too high. If most of the processes complete their CPU bursts within the time quantum, then the number of context switches will not be more.It is seen that the average turnaround time does not necessarily increase with increase in time quantum size. The average turnaround time can be improved if most processes complete their next CPU burst within a single time quantum.5.5 SummaryIn this module, we learnt how preemptive SJF, priority and round robin scheduling algorithms work. In preemptive SJF, at any time, only the process with the shortest remaining CPU burst time is assigned the CPU. In priority scheduling algorithm, the process with the highest priority is assigned the CPU. In round robin scheduling, each process is assigned a fixed time slice of CPU time. We also learnt the performance analysis of each CPU scheduling algorithm in terms of average waiting time and average turnaround time.References1. Abraham Silberschatz, Peter B. Galvin, Greg Gagne, “Operating System Concepts”, Sixth Edition, John Wiley & Sons Inc., 2003. 2. Andrew S. Tanenbaum, Herbert Bos, “Modern Operating Systems”, Fourth Edition, Pearson Education, 2014. Gary Nutt, “Operating Systems”, Third Edition, Pearson Education, 2009. 3. William Stallings, “Operating Systems: Internals and Design Principles”, Seventh Edition, Pearson, 2012Written byEffective ReaderOur site you can see all the details about the computer and all the career information and some unknown facts that you never knew.FollowOperating SystemsComputer ScienceInformation TechnologyCpu SchedulingComputersMore from Effective ReaderFollowOur site you can see all the details about the computer and all the career information and some unknown facts that you never knew.More From MediumA Guide to Video Steganography Using PythonAnand Murali in Better ProgrammingBash Scripts — Part 5 — Signals and Background TasksMikhail Raevskiy in The StartupPython: Getting StartedOsama Yasser in Dev GeniusThe Practical Difference between Abstract Classes and Traits in ScalaMuhammad Shahab Niaz in The StartupTo throw or not to throwVineeth VenudasanBuilding a City Search with Elixir and PythonPaul Götze in The StartupAvoid a Dirty Git RepoŽivković Miloš in Better ProgrammingCharacter Encodings — The Pain That Won’t Go Away, Part 2/3: UnicodeRandy Au in Better ProgrammingAboutHelpLegalGet the Medium app"
Operating System — CPU Scheduling I : 04,https://medium.com/@effectivereader/operating-system-cpu-scheduling-i-04-7efaed31d8a8?source=tag_archive---------1-----------------------,"Operating System,Computer Science,Information Technology,Software Engineering,Computers","Operating System — CPU Scheduling I : 044.1 IntroductionCPU scheduling is used in operating systems to make use of the processor time to the maximum and to provide multiple users with a feel that they are the sole users of the system. This module explains the basic concepts of CPU scheduling and the different criteria needed for evaluating CPU scheduling algorithms and the working of the First Come First Served (FCFS) and non-preemptive Shortest Job First (SJF) CPU scheduling algorithms.4.2 Basic ConceptsIn a multiprogramming system, many processes are kept in memory at a particular time. Any process, during execution may have to wait for the completion of some I/O request. During this time, the CPU will remain idle. But, the objective of multiprogramming is to have some program running always and hence maximize CPU utilization. Hence, when a process waits for I/O, the operating system takes away the CPU from the process and assigns the CPU to another process. But, of the many processes residing in the memory, which is the next process to which the CPU is assigned? This selection is done by the CPU scheduler.The success of CPU scheduling depends on the following property of processes: Process execution comprises a cycle of CPU execution (CPU burst) and I/O wait (I/O burst). Any process alternates between these two states. Process execution begins with a CPU burst. This CPU burst is followed by an I/O burst, then a CPU burst, then an I/O burst and so on. Figure 7.1 shows an example of how a process alternates between CPU and I/O bursts, during its execution.Consider the following program in C to find the sum of two numbers:int main(void){int a,b, sum;/*I/O burst*/ printf(“Enter the two numbers to be added\n”); scanf(“%d %d”,&a,&b);/*CPU burst */ sum = a+b;/*I/O burst*/ printf(“ The sum of %d and %d is %d \n”, a,b,sum);return 0;}It can be seen that the first two statements are I/O bound, the third statement is CPU-bound and the next statement is I/O bound. Thus any program will have alternating CPU-bound and I/O bound instructions.Fig. 7.1 Alternating sequence of CPU and I/O bursts (Source: [1])If a program has few and very long CPU bursts, it is a CPU-bound program. An I/O-bound program has many very short CPU bursts. The duration of CPU bursts vary from process to process and from computer to computer. Still, the CPU bursts tend to have a frequency curve similar to that shown in Figure 7.2. It is seen from Figure 7.2 that very short CPU bursts are more frequent than long CPU bursts. Whenever a CPU burst ends, there is an I/O burst. When there is an I/O burst, the process has to wait for I/O to get completed and is moved to the waiting state. Now, the CPU scheduler has to run to select the next process that should be assigned the CPU. Since the CPU bursts are frequent, the CPU scheduler has to run frequently.Fig. 7.2 Histogram of CPU-burst times (Source: [1])4.3 CPU SchedulerWhenever the CPU becomes idle, the operating system should select one of the processes in the ready queue and that process is assigned the CPU. This selection is done by the CPU scheduler. The CPU scheduler is also called the short-term scheduler. The CPU scheduler selects from among the processes in memory that are ready to execute, and allocates the CPU to one of them. The ready queue from which the processes are selected need not be a first in, first out queue, always. The ready queue may even be a priority queue, a tree or an unordered linked list.Figure 7.3 shows the change in states during the lifetime of a process. CPU scheduling decisions may take place when a process:1. Switches from running to waiting state (I/O, wait system call)2. Switches from running to ready state (timer interrupt)3. Switches from waiting to ready (completion of I/O)4. TerminatesFig. 7.3 Process state transition diagramWhen the process switches from the running state to the waiting state or when the process terminates, the process relinquishes the CPU on its own. It is not forced to relinquish the CPU. When scheduling takes place in these circumstances, it is called non-preemptive CPU scheduling. When the process moves from the waiting state to the ready state or when the process moves from the running state to the ready state, the CPU is forcibly removed from the process. The scheduling that happens in these circumstances is called preemptive scheduling.4.4 DispatcherOnly the selection of which process will use the CPU next is done by the CPU scheduler. The dispatcher module is the one that gives control of the CPU to the process selected by the short-term scheduler. The dispatcher takes care of the following:1. Switching context2. Switching to user mode3. Jumping to the proper location in the user program to restart that program Thus, it takes some time for the dispatcher to stop one process and start another process. This time is called dispatch latency. The dispatch latency should be as less as possible because the CPU does not do any useful work during this period.4.5 Scheduling CriteriaMany CPU scheduling algorithms have been proposed. To select the best CPU scheduling algorithm, various criteria can be considered. The following are some of the criteria that are used to analyze the performance of any CPU scheduling algorithm:1. CPU utilization — Keep the CPU as busy as possible. Hence, CPU utilization should be maximum.2. Throughput — Number of processes that complete their execution per time unit. Throughput should be maximum.3. Turnaround time — amount of time to execute a particular process. This should be as minimum as possible.4. Waiting time — amount of time a process has been waiting in the ready queue. This should be as minimum as possible.5. Response time — amount of time it takes from when a request was submitted until the first response is produced, not output (for time-sharing environment). Response time should be as minimum as possible.4.6 Scheduling algorithmsIn this section, we will learn two CPU scheduling algorithms, First Come First Served (FCFS) scheduling and Shortest Job First (SJF) scheduling algorithms.4.6.1 First-Come, First-Served (FCFS) SchedulingIn FCFS, the process that arrived first and requests the CPU first is assigned the CPU first. In FCFS, the ready queue can be maintained as a FIFO queue. When processes arrive they are added to the tail of the queue. When the CPU becomes free, the process in the head of the queue is taken for execution. This is a non-preemptive algorithm. Once a process is assigned the CPU, the process continues to use the CPU till its CPU burst time is completed. When its CPU burst gets over, the process by itself relinquishes the CPU. FCFS is explained with an example given below:Consider three processes P1, P2 and P3 with CPU-burst times 24 milliseconds (ms), 3 ms and 3 ms respectively. All three processes arrive at the same time in the order P1, P2, P3.The Gantt chart that shows the order in which processes are assigned the CPU is shown below. Since process P1 is the first process in the queue, P1 is assigned the CPU first. P1 has a CPU-burst length of 24 ms. P1 uses the CPU for 24 ms and then relinquishes the CPU as shown in Figure 7.4.Fig. 7.4 Process P1 using the CPUThe next process in the queue is P2. P2 is scheduled next. P2 has a CPU-burst time of 3 ms and uses the CPU till 27 ms as shown in Figure 7.5.Fig. 7.5 Process P2 using the CPUAfter P2, P3 is the only process in the queue and it is assigned the CPU. P3 uses the CPU for a time duration of 3 ms and then relinquishes the CPU as shown in Figure 7.6.Fig. 7.4 Process P3 using the CPUThe waiting time for each process and hence the average waiting time can be calculated. Since all the three processes arrive at the same time, the arrival time of the processes is taken as 0. Process P1 arrived at time 0 and was assigned the CPU immediately. Hence, the waiting time for P1 = 0. Process P2 arrived at time 0 and was assigned the CPU at time 24. Hence, the waiting time for P2 = 24. Process P3 arrived at time 0 and was assigned the CPU at time 27. Hence, the waiting time for P3 = 27.Hence, the average waiting time is (0 + 24 + 27) / 3 = 17.Similarly, the turnaround time for each process and hence the average turnaround time can be calculated. Process P1 arrived at time 0 and completed its CPU burst at time 24. Hence, the turnaround time for P1 = 24. Process P2 arrived at time 0 and completed its CPU burst at time 27. Hence, the turnaround time for P2 = 27. Process P3 arrived at time 0 and completed its CPU burst at time 30. Hence, the turnaround time for P3 = 30.The average turnaround time is (24 + 27 + 30) / 3 = 27.Suppose if the three processes arrive in the order P2, P3, P1. The Gantt chart for the schedule is as shown in Figure 7.5.Fig. 7.5 Gantt chart with the order of the processes changedThe waiting time of the processes can be calculated as follows: The arrival time for all the processes is the same and is taken as 0. Therefore, the waiting time for P1 = 6, P2 = 0 and P3 = 3. The average waiting time is (6 + 0 + 3)/3 = 3. The turnaround time for P1 =30, P2 = 3 and P3 = 6. Therefore, the average turnaround time is (3 + 6 + 30)/3 = 13. It is seen that the average waiting time and the average turnaround time have improved when the order of the processes is changed. In the earlier case, process P1 had a long CPU burst and the other processes had to wait for P1 to complete its CPU burst. This increased the average waiting time and the average turnaround time.4.6.2 Shortest-Job-First (SJF) SchedulingThe SJF CPU scheduling algorithm associates with each process the length of its next CPU burst. These lengths are used to schedule the process with the shortest time. When the CPU becomes available, the process with the shortest next CPU burst is assigned the CPU. There are two schemes in SJF. One is non-preemptive in which once CPU is assigned to a process, it cannot be preempted until it completes its CPU burst. The other is preemptive in which if a new process arrives with CPU burst length less than the remaining time of the currently executing process, the currently executing process is preempted. This scheme is known as the Shortest-Remaining-Time-First (SRTF). In this module, we will learn how scheduling is done in non-preemptive SJF. Consider four processes P1, P2, P3 and P4. The arrival times and the CPU-bursttimes of the four processes are given below:Process Arrival Time Burst TimeP1 0.0 7P2 2.0 4P3 4.0 1P4 5.0 4At time 0.0, P1 is the only process that has arrived. Hence, P1 is assigned the CPU first. Since it is non-preemptive SJF scheduling, P1 continues to use the CPU till its CPU-burst gets over as shown in Figure 7.6Fig. 7.6 Process P1 using the CPUAfter P1 finishes its CPU-burst, the processes remaining in the ready queue are P2, P3 and P4. The processes P2, P3 and P4 have now arrived. Of these three processes, P3 has the shortest CPU burst. Hence, P3 is assigned the CPU. P3 makes use of the CPU for a time duration that is equal to its CPU burst (1 ms) and then relinquishes the CPU as in Figure 7.7.Fig. 7.7 Process P3 using the CPUP2 and P4 are the remaining processes. Both the processes have the same CPU burst time. Any one of these can be assigned the CPU. So, the tie is now broken using FCFS.Of the two processes, P2 arrived earlier. Hence, P2 is assigned the CPU and P2 executes till its CPU burst is completed as in Figure 7.8.Fig. 7.8 P2 using the CPUThe average waiting time and the average turnaround time can be calculated as follows. The waiting time for process P1 is 0. P1 arrived at time 0 and was assigned the CPU immediately. P1 did not wait. P2 arrived at time 2.0 and was assigned the CPU at time 8.0. Hence, the waiting time for process P2 is 8–2 = 6. P3 arrived at time 4.0 and was assigned the CPU at time 7.0. Hence, the waiting time for process P2 is 7–4 = 3. Process P4 arrived at time 5.0 and was assigned the CPU at time 12.0. Hence the waiting time of process P2 is 12–5 = 7. Hence, the average waiting time = (0 + (8–2) + (7–4) + (12–5)) / 4 = 4.P1 arrived at time 0 and completed execution at 7. The turnaround time of process P1 is 7. P2 arrived at time 2.0 and completed execution at time 12.0. Hence, the turnaround time for process P2 is 12–2 = 10. P3 arrived at time 4.0 and completed execution at time 8.0. Hence, the waiting time for process P2 is 8–4 = 4. Process P4 arrived at time 5.0 and completed execution at time 16.0. Hence, the turnaround time of process P2 is 16–5 = 11. Hence the average waiting time = (0 + (8–2) + (7–4) + (12–5)) / 4 = 4. Hence, the average turnaround time = ((7–0) + (12–2) + (8–4) + (16–5)) / 4 = 32 / 4 =8.4.7 SummaryIn this module, we learnt what CPU scheduling is. Multiprogramming maximizes CPU utilization. The CPU scheduler selects the next process that should be assigned the CPU. Many CPU scheduling algorithms have been proposed. CPU scheduling algorithms can be preemptive or non-preemptive. In this module, we learnt how First Come First Served (FCFS) and non-preemptive Shortest Job First (SJF) CPU scheduling algorithms work. We saw that SJF has less waiting time and less turnaround time when compared to FCFS.References1. Abraham Silberschatz, Peter B. Galvin, Greg Gagne, “Operating System Concepts”, Sixth Edition, John Wiley & Sons Inc., 2003.Written byEffective ReaderOur site you can see all the details about the computer and all the career information and some unknown facts that you never knew.FollowOperating SystemComputer ScienceInformation TechnologySoftware EngineeringComputersMore from Effective ReaderFollowOur site you can see all the details about the computer and all the career information and some unknown facts that you never knew.More From MediumHow to Automate Continuous Integration and Development, Versioning and PublishingSidney Barrah in The StartupAutomating .NET Core Services with PostSharp and Aspect-Oriented CodeAlexander Johnston in DealerOn DevPython TestingJordan Williams in Tech x TalentMost Common String Methods in PythonOzan Güner in The StartupRSpec Tests for BeginnersJlspursfan in The StartupDynamic component styles in Nuxt using Tailwind CSS and Lookup tablesLiam Hall in JavaScript In Plain English11 Things That Will Make Your Web Application Load FasterAmel HalilovicWhy do we fall into the rewrite trap?Justin Fuller in The StartupAboutHelpLegalGet the Medium app"
